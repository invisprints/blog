{
  
    
        "post0": {
            "title": "Markdown Posts Template",
            "content": "Today, we are going to show you how to set up a literate programming environment, allowing you to use an IDE (VS Code) and an interactive computing environment (Jupyter), without leaving your browser, for free, in under 5 minutes. You’ll even see how VSCode and Jupyter work together automatically! But first, what is literate programming? And how did I go from skeptic to a zealot of literate programming? . Introduction . Literate programming is a programming paradigm introduced by Donald Knuth in which a computer program is given an explanation of its logic in a natural language, such as English, interspersed with snippets of macros and traditional source code, from which compilable source code can be generated. According to Knuth, literate programming provides higher-quality programs by forcing programmers to explicitly state the thoughts behind the program. This process makes poorly thought-out design decisions more obvious. Knuth also claims that literate programming provides a first-rate documentation system, which is not an add-on, but is grown naturally in the process of exposition of one’s thoughts during a program’s creation. 1 . When I first learned about literate programming, I was quite skeptical. For the longest time, I had wrongly equated Jupyter notebooks with literate programming. Indeed, Jupyter is a brilliant interactive computing system, which was awarded the Association of Computing Machinery (ACM) Software System Award, and is loved by many developers. However, Jupyter falls short of the literate programming paradigm for the following reasons:2 . It can be difficult to compile source code from notebooks. | It can be difficult to diff and use version control with notebooks because they are not stored in plain text. | It is not clear how to automatically generate documentation from notebooks. | It is not clear how to properly run tests suites when writing code in notebooks. | . My skepticism quickly evaporated when I began using nbdev, a project that extends notebooks to complete the literate programming ideal. I spent a month, full time, using nbdev while contributing to the python library fastcore, and can report that Donald Knuth was definitely onto something. The process of writing prose and tests alongside code forced me to deeply understand why the code does what it does, and to think deeply about its design. Furthermore, the reduced cognitive load and speed of iteration of having documentation, code, and tests in one location boosted my productivity to levels I have never before experienced as a software developer. Furthermore, I found that developing this way bolstered collaboration such that code reviews not only happened faster but were more meaningful. In short, nbdev may be the most profound productivity tool I have ever used. . As a teaser, look how easy it is to instantiate this literate programming environment, which includes a notebook, a docs site and an IDE with all dependencies pre-installed! :point_down: . . Features of nbdev . As discussed in the docs, nbdev provides the following features: . Searchable, hyperlinked documentation, which can be automatically hosted on GitHub Pages for free. | Python modules, following best practices such as automatically defining __all__ with your exported functions, classes, and variables. | Pip and Conda installers. | Tests defined directly in notebooks which run in parallel. This testing system has been thoroughly tested with GitHub Actions. | Navigate and edit your code in a standard text editor or IDE, and export any changes automatically back into your notebooks. | . Since you are in a notebook, you can also add charts, text, links, images, videos, etc, that are included automatically in the documentation of your library, along with standardized documentation generated automatically from your code. This site is an example of docs generated automatically by nbdev. . GitHub Codespaces . Thanks to Conda and nbdev_template, setting up a development environment with nbdev is far easier than it used to be. However, we realized it could be even easier, thanks to a new GitHub product called Codespaces. Codespaces is a fully functional development environment in your browser, accessible directly from GitHub, that provides the following features: . A full VS Code IDE. | An environment that has files from the repository mounted into the environment, along with your GitHub credentials. | A development environment with dependencies pre-installed, backed by Docker. | The ability to serve additional applications on arbitrary ports. For nbdev, we serve a Jupyter notebook server as well as a Jekyll based documentation site. | A shared file system, which facilitates editing code in one browser tab and rendering the results in another. | … and more. | Codespaces enables developers to immediately participate in a project without wasting time on DevOps or complicated setup steps. Most importantly, CodeSpaces with nbdev allows developers to quickly get started with creating their own software with literate programming. . A demo of nbdev + Codespaces . This demo uses the project fastai/fastcore, which was built with nbdev, as an example. First, we can navigate to this repo and launch a Codespace: . . If you are launching a fresh Codespace, it may take several minutes to set up. Once the environment is ready, we can verify that all dependencies we want are installed (in this case fastcore and nbdev): . . Additionally, we can serve an arbitrary number of applications on user-specified ports, which we can open through VSCode as shown below: . . In this case, these applications are a notebook and docs site. Changes to a notebook are reflected immediately in the data docs. Furthermore, we can use the cli command nbdev_build_lib to sync our notebooks with python modules. This functionality is shown below: . . This is amazing! With a click of a button, I was able to: . Launch an IDE with all dependencies pre-installed. | Launch two additional applications: a Jupyter Notebook server on port 8080 and a docs site on port 4000. | Automatically update the docs and modules every time I make a change to a Jupyter notebook. | This is just the tip of the iceberg. There are additional utilities for writing and executing tests, diffing notebooks, special flags for hiding, showing, and collapsing cells in the generated docs, as well as git hooks for automation. This and more functionality is covered in the nbdev docs. . Give It A Try For Yourself . To try out nbdev yourself, take this tutorial, which will walk you through everything you need to know. The tutorial also shows you how to use a repository template with the configuration files necessary to enable Codespaces with nbdev. . You Can Write Blogs With Notebooks, Too! . This blog post was written in fastpages which is also built on nbdev! We recommend fastpages if you want an easy way to blog with Jupyter notebooks. . Additional Resources . The GitHub Codepaces site. | The official docs for Codespaces. | The nbdev docs. | The nbdev GitHub repo. | fastpages: The project used to write this blog. | The GitHub repo fastai/fastcore, which is what we used in this blog post as an example. | . Wikipedia article: Literate Programming &#8617; . | This is not a criticism of Jupyter. Jupyter doesn’t claim to be a full literate programming system. However, people can sometimes (unfairly) judge Jupyter according to this criteria. &#8617; . |",
            "url": "https://invisprints.github.io/blog/template",
            "relUrl": "/template",
            "date": " • Dec 10, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Word 下插入公式",
            "content": "Microsoft 365/ 2019 如今已经非常强大，近几年的更新中加入了对 LaTeX 公式的支持，基本上可以摆脱对 mathtype 或其他专业公式编辑器的依赖。 . 关于在 Word 中插入公式的方法，Microsoft 支持中一文Word 中使用 UnicodeMath 和 LaTeX 的线性格式公式已经阐述得很清楚了，此篇博文在这篇说明上上作以下几点重要补充。 . 推荐使用 LaTeX 编辑公式 . 目前学术界广泛使用 LaTeX 编辑公式，或者说就笔者所知，目前除了 Microsoft Office 外没有其他软件支持 UnicodeMath，因此从分享的便利性来讲，LaTex 公式更易与他人共享合作。 . 公式字体 . 尽管 Word 默认支持各种各样的字体，但是公式编辑器默认只支持 Cambria Math 字体，这难以满足大部分论文要求。 . 以 macOS 版的 2019 Word 为例，在安装好期刊会议要求的公式字体后，在格式-公式选项中将公式的默认字体切换到要求的字体上。Word 公式编辑器支持的字体需满足 Opentype Math 格式。 . 公式编号 . 像下图这种公式后面的编号怎么实现呢？ 很简单，在公式末尾添加#(数字序号)即可实现。 . h=F(x_1,x_2, cdots,x_n)#(7) . 导出 . 对于使用自定义公式字体的 Word 文档，导出成 pdf 时可能会遇到公式模糊，锯齿感严重等问题。这时只需将导出改成【文件】- 【打印】，然后选择打印机为 Microsoft Print to PDF ，点击打印，即可完美实现 PDF 输出。 . 参考 . 文中所有链接 . Microoft Word 数学公式完美解决方案 .",
            "url": "https://invisprints.github.io/blog/word/2020/11/04/Word-formula.html",
            "relUrl": "/word/2020/11/04/Word-formula.html",
            "date": " • Nov 4, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "WingLoss 核心技术复现",
            "content": "&#23433;&#35013;&#28145;&#24230;&#23398;&#20064;&#29615;&#22659; . !pip install pytorch-lightning opencv-python matplotlib pandas -U -i https://mirrors.aliyun.com/pypi/simple/ # !pip install plotly -U -i https://mirrors.aliyun.com/pypi/simple/ # !jupyter labextension install jupyterlab-plotly plotlywidget . 为了让代码可阅读性更加，这次我们使用 pytorch-lightning 库而不是原生的 pytorch 复现 Wingloss，有关 pytorch-lightning 的介绍可以阅读官方指南PyTorch Lightning . %reload_ext autoreload %autoreload 2 %matplotlib inline . &#25968;&#25454;&#38598;&#23384;&#25918;&#26684;&#24335; . 为了方便期间，我们假设文件结构如下定义 . root/ main.ipynb | data/ 300W/ | WFLW/ | ... | . | . | . &#23450;&#20041; WingLoss . 在论文中，Wingloss 的数学表达形式如下 . $$ wing(x)= left { begin{matrix} omega ln(1+ left | x right |/ varepsilon ) &amp; if left | x right | &lt; omega left | x right |-C &amp; otherwise, end{matrix} right. $$按照数学表达式我们定义其损失函数如下 . import math import torch from torch import nn class WingLoss(nn.Module): def __init__(self, omega=10, epsilon=2): super().__init__() self.omega = omega self.epsilon = epsilon def forward(self, pred, target): y = target # y = y.view(y.shape[0], -1) y_hat = pred delta_y = (y - y_hat).abs() delta_y1 = delta_y[delta_y &lt; self.omega] delta_y2 = delta_y[delta_y &gt;= self.omega] loss1 = self.omega * torch.log(1 + delta_y1 / self.epsilon) C = self.omega - self.omega * math.log(1 + self.omega / self.epsilon) loss2 = delta_y2 - C return (loss1.sum() + loss2.sum()) / (len(loss1) + len(loss2)) . &#25968;&#25454;&#22788;&#29702; . from pathlib import Path # data_type = &#39;wflw&#39; # data_root = &#39;WFLW_images&#39; data_type = &#39;300w&#39; data_root = &#39;300W_&#39; data_path = Path(&#39;/home/oppoer/work/&#39;)/data_type train_csv_file = data_path/f&#39;face_landmarks_{data_type}_train.csv&#39; # test_csv_file = data_path/f&#39;face_landmarks_{data_type}_test.csv&#39; test_csv_file = data_path/&#39;face_landmarks_300w_valid_common.csv&#39; # test_csv_file = data_path/&#39;face_landmarks_300w_valid_challenge.csv&#39; . import numpy as np import cv2 import math DEBUG = True def ref3DModel(): modelPoints = [[0.0, 0.0, 0.0], [0.0, -330.0, -65.0], [-225.0, 170.0, -135.0], [225.0, 170.0, -135.0], [-150.0, -150.0, -125.0], [150.0, -150.0, -125.0]] return np.array(modelPoints, dtype=np.float64) def ref2dImagePoints(shape): imagePoints = [shape[30], shape[8], shape[36], shape[45], shape[48], shape[54]] return np.array(imagePoints, dtype=np.float64) def cameraMatrix(fl, center): mat = [[fl, 0, center[0]], [0, fl, center[1]], [0, 0, 1]] return np.array(mat, dtype=np.float) face3Dmodel = ref3DModel() def cal_euler(img_path, landmark): refImgPts = ref2dImagePoints(landmark) height, width, channel = cv2.imread(str(img_path)).shape focalLength = 1 * width camMatrix = cameraMatrix(focalLength, (height / 2, width / 2)) mdists = np.zeros((4, 1), dtype=np.float64) # calculate rotation and translation vector using solvePnP success, rotationVector, translationVector = cv2.solvePnP( face3Dmodel, refImgPts, camMatrix, mdists) rotation_matrix, _ = cv2.Rodrigues(rotationVector) proj_mat = cv2.hconcat((rotation_matrix, translationVector)) eulerAngles = cv2.decomposeProjectionMatrix(proj_mat)[6] #[pitch, yaw, roll] pitch, yaw, roll = [math.radians(_) for _ in eulerAngles] pitch = math.degrees(math.asin(math.sin(pitch))) roll = -math.degrees(math.asin(math.sin(roll))) yaw = math.degrees(math.asin(math.sin(yaw))) return pitch, yaw, roll . import random import matplotlib.pyplot as plt from tqdm import tqdm import pandas as pd def oversample(csv_file, debug=False): if debug: figure, ax = plt.subplots(1,2) else: figure, ax = plt.subplots(1,1) yaws = [] df = pd.read_csv(csv_file) for idx in tqdm(range(len(df)), desc=&#39;cal origin euler...&#39;): img_path = data_path/data_root/df.iloc[idx, 0] pts = df.iloc[idx, 4:].values pts = pts.astype(&#39;float&#39;).reshape(-1, 2) yaw = cal_euler(img_path, pts)[1] yaws.append(yaw) if debug: n, bins, patches = ax[0].hist(yaws, bins=9) else: n, bins, patches = ax.hist(yaws, bins=9) print(&quot;orginal hist&quot;, n, bins) frame_lists = [] n_max = max(n) for idx in tqdm(range(len(df)), desc=&#39;oversample data&#39;): img_path = data_path/data_root/df.iloc[idx, 0] pts = df.iloc[idx, 4:].values pts = pts.astype(&#39;float&#39;).reshape(-1, 2) yaw = cal_euler(img_path, pts)[1] for i in range(len(bins)-1): if bins[i]&lt;=yaw&lt;bins[i+1]+0: for count in range(int(n_max/n[i])): frame_lists.append(df.iloc[idx]) if n_max/n[i] - int(n_max/n[i]) &gt; random.random(): frame_lists.append(df.iloc[idx]) break new_df = pd.DataFrame(frame_lists) if debug: yaws = [] for idx in tqdm(range(len(new_df)), desc=&#39;cal pdb euler...&#39;): img_path = data_path/data_root/new_df.iloc[idx, 0] pts = new_df.iloc[idx, 4:].values pts = pts.astype(&#39;float&#39;).reshape(-1, 2) yaw = cal_euler(img_path, pts)[1] yaws.append(yaw) n, bins, patches = ax[1].hist(yaws, bins=9) print(&quot;oversample hist&quot;, n, bins) return new_df # train_df = oversample(train_csv_file, debug=False) train_df = pd.read_csv(train_csv_file) test_df = pd.read_csv(test_csv_file) . import numpy as np import cv2 import torch import skimage.transform as transform MATCHED_PARTS = { &quot;300w&quot;: ([1, 17], [2, 16], [3, 15], [4, 14], [5, 13], [6, 12], [7, 11], [8, 10], [18, 27], [19, 26], [20, 25], [21, 24], [22, 23], [32, 36], [33, 35], [37, 46], [38, 45], [39, 44], [40, 43], [41, 48], [42, 47], [49, 55], [50, 54], [51, 53], [62, 64], [61, 65], [68, 66], [59, 57], [60, 56]), &quot;wflw&quot;: ([0, 32], [1, 31], [2, 30], [3, 29], [4, 28], [5, 27], [6, 26], [7, 25], [8, 24], [9, 23], [10, 22], [11, 21], [12, 20], [13, 19], [14, 18], [15, 17], # check [33, 46], [34, 45], [35, 44], [36, 43], [37, 42], [38, 50], [39, 49], [40, 48], [41, 47], # elbrow [60, 72], [61, 71], [62, 70], [63, 69], [64, 68], [65, 75], [66, 74], [67, 73], [55, 59], [56, 58], [76, 82], [77, 81], [78, 80], [87, 83], [86, 84], [88, 92], [89, 91], [95, 93], [96, 97])} def fliplr_joints(x, width, dataset=&#39;aflw&#39;): &quot;&quot;&quot; flip coords &quot;&quot;&quot; matched_parts = MATCHED_PARTS[dataset] # Flip horizontal x[:, 0] = width - x[:, 0] if dataset == &#39;WFLW&#39;: for pair in matched_parts: tmp = x[pair[0], :].copy() x[pair[0], :] = x[pair[1], :] x[pair[1], :] = tmp else: for pair in matched_parts: tmp = x[pair[0] - 1, :].copy() x[pair[0] - 1, :] = x[pair[1] - 1, :] x[pair[1] - 1, :] = tmp return x def get_transform(center, scale, output_size, rot=0): &quot;&quot;&quot; General image processing functions &quot;&quot;&quot; # Generate transformation matrix h = 200 * scale t = np.zeros((3, 3)) t[0, 0] = float(output_size[1]) / h t[1, 1] = float(output_size[0]) / h t[0, 2] = output_size[1] * (-float(center[0]) / h + .5) t[1, 2] = output_size[0] * (-float(center[1]) / h + .5) t[2, 2] = 1 if not rot == 0: rot = -rot # To match direction of rotation from cropping rot_mat = np.zeros((3, 3)) rot_rad = rot * np.pi / 180 sn, cs = np.sin(rot_rad), np.cos(rot_rad) rot_mat[0, :2] = [cs, -sn] rot_mat[1, :2] = [sn, cs] rot_mat[2, 2] = 1 # Need to rotate around center t_mat = np.eye(3) t_mat[0, 2] = -output_size[1]/2 t_mat[1, 2] = -output_size[0]/2 t_inv = t_mat.copy() t_inv[:2, 2] *= -1 t = np.dot(t_inv, np.dot(rot_mat, np.dot(t_mat, t))) return t def transform_pixel(pt, center, scale, output_size, invert=0, rot=0): # Transform pixel location to different reference t = get_transform(center, scale, output_size, rot=rot) if invert: t = np.linalg.inv(t) new_pt = np.array([pt[0] - 1, pt[1] - 1, 1.]).T new_pt = np.dot(t, new_pt) return new_pt[:2].astype(int) + 1 def crop(img, center, scale, output_size, rot=0): center_new = center.clone() # Preprocessing for efficient cropping ht, wd = img.shape[0], img.shape[1] sf = scale * 200.0 / output_size[0] if sf &lt; 2: sf = 1 else: new_size = int(np.math.floor(max(ht, wd) / sf)) new_ht = int(np.math.floor(ht / sf)) new_wd = int(np.math.floor(wd / sf)) if new_size &lt; 2: return torch.zeros(output_size[0], output_size[1], img.shape[2]) if len(img.shape) &gt; 2 else torch.zeros(output_size[0], output_size[1]) else: img = cv2.resize(img, (new_wd, new_ht)) # (0-1)--&gt;(0-255) # img = transform.resize(img, (new_ht, new_wd)) # center_new[0] = center_new[0] * 1.0 / sf # center_new[1] = center_new[1] * 1.0 / sf center_new[1] = center_new[1] * new_ht / ht center_new[0] = center_new[0] * new_wd / wd scale = scale / sf # Upper left point ul = np.array(transform_pixel([0, 0], center_new, scale, output_size, invert=1)) # Bottom right point br = np.array(transform_pixel(output_size, center_new, scale, output_size, invert=1)) # Padding so that when rotated proper amount of context is included pad = int(np.linalg.norm(br - ul) / 2 - float(br[1] - ul[1]) / 2) if not rot == 0: ul -= pad br += pad new_shape = [br[1] - ul[1], br[0] - ul[0]] # [y, x] if len(img.shape) &gt; 2: new_shape += [img.shape[2]] new_img = np.zeros(new_shape, dtype=np.float32) # Range to fill new array new_x = max(0, -ul[0]), min(br[0], img.shape[1]) - ul[0] new_y = max(0, -ul[1]), min(br[1], img.shape[0]) - ul[1] # Range to sample from original image old_x = max(0, ul[0]), min(img.shape[1], br[0]) old_y = max(0, ul[1]), min(img.shape[0], br[1]) new_img[new_y[0]:new_y[1], new_x[0]:new_x[1]] = img[old_y[0]:old_y[1], old_x[0]:old_x[1]] if not rot == 0: # Remove padding new_img = transform.rotate(new_img, rot) new_img = new_img[pad:-pad, pad:-pad] new_img = cv2.resize(new_img, output_size) return new_img . import os import random import torch import torch.utils.data as data import pandas as pd import numpy as np class FaceLandmarks(data.Dataset): def __init__(self, df, data_root, img_size, data_type, is_train=False): self.is_train = is_train self.data_root = data_root self.img_size = img_size self.sigma = 1.5 self.scale_factor = 0.25 self.rot_factor = 30 self.flip = True self.data_type = data_type # load annotations self.df = df self.mean = np.array([0.485, 0.456, 0.406], dtype=np.float32) self.std = np.array([0.229, 0.224, 0.225], dtype=np.float32) def __len__(self): return len(self.df) def __getitem__(self, idx): image_path = os.path.join(self.data_root, self.df.iloc[idx, 0]) scale = self.df.iloc[idx, 1] center_w = self.df.iloc[idx, 2] center_h = self.df.iloc[idx, 3] center = torch.Tensor([center_w, center_h]) pts = self.df.iloc[idx, 4:].values pts = pts.astype(&#39;float32&#39;).reshape(-1, 2) scale *= 1.25 img = cv2.imread(image_path, cv2.IMREAD_COLOR) img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) r = 0 if self.is_train: scale = scale * (random.uniform(1 - self.scale_factor, 1 + self.scale_factor)) r = random.uniform(-self.rot_factor, self.rot_factor) if random.random() &lt;= 0.6 else 0 if random.random() &lt;= 0.5 and self.flip: img = np.fliplr(img) pts = fliplr_joints(pts, width=img.shape[1], dataset=self.data_type) center[0] = img.shape[1] - center[0] img = crop(img, center, scale, self.img_size, rot=r) nparts = pts.shape[0] for i in range(nparts): pts[i, 0:2] = transform_pixel(pts[i, 0:2]+1, center, scale, self.img_size, rot=r) # pts = torch.from_numpy(pts/self.img_size) pts = torch.from_numpy(pts*2/self.img_size-1) pts = pts.float() img = img.astype(np.float32) img = (img/255.0 - self.mean) / self.std img = torch.from_numpy(img.transpose([2, 0, 1])) center = torch.Tensor(center) return img, pts . img_size = (224, 224) train_dataset = FaceLandmarks(train_df, data_path/data_root, img_size, data_type, is_train=True) test_dataset = FaceLandmarks(test_df, data_path/data_root, img_size, data_type, is_train=False) . import matplotlib.pyplot as plt import cv2 def vis_points(image, points, diameter=15): points = np.round((points+1)*img_size/2) image = image*(0.229, 0.224, 0.225)+(0.485, 0.456, 0.406) if len(points.shape) != 2: points = points.reshape(-1, 2) plt.imshow(image) plt.scatter(points[:, 0], points[:, 1], s=10, marker=&#39;.&#39;, c=&#39;r&#39;) plt.pause(0.001) # pause a bit so that plots are updated # img, pts = test_dataset[534] # 463 534 img, pts = train_dataset[462] vis_points(img.numpy().transpose(1,2,0), pts.numpy()) . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . train_dataloader = data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True) test_dataloader = data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True) . from pytorch_lightning.metrics.metric import TensorMetric import torch class NME(TensorMetric): def forward(self, y_hat, y): assert len(y.shape)==3, y.shape y_hat = y_hat.view(-1, y.shape[1], y.shape[2]) error_sum = 0 L = y.shape[1] # points/2 N = y.shape[0] # batch size for i in range(N): pts_pred = y_hat[i] pts_gt = y[i] if L == 68: #300w left = pts_gt[36:42].mean(0) right = pts_gt[42:48].mean(0) interpupil = torch.norm(left - right) # interocular = np.linalg.norm(pts_gt[36, ] - pts_gt[45, ]) elif L == 98: interpupil = torch.norm(pts_gt[96] - pts_gt[97]) # interocular = torch.norm(pts_gt[60, ] - pts_gt[72, ]) else: raise ValueError(&#39;Number of landmarks is wrong&#39;) error_sum += torch.sum(torch.norm(pts_pred - pts_gt, dim=1)) / (interpupil * y.shape[1]) return error_sum/y.shape[0] . import pytorch_lightning as pl import torch import torch.nn as nn import torch.nn.functional as F from torch.optim.lr_scheduler import ReduceLROnPlateau import torchvision.models as models class CNN6(nn.Module): def __init__(self, L=68): super().__init__() self.conv1 = nn.Conv2d(3, 32, 3, padding=1) self.conv2 = nn.Conv2d(32, 64, 3, padding=1) self.conv3 = nn.Conv2d(64, 128, 3, padding=1) self.conv4 = nn.Conv2d(128, 256, 3, padding=1) self.conv5 = nn.Conv2d(256, 512, 3, padding=1) self.fc1 = nn.Linear(512 * 2 * 2, 1024) self.fc2 = nn.Linear(1024, L*2) def forward(self, x): # input shape (3,64,64) x = F.max_pool2d(F.relu(self.conv1(x)), 2) x = F.max_pool2d(F.relu(self.conv2(x)), 2) x = F.max_pool2d(F.relu(self.conv3(x)), 2) x = F.max_pool2d(F.relu(self.conv4(x)), 2) x = F.max_pool2d(F.relu(self.conv5(x)), 2) x = F.adaptive_avg_pool2d(x, 2) x = x.view(-1, 512 * 2 * 2) x = F.relu(self.fc1(x)) x = self.fc2(x) # output shape(2 * L) return x class CNN7(nn.Module): def __init__(self, L=68): super().__init__() self.conv1 = nn.Conv2d(3, 64, 3, padding=1) self.conv2 = nn.Conv2d(64, 64, 3, padding=1) self.conv3 = nn.Conv2d(64, 128, 3, padding=1) self.conv4 = nn.Conv2d(128, 256, 3, padding=1) self.conv5 = nn.Conv2d(256, 512, 3, padding=1) self.conv6 = nn.Conv2d(512, 512, 3, padding=1) self.fc1 = nn.Linear(512 * 2 * 2, 1024) self.fc2 = nn.Linear(1024, L*2) def forward(self, x): # input shape (3,128,128) x = F.max_pool2d(F.relu(self.conv1(x)), 2) x = F.max_pool2d(F.relu(self.conv2(x)), 2) x = F.max_pool2d(F.relu(self.conv3(x)), 2) x = F.max_pool2d(F.relu(self.conv4(x)), 2) x = F.max_pool2d(F.relu(self.conv5(x)), 2) x = F.max_pool2d(F.relu(self.conv6(x)), 2) x = F.adaptive_avg_pool2d(x, 2) x = x.view(-1, 512 * 2 * 2) x = F.relu(self.fc1(x)) x = self.fc2(x) # output shape(2 * L) return x class FaceModel(pl.LightningModule): def __init__(self, net_name, L=68, freeze=False): super().__init__() self.save_hyperparameters() # self.loss = WingLoss(15, 3) self.loss = nn.SmoothL1Loss() if net_name == &#39;cnn6&#39;: self.net = CNN6(L) elif net_name == &#39;resnet&#39;: net = models.resnet50(pretrained=True) if freeze: for param in net.parameters(): param.requires_grad = False net.fc = nn.Linear(net.fc.in_features, L*2) self.net = net elif net_name == &#39;cnn7&#39;: self.net = CNN7(L) self.loss = WingLoss(15, 3) else: print(&#39;no net&#39;) self.metric = NME(&#39;nme&#39;) def forward(self, x): return self.net(x) def training_step(self, batch, batch_nb): x, y = batch y_hat = self(x) y = y.view(y.shape[0], -1) loss = self.loss(y_hat, y) tensorboard_logs = {&#39;train_loss&#39;: loss} return {&#39;loss&#39;: loss, &#39;log&#39;: tensorboard_logs} def validation_step(self, batch, batch_nb): x, y = batch x = x.float() y = y.float() y_hat = self(x) nme = self.metric(y_hat, y) y = y.view(y.shape[0], -1) loss = self.loss(y_hat, y) return {&#39;val_loss&#39;: loss, &#39;nme&#39;: nme} def validation_epoch_end(self, outputs): avg_loss = torch.stack([x[&#39;val_loss&#39;] for x in outputs]).mean() avg_nme = torch.stack([x[&#39;nme&#39;] for x in outputs]).mean() tensorboard_logs = {&#39;val_loss&#39;: avg_loss, &#39;nme&#39;: avg_nme} return {&#39;val_loss&#39;: avg_loss, &#39;log&#39;: tensorboard_logs} def test_step(self, batch, batch_nb): x, y = batch y_hat = self(x) nme = self.metric(y_hat, y) y = y.view(y.shape[0], -1) loss = self.loss(y_hat, y) return {&#39;test_loss&#39;: loss, &#39;nme&#39;: nme} def test_epoch_end(self, outputs): # OPTIONAL avg_loss = torch.stack([x[&#39;test_loss&#39;] for x in outputs]).mean() avg_nme = torch.stack([x[&#39;nme&#39;] for x in outputs]).mean() logs = {&#39;test_loss&#39;: avg_loss, &#39;nme&#39;: avg_nme} return {&#39;test_loss&#39;: avg_loss, &#39;log&#39;: logs, &#39;progress_bar&#39;: logs} def configure_optimizers(self): optimizer = torch.optim.SGD(self.parameters(), lr=1e-2, momentum=0.9, weight_decay=5e-4) # optimizer = torch.optim.Adam(net.parameters(), lr = 0.001) scheduler = ReduceLROnPlateau(optimizer, patience=10) return [optimizer], [scheduler] . model = FaceModel(net_name=&#39;resnet&#39;, L=68, freeze=True) lr_logger = pl.callbacks.LearningRateLogger() # trainer = pl.Trainer(gpus=1, fast_dev_run=True) trainer = pl.Trainer(gpus=1, max_steps=5000, callbacks=[lr_logger]) trainer.fit(model, train_dataloader=train_dataloader, val_dataloaders=test_dataloader) . model.unfreeze() lr_logger = pl.callbacks.LearningRateLogger() trainer = pl.Trainer(gpus=1, max_steps=40000, callbacks=[lr_logger]) trainer.fit(model, train_dataloader=train_dataloader, val_dataloaders=test_dataloader) . GPU available: True, used: True TPU available: False, using: 0 TPU cores CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params - 0 | loss | SmoothL1Loss | 0 1 | net | ResNet | 23 M 2 | metric | NME | 0 . model = FaceModel.load_from_checkpoint(checkpoint_path=&quot;lightning_logs/version_5/checkpoints/epoch=236.ckpt&quot;) trainer = pl.Trainer(gpus=1) trainer.test(model, test_dataloaders=test_dataloader) # trainer.test(model, test_dataloaders=chatest_dataloader) . GPU available: True, used: True TPU available: False, using: 0 TPU cores CUDA_VISIBLE_DEVICES: [0] . -- TEST RESULTS {&#39;nme&#39;: tensor(0.0620), &#39;test_loss&#39;: tensor(0.0006, device=&#39;cuda:0&#39;)} -- . {&#39;test_loss&#39;: 0.0006441270234063268, &#39;nme&#39;: 0.06202881038188934} . image, landmarks = test_dataset[8] nme = NME(&#39;my_nme&#39;) vis_points(image.numpy().transpose(1,2,0), landmarks.numpy()) model.eval() with torch.no_grad(): pred = model(image[None].to(model.device)) vis_points(image.numpy().transpose(1,2,0), pred.view(-1, 2).cpu().numpy()) print(nme(pred.cpu(), landmarks[None])) . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . tensor(0.0543) . from pytorch_lightning.core.memory import ModelSummary model = FaceModel(net_name=&#39;cnn7&#39;) model.example_input_array = torch.randn(8, 3, 128, 128) ModelSummary(model, mode=&#39;full&#39;) . | Name | Type | Params | In sizes | Out sizes - 0 | loss | WingLoss | 0 | ? | ? 1 | net | CNN7 | 6 M | [8, 3, 128, 128] | [8, 136] 2 | net.conv1 | Conv2d | 1 K | [8, 3, 128, 128] | [8, 64, 128, 128] 3 | net.conv2 | Conv2d | 36 K | [8, 64, 64, 64] | [8, 64, 64, 64] 4 | net.conv3 | Conv2d | 73 K | [8, 64, 32, 32] | [8, 128, 32, 32] 5 | net.conv4 | Conv2d | 295 K | [8, 128, 16, 16] | [8, 256, 16, 16] 6 | net.conv5 | Conv2d | 1 M | [8, 256, 8, 8] | [8, 512, 8, 8] 7 | net.conv6 | Conv2d | 2 M | [8, 512, 4, 4] | [8, 512, 4, 4] 8 | net.fc1 | Linear | 2 M | [8, 2048] | [8, 1024] 9 | net.fc2 | Linear | 139 K | [8, 1024] | [8, 136] 10 | metric | NME | 0 | ? | ? . !rm -rf lightning_logs/version_6 .",
            "url": "https://invisprints.github.io/blog/jupyter/fastpages/2020/09/06/Wingloss.html",
            "relUrl": "/jupyter/fastpages/2020/09/06/Wingloss.html",
            "date": " • Sep 6, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "人脸关键点检测",
            "content": "人脸关键点检测 . 人脸关键点的目标在于确定预先定义的关键点的位置，如鼻尖、眼角、眉毛等。可靠的关键点是许多复杂视觉任务的基础，它在 3D 人脸重建、人脸姿态估计、人脸识别等领域有重要作用。由于人脸有着复杂的变化，如光照与头部姿势，肤色与脸部表情等，关键点检测仍具有挑战性。 . 常用数据集介绍 . 300W 简介 . 300W 是一个包含 LFPW，HELEN，AFW 和 IBUG 的复合数据集，每张人脸含有68个关键点。通常将 AFW 的全部图片和 LFPW 与 HELEN 的训练图片当作训练数据，共 3148 张图片。IBUG 的全部图片和 LFPW 与 HELEN 的测试图片当作测试数据，共689张图片。其中来自 LFPW 与 HELEN 的被划分为普通测试集，来自 IBUG 被当作高难度测试集 300 Faces In-the-Wild Challenge 300W 关键点定义 . WFLW 简介 . WFLW 数据集包含10000张人脸，其中7500张为训练数据，2500张为测试数据。图片来源于 WIDER FACE 数据集，每张人脸上有98个关键点。测试数据包含姿态、表情、光照、遮挡等多个子类。 WFLW关键点定义 . WingLoss . Wing Loss for Robust Facial Landmark Localisation with Convolutional Neural Networks 这是一篇于2017年11月发表在 arXiv.org 上的论文，不同于之前广泛研究的级联网络，这篇文章对 loss function 函数下手，是第一篇在人脸对齐上研究损失函数的论文。由于这篇文章相对简单，非常适合作为人脸关键点检测的入门材料。 . 论文具体内容请阅读原文或上网搜素，这里不再赘述。 . WingLoss 复现 . 请跳转到下一篇博文 . 参考材料 . Wing Loss for Robust Facial Landmark Localisation with Convolutional Neural Networks 深度学习之人脸图像处理 .",
            "url": "https://invisprints.github.io/blog/computer%20vision/keypoints/2020/09/06/Facial-Landmark.html",
            "relUrl": "/computer%20vision/keypoints/2020/09/06/Facial-Landmark.html",
            "date": " • Sep 6, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "自编 code server",
            "content": "code server 已经有相当一段时间没有发布编译版本，最近的一次 release 在6月5日。 这段期间 VS Code 已经到 1.47 了，因此我自己编译了 code server，这对编译 vscode 也有不少借鉴意义。 . 搭建环境 . 首先按照 VS Code 编译环境要求 配置相应环境，要注意 python 的版本是 2.7， python 3 是无法编译 VS Code 的。 另外按照说明有可能会漏掉pkg-config包，这个也需安装好 . sudo apt install pkg-config . 然后按照 code server 的要求配置好其余的环境，基本上就可以到位了。 . 网络问题 . 只有国内网是很难编译成功的，建议编译时开启随意访问国外的网站的权限。 . release . code server 我自己编译的 release 在这里下载 .",
            "url": "https://invisprints.github.io/blog/apps/2020/08/09/code-server.html",
            "relUrl": "/apps/2020/08/09/code-server.html",
            "date": " • Aug 9, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "1Password 使用技巧",
            "content": "1Password 是一款非常好用的密码管理软件，虽然有着高昂的订阅价格，但其美观的设计和丰富的功能吸引了大批忠实用户。 有关密码管理软件的好坏这里就不再讨论，这篇文章主要来讲一下 1Password 在桌面端的使用技巧。 . 浏览器自动填充 . 这个我就不用说了，相关的入门介绍多如牛毛。 . 本地应用的密码提示 . 很多本地应用也需要我们进行登录使用，经常使用 1Password 的老用户会发现 1Password 会识别某些本地 App，这让从不记密码的我们能快速登录这些软件。 如在打开 App Store 后，点击 1Password mini 能自动显示我们的 Apple ID。 . 但很多时候我们发现 1Password 并不能自动识别，如打开 setapp 后，mini 里面空空如也 . 但细心人发现在 mini 的建议栏中，1Password 其实已经认出这是 setapp 了，只是它还没有将这个 setapp 与我们账号中的 setapp 账号对上号。 . 根据 reddit 论坛 的提示，我们需创建一个 URL scheme 链接来指向这个 App， 1Password 方能将账号密码和这个 App 对应上。URL scheme的功能与网址类似，一个记录网上网页的地址，一个记录本地 App 的地址。 . 查找本地 APP 的包名 . 打开终端，输入以下命令 . osascript -e &#39;id of app &quot;App Name&quot;&#39; . 比如对于 setapp，我们就输入如下命令 . osascript -e &#39;id of app &quot;setapp&quot;&#39; com.setapp.DesktopClient . 得到的 com.setapp.DesktopClient 就是这个 App 的包名了。 . 有了 App 的包名，我们便可以在 1Password 中添加它的链接 . app://com.setapp.DesktopClient . . 这样下次再打开 setapp 时，1Password 就能找出当前 App 所对应的账号密码了 .",
            "url": "https://invisprints.github.io/blog/apps/2020/08/03/1password-tricks.html",
            "relUrl": "/apps/2020/08/03/1password-tricks.html",
            "date": " • Aug 3, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Windows 开发软件推荐",
            "content": "终端工具 . mobaxterm . MobaXterm free Xserver and tabbed SSH client for Windows 功能非常全面的终端工具，putty 的最佳替代品 . WSL 2 . WSL 2 是个运行在 Windows 下的 Linux 子系统，WSL 2 已经非常接近于原生 Linux 系统，拿来做终端绰绰有余。要求较新的 Windows 10 . Windows Terminal . microsoft/terminal 如果觉得用 WSL2 跑终端小题大做的话，微软家的 Windows Terminal 是个不错的选择，有很多方便易用的功能。要求较新的 Windows 10 . Termius . Termius 这个似乎是收费版才好用，不过可以用 GitHub 学生包嫖到毕业。优点是跨平台同步各种远程连接配置，支持移动端（iOS &amp; Android） .",
            "url": "https://invisprints.github.io/blog/apps/2020/08/02/windows-dev-software.html",
            "relUrl": "/apps/2020/08/02/windows-dev-software.html",
            "date": " • Aug 2, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "用 Pycharm 进行远程调试",
            "content": "官方说明 . Remote Debugging with PyCharm . 官网详细介绍了如何在本地创建项目，上传本地项目并在远程服务器上调试运行。但对于服务器上已有项目，并没有明确提到该如何操作。 . 调试服务器上的代码 . 其实方法很简单，在按着上述官网教程创建新项目，在新建项目时选择远程 python 解释器环境环境。之后在 setting 设置检查解释器是否设置正确，没有问题的话找到 Build, Execution, Deployment 节点，在 Deployment 标签页中设置好连接选项（一般就是修改下root path），然后在mappings中将远程路径指向远程项目所在路径。 . 待 pycharm 建立好本地与远程的映射关系后，在 Tools-Deployment 中选择 Download from，这样就可以把远程代码同步到本地。 .",
            "url": "https://invisprints.github.io/blog/pycharm/2020/08/02/pycharm-remote.html",
            "relUrl": "/pycharm/2020/08/02/pycharm-remote.html",
            "date": " • Aug 2, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "远程连接 Jupyter lab/notebook",
            "content": "直接连接 . 首先运行远程的 Jupyter Lab 或者 Jupyter Notebook . jupyter-lab --no-browser --port=port_num To access the notebook, open this file in a browser: file:///xxxxxxxxxxxxxxxxxxxxx.html Or copy and paste one of these URLs: http://localhost:port_num/?token=jupyterlab_token . 此时记下 jupyter 的地址 . 然后 ssh 端口转发。目标端口要和 jupyter 的端口一致 . ssh -f usr@remote_server -N -L port_num:localhost:port_num . -L 端口转发 本地网卡地址(可省):本地端口:目标地址:目标端口 . -N 不执行远程命令. 用于转发端口 . -f 要求 在执行命令前退至后台 . 在本地浏览器中打开之前记下的 jupyter 地址，即可使用 JupyterLab。 . 跳转连接 . （未测试） 有时需要先登录某个中转服务器，才能登录到你想要的服务器。这时候与前者类似，只是需要多建立一层ssh连接。首先建立与中转服务器的连接 . ssh -f usr@remote_serverA -N -L port_num:localhost:port_num . 然后登录中转服务器，建立与目标服务器的连接 . ssh -X usr@remote_serverA (remote_serverA) $ ssh -f usr@remote_serverB -N -L port_num:localhost:port_num . 登录目标服务器，运行JupyterLab . (remote_serverA) $ ssh -X usr@remote_serverB (remote_serverB) $ jupyter-lab --no-browser --port=port_num . 最后在本地浏览器打开网址。 .",
            "url": "https://invisprints.github.io/blog/jupyter/2020/08/02/jupyter-remote.html",
            "relUrl": "/jupyter/2020/08/02/jupyter-remote.html",
            "date": " • Aug 2, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "Motrix 1.5.7 自编译版本",
            "content": ". Important: Motrix 虽然在快速开发中，但不知什么原因迟迟没有发布最新版，截止目前(2020-05-04)，Motrix 的预编译版本仍在 2019-06-24 的 1.4.1 版本，而 master 分支其实已经开发到 1.5.7 版本了。 . 下面提供我在 macOS 和 Ubuntu 平台下编译的 Motrix . 下载界面 . P.S. Motrix 作者似乎想搞 GitHub Action 自动 release Motrix 软件包，但不知什么原因没有 work，有能力的小伙伴可以去提交 PR。 .",
            "url": "https://invisprints.github.io/blog/apps/2020/05/04/motrix.html",
            "relUrl": "/apps/2020/05/04/motrix.html",
            "date": " • May 4, 2020"
        }
        
    
  
    
        ,"post10": {
            "title": "常用软件邀请链接",
            "content": "常用软件邀请链接 . 使用邀请链接注册，能获得更多优惠或更长试用期限 . oneDrive . 邀请链接 . 幕布 . 邀请链接 . 滴答清单 . 微信邀请链接 . 语雀 . 点击链接快来和我一起加入语雀文档，体验全新知识创作，让你的协作更高效！ .",
            "url": "https://invisprints.github.io/blog/apps/2020/04/27/invite-link.html",
            "relUrl": "/apps/2020/04/27/invite-link.html",
            "date": " • Apr 27, 2020"
        }
        
    
  
    
        ,"post11": {
            "title": "Vim 搭建教程",
            "content": "Vim 搭建教程 . 号称编辑器之神的 Vim 有着极为强大的扩展能力和陡峭的学习曲线，本文在尽可能少装插件的情况下打造较为舒适的 Vim 开发环境。 . 本文理念 . 在开始前先回答下面几个问题，也是写本篇博文的理念。 . 为什么用 Vim | 为什么用 Vim 8 | . 目前编辑器领域百花齐放，VS Code 的表现尤其亮眼，为什么我们还要用 Vim 呢？ 其实目前仍有部分领域是 Vim 擅长而 VS Code 和 Sublime 3 之类不擅长的——比如 ssh 远程编辑。本篇博文的目的也是打造适合远程编辑的 Vim 环境。至于其他领域，VS Code 不香吗？ . 关注 Vim 的人也应该知道，NeoVim 在近几年的表现尤为亮眼，但是本文并不打算采用 NeoVim 作为远程开发环境。原因有二，一是 NeoVim 尚不稳定，还处于快速开发期，在工业场景下还是成熟的 Vim 8 更为可靠；二是 NeoVim 目前配置比较复杂，等普通人配置好了我都可以拿 VS Code 远程编辑了，不够轻量。这也是为什么我们不打算装太多插件的原因，IDE 不香吗？ . 搭建 . 下载.vimrc配置文件 | 安装 Plug 插件管理器 | 安装插件 | 开始远程编辑 | 这是笔者多年经验精简下来的.vimrc配置文件，没有多余的快捷键配置，零上手难度。 . &quot; Configuration file for vim &quot; Normally we use vim-extensions. If you want true vi-compatibility &quot; remove change the following statements set nocompatible &quot; 去除VI一致性,必须 &quot;===========设置包括vundle========= call plug#begin(&#39;~/.vim/plugged&#39;) &quot; Github上的插件 &quot; 格式为 Plug &#39;用户名/插件仓库名&#39; Plug &#39;majutsushi/tagbar&#39; Plug &#39;joshdick/onedark.vim&#39; Plug &#39;neoclide/coc.nvim&#39;, {&#39;branch&#39;: &#39;release&#39;} &quot; 你的所有插件需要在下面这行之前 call plug#end() &quot; 必须 &quot; &quot; 简要帮助文档 &quot; :PluginList - 列出所有已配置的插件 &quot; :PluginInstall - 安装插件,追加 `!` 用以更新或使用 :PluginUpdate &quot; :PluginSearch foo - 搜索 foo ; 追加 `!` 清除本地缓存 &quot; :PluginClean - 清除未使用插件,需要确认; 追加 `!` 自动批准移除未使用插件 &quot;=======主题等设置======== syntax on colorscheme onedark set hlsearch &quot;高亮匹配项 set autoindent &quot; always set autoindenting on set nu &quot; 显示行号 set relativenumber &quot; 相对行号 set showmatch &quot; 设置匹配模式，显示匹配的括号 set tabstop=4 &quot; 设置制表符(tab键)的宽度 set softtabstop=4 &quot; 设置软制表符的宽度 set shiftwidth=4 &quot; (自动) 缩进使用的4个空格 set scrolloff=3 &quot;保持最后3行可见 set guifont=SourceCodeProForPowerline-Regular:h16 set backspace=indent,eol,start set cursorline &quot;高亮当前行 set cursorcolumn &quot;高亮当前列 &quot;=====系统设置===== set foldmethod=indent &quot;使用缩进定义代码折叠 set foldlevelstart=99 &quot;默认代码不折叠 &quot;set tags=tags; &quot;不断递归向上查找tags set showcmd &quot;显示正在输入的命令 set clipboard=unnamed &quot;共用系统剪贴板 ubuntu:unnamedplus set fileencodings=ucs-bom,utf-8,cp936,gb18030,big5,euc-jp,euc-kr,latin1 &quot;===插件配置==== &quot;====tagbar nmap &lt;F8&gt; :TagbarToggle&lt;CR&gt; let g:tagbar_auto_faocus=1 . 插件只有3个，tagbar 是显示代码类和变量的查看器，需要配合 ctags 使用，ctags 安装也很简单，ctags 安装教程 onedark 是一个 vim 配色方案，读者也可按照自己的喜好选择。 coc.nvim 是自动补全平台插件，不过我发现自带的通用补全已经很不错了，需要安装 Nodejs . 所有的配置都有注释，已经算是很容易理解的了。有人说 SpaceVim 也很简单啊，当然如果读者熟悉 SpaceVim 的话我也很推荐。能简单就不要复杂，能自动化就不要手动操作。 . Plug 的安装和使用参看 plug 安装教程 . 总结 . 笔者接触 Vim 8年有余，从最开始的把 Vim 打造成 IDE 到后来的用 Vim 建立 QQ 聊天框，折腾了一圈下来发现自己并没有什么收获，反而是在挖掘各种奇技淫巧方案耗费了大量时间。Vim 并不是什么 IDE 之神或者 Linux 高手标志，它只是处理文件的利器而已。因此相比于装一堆插件或写超长配置把 Vim 打造成 IDE，还不如在 IDE 里装个 Vim 插件来的省时省力。当然这是我个人的想法，读者完全可以按照自己的兴趣打造自己的 Vim，毕竟这是 Vim 的魅力所在。 .",
            "url": "https://invisprints.github.io/blog/vim/2020/04/25/vim-tutorial.html",
            "relUrl": "/vim/2020/04/25/vim-tutorial.html",
            "date": " • Apr 25, 2020"
        }
        
    
  
    
        ,"post12": {
            "title": "Vim: 小技巧",
            "content": "Vim: 小技巧 . [toc] . 最近发现这篇 readme 是学 Vim 小技巧的神器，强烈建议参考 . Linux下去掉 ^M . vi filename | :%s/ ^M//g | ^M 输入方法： ctrl+V ,ctrl+M | 若要将^M换成回车，则输入下面语句 . :%s/^M/[ctrl-v]+[enter]/g . 或 . :%s/^M/ r/g . 若想查找回车，用户 n代替 r。 . 转换文件格式 . 通过输入下面命令查看 vim 支持格式： . set fileformats . 转换： dos-&gt;unix: . set ff=unix . unix-&gt;dos: . set ff=dos . 自动补全 . &lt;Ctrl-x&gt;&lt;Ctrl-k&gt;:字典查找 需要运行`:set spell`启动补全 &lt;Ctrl-x&gt;&lt;Ctrl-l&gt;：整行补全 . 代码折叠 . vim中自带了代码折叠功能。 配置foldmethod可以定义折叠方式，有6种可选方式： . manual //手工定义折叠 | indent //用缩进表示折叠 | expr　 //用表达式来定义折叠 | syntax //用语法高亮来定义折叠 | diff //对没有更改的文本进行折叠 | marker //用标志折叠 | 我选用syntax来定义折叠，这种方式比较简单，但是当配置完这个值后，你打开代码，就会发现vim默认把所有代码都折叠了，这显然不是我想要的，设置foldlevelstart为99后，打开默认没有折叠。 . &quot;使用语法高亮定义代码折叠 set foldmethod=syntax &quot;打开文件是默认不折叠代码 set foldlevelstart=99 . 这里提供最简单的折叠命令： zc 关闭折叠 zo 打开折叠 za 打开/关闭折叠互相切换 . 不离开插入模式，粘贴寄存器中的内容 . &lt;C-r&gt;0 . 深入理解寄存器 . 所有复制的内容，不仅被复制到了无名寄存器”“,还被复制到复制专用寄存器”0. . 转换单词大小写 . :guaw :gUaw . 替换 . ：%s/[1]/[2]/gc %：范围为整个文件，否则为当前行 [1]:查找内容，为空则为上次查找的内容 [2]:替换内容 g：作用于一行所有匹配项，否则为一行第一项 c：手动确认 . 文本排序 . 假设对下面内容进行排序 . first name,last name,email john,smith,john@example.com drew,neil,drew@vimcasts.org jane,doe,jane@example.com . 假设我们想基于第二个字段”last name”来重排这些记录。我们可以用-t&#39;,&#39; k2参数进行排序（有关sort的具体命令请在命令行输入man sort查阅），由于文件的第一行是标题信息，我们想把它们保留的文件顶部，因此需要用到范围:2,$指定范围 . :2,$!sort -t&#39;,&#39; -k2 . 相关知识 . 这个是在vim中运行Shell命令的一个用法。当给定一个范围时，:!{cmd}命令具有特殊含义，由[range]所指定的行会传给{cmd}作为标准输入，又会用{cmd}的输出覆盖[range]内原本的内容 . 数字加减 . 在普通模式下光标指向该数字，按 . ctrl-a //加1 ctrl-x //减1 . 选中单词 . aw这个命令可以表示选中单词的意思，如 复制单词 . yaw . 转换大写 . gUaw . vim多文件搜索字符串 . vimgrep . vim自带的vimgrep命令除了搜索速度慢，其他的都很好用 vimgrep命令格式如下: . vimgrep /搜索字符串/gj 文件 . 上面的g和j参数都是可选的, . /g : 加上g参数的话, 如果一行有多个匹配, 那么这些匹配会都出现在搜索结果里, 所以一般不用加/g参数; | /j : 如果不加j参数, 执行完vimgrep会自动跳转到第一个匹配处, 所以一般都会加上/j参数; | . 比如vimgrep /keyword/j *.php表示仅在当前目录下的所有php文件里搜索”keyword”, 且不自动跳转到搜索结果. 如果也要在子目录递归搜索, **表示在当前目录以及子目录递归, 比如**/*.php . 一些栗子: . 当前目录下递归搜索: vimgrep /字符串/j **/*.php | 仅当前目录, 不递归: vimgrep /字符串/g *.php | 如果要搜索多个文件扩展名, 用空格分开即可: vimgrep /字符串/j **/*.cpp **/*.php | Linux绝对路径, 递归搜索: vimgrep /字符串/j /home/user/**/*.cpp | Win绝对路径, 递归搜索: vimgrep /字符串/j D: home user/**/*.cpp | . 搜索完成后vim会将搜索结果存放在quickfix中，输入命令:cw即可打开quickfix . 搜索 . 不区分大小写 . 在最后面添加 c，如 . /goodday c . 就可以搜索到GoodDay，goodday等字符串 .",
            "url": "https://invisprints.github.io/blog/vim/2020/04/25/Vim-tricks.html",
            "relUrl": "/vim/2020/04/25/Vim-tricks.html",
            "date": " • Apr 25, 2020"
        }
        
    
  
    
        ,"post13": {
            "title": "LSTM 模型预测 A 股走势",
            "content": "LSTM &#27169;&#22411;&#39044;&#27979; A &#32929;&#36208;&#21183; . 这几天闲来无事，看网上很多人都在评论股市的起起伏伏，于是心血来潮，想用深度学习看看能否预测股票走势。由于之前研究方向都是 CV 和 NAS，也想借用这个机会深入了解下 RNN 这个派系是怎么回事。 . 数日后 . . 经过我多日的观察，LSTM 似乎并不能预测 A 股走势。当然由于我在这方面还是初学者，所以代码有可能存在问题，欢迎大家指出！ . &#19979;&#36733;&#25968;&#25454;&#38598; . 证券宝 www.baostock.com 是一个免费、开源的证券数据平台（无需注册）。其优点请访问官网 . 取消下面代码注释来安装 baostock 库 . . 按照官网教程下载一只股票的k线数据，这里取sz.002648 15年以后的数据。 . import baostock as bs import pandas as pd #### 登陆系统 #### lg = bs.login() #### 获取沪深A股历史K线数据 #### # 详细指标参数，参见“历史行情指标参数”章节；“分钟线”参数与“日线”参数不同。 # 分钟线指标：date,time,code,open,high,low,close,volume,amount,adjustflag rs = bs.query_history_k_data_plus(&quot;sz.002648&quot;, &quot;date,code,open,high,low,close,preclose,volume,amount,adjustflag,turn,tradestatus,pctChg,isST&quot;, start_date=&#39;2015-01-01&#39;, end_date=&#39;2020-4-14&#39;, frequency=&quot;d&quot;, adjustflag=&quot;3&quot;) #### 打印结果集 #### data_list = [] while (rs.error_code == &#39;0&#39;) &amp; rs.next(): # 获取一条记录，将记录合并在一起 data_list.append(rs.get_row_data()) df = pd.DataFrame(data_list, columns=rs.fields) #### 结果集输出到csv文件 #### # result.to_csv(&quot;D: history_A_stock_k_data.csv&quot;, index=False) print(df) #### 登出系统 #### bs.logout() . login success! date code open high low close preclose 0 2015-01-05 sz.002648 12.0400 12.4700 11.8000 12.2200 12.1000 1 2015-01-06 sz.002648 12.2000 12.3600 12.0000 12.2900 12.2200 2 2015-01-07 sz.002648 12.2900 12.5600 12.2500 12.4000 12.2900 3 2015-01-08 sz.002648 12.4300 12.6300 12.3000 12.4700 12.4000 4 2015-01-09 sz.002648 12.4600 12.7400 12.3900 12.4100 12.4700 ... ... ... ... ... ... ... ... 1281 2020-04-08 sz.002648 13.7400 14.1200 13.6500 13.9700 13.8400 1282 2020-04-09 sz.002648 14.0800 14.2900 14.0300 14.1800 13.9700 1283 2020-04-10 sz.002648 14.0500 14.0500 13.5400 13.7600 14.1800 1284 2020-04-13 sz.002648 14.1900 15.1400 14.0000 14.9600 13.7600 1285 2020-04-14 sz.002648 15.0600 15.2000 14.8000 14.8900 14.9600 volume amount adjustflag turn tradestatus pctChg 0 16718083 201474357.0000 3 2.089760 1 0.991700 1 7965196 97122442.0000 3 0.995649 1 0.572800 2 7684398 95370790.0000 3 0.960550 1 0.895000 3 8056201 100447582.0000 3 1.007025 1 0.564500 4 7648582 96383568.0000 3 0.956073 1 -0.481200 ... ... ... ... ... ... ... 1281 15477705 214734917.0800 3 1.490800 1 0.939300 1282 16011717 226975113.8300 3 1.542300 1 1.503200 1283 17320147 238855999.3500 3 1.669400 1 -2.961900 1284 56552045 834440561.6200 3 5.450700 1 8.720900 1285 42736530 638906444.8700 3 4.119100 1 -0.467900 isST 0 0 1 0 2 0 3 0 4 0 ... ... 1281 0 1282 0 1283 0 1284 0 1285 0 [1286 rows x 14 columns] logout success! . &lt;baostock.data.resultset.ResultData at 0x11cdb33d0&gt; . 下载的数据都是以字符串形式保存的，我们把需要的数据转换成整数和浮点数 . float_type = [&#39;open&#39;,&#39;high&#39;,&#39;low&#39;,&#39;close&#39;,&#39;preclose&#39;,&#39;amount&#39;,&#39;pctChg&#39;] for item in float_type: df[item] = df[item].astype(&#39;float&#39;) df[&#39;amount&#39;] = df[&#39;amount&#39;].astype(&#39;int&#39;) df[&#39;volume&#39;] = df[&#39;volume&#39;].astype(&#39;int&#39;) df[&#39;turn&#39;] = [0 if x == &quot;&quot; else float(x) for x in df[&quot;turn&quot;]] df[&#39;buy_flag&#39;] = 10 # df.tail() . &#22788;&#29702;&#25968;&#25454;&#38598; . 用 LSTM 预测价格显示是不合理的，因为价格的波动非常不可控，所以我们退而求其次，预测股票的走势，即涨还是跌。 . 但是怎么量化股票的涨跌是个问题，本人之前完全没接触过股票，所以这里就想当然用未来数天的平均股价表示股票的起伏。 . def MA_next(df, date_idx, price_type, n): return df[price_type][date_idx:date_idx+n].mean() . 假设短期2天，中期6天，长期15天。如果未来15天平均价格大于未来6天平均价格大于未来2天平均价格，我们就可认为未来15天的股市走势很好。 这里还要求有3%的涨幅，能一定程度上减少标签频繁波动。 . &#39;2&#39;含义为买入，&#39;0&#39;含义为卖出，&#39;1&#39;为默认值 . s_time = 2 m_time = 6 l_time = 15 for i in range(len(df)-l_time): if MA_next(df,i,&#39;close&#39;,l_time)&gt;MA_next(df,i,&#39;close&#39;,m_time)*1.03&gt;MA_next(df,i,&#39;close&#39;,s_time)*1.03: df.loc[i, &#39;buy_flag&#39;] = 2 elif MA_next(df,i,&#39;close&#39;,s_time)&gt;MA_next(df,i,&#39;close&#39;,m_time): df.loc[i, &#39;buy_flag&#39;] = 0 else: df.loc[i, &#39;buy_flag&#39;] = 1 df.loc[i, &#39;buy_flag&#39;] = 1 + (MA_next(df,i,&#39;close&#39;,m_time)-MA_next(df,i,&#39;close&#39;,s_time))/MA_next(df,i,&#39;close&#39;,s_time) # df.loc[i, &#39;buy_flag&#39;] = 10*(MA_next(df,i,&#39;close&#39;,m_time)+MA_next(df,i,&#39;close&#39;,l_time)-2*MA_next(df,i,&#39;close&#39;,s_time))/MA_next(df,i,&#39;close&#39;,s_time) df.tail() . date code open high low close preclose volume amount adjustflag turn tradestatus pctChg isST buy_flag . 1281 2020-04-08 | sz.002648 | 13.74 | 14.12 | 13.65 | 13.97 | 13.84 | 15477705 | 214734917 | 3 | 1.4908 | 1 | 0.9393 | 0 | 10.0 | . 1282 2020-04-09 | sz.002648 | 14.08 | 14.29 | 14.03 | 14.18 | 13.97 | 16011717 | 226975113 | 3 | 1.5423 | 1 | 1.5032 | 0 | 10.0 | . 1283 2020-04-10 | sz.002648 | 14.05 | 14.05 | 13.54 | 13.76 | 14.18 | 17320147 | 238855999 | 3 | 1.6694 | 1 | -2.9619 | 0 | 10.0 | . 1284 2020-04-13 | sz.002648 | 14.19 | 15.14 | 14.00 | 14.96 | 13.76 | 56552045 | 834440561 | 3 | 5.4507 | 1 | 8.7209 | 0 | 10.0 | . 1285 2020-04-14 | sz.002648 | 15.06 | 15.20 | 14.80 | 14.89 | 14.96 | 42736530 | 638906444 | 3 | 4.1191 | 1 | -0.4679 | 0 | 10.0 | . &#21487;&#35270;&#21270; . 使用 plotly 绘图 . import plotly.graph_objects as go # from IPython.display import HTML import chart_studio.plotly as py fig = go.Figure(data=[go.Candlestick(x=df[&#39;date&#39;], open=df[&#39;open&#39;], high=df[&#39;high&#39;], low=df[&#39;low&#39;], close=df[&#39;close&#39;], increasing_line_color= &#39;red&#39;, decreasing_line_color= &#39;green&#39;) ]) fig.add_trace(go.Scatter(x=df[&#39;date&#39;],y=df[&#39;buy_flag&#39;], name=&#39;Flag&#39;)) fig.update_layout( xaxis_range=[&#39;2017-01-01&#39;,&#39;2019-12-31&#39;], yaxis_title=&#39;Price&#39;, # xaxis_rangeslider_visible=False, ) py.iplot(fig, filename=&quot;stock-price&quot;) . 在 Fast.ai Part 1 课程中，提到一个能扩展日期特征的函数add_datepart，该函数能计算当前日期的年、月、日、一周第几天、周数、月初月末、一年当中的第几天等信息。我们用该函数扩展日期特征。 . from fastai.tabular import * add_datepart(df, &quot;date&quot;, drop=False) seq_length = 90 train_df = df[seq_length:-seq_length] # 丢掉不重要的特征 train_df = train_df.drop([&#39;date&#39;,&#39;code&#39;,&#39;Is_month_end&#39;, &#39;Is_month_start&#39;, &#39;Is_quarter_end&#39;, &#39;Is_quarter_start&#39;, &#39;Is_year_end&#39;, &#39;Is_year_start&#39;,&#39;Dayofyear&#39;],axis=1) train_df . open high low close preclose volume amount adjustflag turn tradestatus pctChg isST buy_flag Year Month Week Day Dayofweek Elapsed . 90 16.15 | 16.85 | 16.07 | 16.28 | 16.19 | 20654461 | 340943328 | 3 | 2.581808 | 1 | 0.5559 | 0 | 2.000000 | 2015 | 5 | 21 | 20 | 2 | 1432080000 | . 91 16.45 | 16.84 | 16.30 | 16.81 | 16.28 | 21049050 | 349775744 | 3 | 2.631131 | 1 | 3.2555 | 0 | 2.000000 | 2015 | 5 | 21 | 21 | 3 | 1432166400 | . 92 16.91 | 17.50 | 16.72 | 17.25 | 16.81 | 26445834 | 455184800 | 3 | 3.305729 | 1 | 2.6175 | 0 | 2.000000 | 2015 | 5 | 21 | 22 | 4 | 1432252800 | . 93 17.20 | 17.72 | 16.93 | 17.52 | 17.25 | 25543119 | 444374592 | 3 | 3.192890 | 1 | 1.5652 | 0 | 1.070076 | 2015 | 5 | 22 | 25 | 0 | 1432512000 | . 94 17.78 | 17.82 | 17.26 | 17.68 | 17.52 | 23197897 | 407829184 | 3 | 2.899737 | 1 | 0.9132 | 0 | 1.031780 | 2015 | 5 | 22 | 26 | 1 | 1432598400 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 1191 14.22 | 14.35 | 13.77 | 13.86 | 14.10 | 13857446 | 193912775 | 3 | 1.334800 | 1 | -1.7021 | 0 | 1.014370 | 2019 | 11 | 47 | 22 | 4 | 1574380800 | . 1192 13.92 | 14.62 | 13.91 | 14.44 | 13.86 | 33019563 | 474715627 | 3 | 3.180500 | 1 | 4.1847 | 0 | 1.012324 | 2019 | 11 | 48 | 25 | 0 | 1574640000 | . 1193 14.47 | 14.56 | 14.23 | 14.23 | 14.44 | 14896110 | 213625282 | 3 | 1.434800 | 1 | -1.4543 | 0 | 1.028050 | 2019 | 11 | 48 | 26 | 1 | 1574726400 | . 1194 14.18 | 14.54 | 14.01 | 14.29 | 14.23 | 16550049 | 236702541 | 3 | 1.594100 | 1 | 0.4216 | 0 | 1.031558 | 2019 | 11 | 48 | 27 | 2 | 1574812800 | . 1195 14.28 | 14.76 | 14.21 | 14.44 | 14.29 | 16324504 | 236742107 | 3 | 1.572400 | 1 | 1.0497 | 0 | 1.021047 | 2019 | 11 | 48 | 28 | 3 | 1574899200 | . 1106 rows × 19 columns . 接下来我们为数据生成序列，用前seq_length天的信息作为输入序列，后1天的股市起伏buy_flag作为标签 . def sliding_windows(data, label, seq_length): x = [] y = [] for i in range(len(data)-seq_length-1): _x = data[i:(i+seq_length)] _y = label[i+seq_length] x.append(_x) y.append(_y) return np.array(x),np.array(y) . 在 Pytorch 中，LSTM 默认的输入顺序是 seq_length*batch_size*feature，而我们通常生成的序列是batch_size*seq_length*feature，因此需要交换下输入数据纬度。 . from sklearn.preprocessing import MinMaxScaler import numpy as np y_scaler = MinMaxScaler() x_scaler = MinMaxScaler() #converting dataset into x_train and y_train X = train_df.drop([&#39;buy_flag&#39;],axis=1).values X = x_scaler.fit_transform(X) Y = train_df[&#39;buy_flag&#39;] Y = np.array(Y).reshape(-1,1) Y = y_scaler.fit_transform(Y) x, y = sliding_windows(X, Y, seq_length) y_train,y_test = y[:int(y.shape[0]*0.8)],y[int(y.shape[0]*0.8):] x_train,x_test = x[:int(x.shape[0]*0.8)],x[int(x.shape[0]*0.8):] # lstm: seq, batch, feature device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;) dataX = torch.Tensor(x.transpose(1,0,2)) dataY = torch.Tensor(y) trainX = torch.Tensor(x_train.transpose(1,0,2)) trainY = torch.Tensor(y_train) testX = torch.Tensor(x_test.transpose(1,0,2)) testY = torch.Tensor(y_test) trainX.shape, trainY.shape . (torch.Size([90, 812, 18]), torch.Size([812, 1])) . &#24314;&#31435; LSTM &#27169;&#22411; . class LSTM(nn.Module): def __init__(self, num_classes, input_size, hidden_size, num_layers): super(LSTM, self).__init__() self.num_classes = num_classes self.num_layers = num_layers self.input_size = input_size self.hidden_size = hidden_size self.seq_length = seq_length self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers) self.fc = nn.Linear(hidden_size, num_classes) def forward(self, x): # 不手动指定 h 和 c 的话，默认就是 0 # h_0 = torch.zeros( # self.num_layers, x.size(0), self.hidden_size) # c_0 = torch.zeros( # self.num_layers, x.size(0), self.hidden_size) # Propagate input through LSTM # ula, (h_out, _) = self.lstm(x, (h_0, c_0)) ula, (h_out, _) = self.lstm(x) h_out = h_out.view(-1, self.hidden_size) out = self.fc(h_out) return out . &#35757;&#32451;&#27169;&#22411; . num_epochs = 15 learning_rate = 0.001 input_size = train_df.shape[1]-1 # The number of expected features in the input x hidden_size = 300 # The number of features in the hidden state h num_layers = 1 # Number of recurrent layers. num_classes = 1 # output lstm = LSTM(num_classes, input_size, hidden_size, num_layers) criterion = torch.nn.MSELoss() # mean-squared error for regression optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate) #optimizer = torch.optim.SGD(lstm.parameters(), lr=learning_rate) # Train the model lstm.train() lstm.to(device) trainX = trainX.to(device) for epoch in range(num_epochs): optimizer.zero_grad() outputs = lstm(trainX) # obtain the loss function loss = criterion(outputs, trainY) loss.backward() optimizer.step() print(&quot;Epoch: %d, loss: %1.5f&quot; % (epoch, loss.item())) . Epoch: 0, loss: 0.22898 Epoch: 1, loss: 0.17325 Epoch: 2, loss: 0.14031 Epoch: 3, loss: 0.13380 Epoch: 4, loss: 0.14764 Epoch: 5, loss: 0.14571 Epoch: 6, loss: 0.13712 Epoch: 7, loss: 0.13153 Epoch: 8, loss: 0.12988 Epoch: 9, loss: 0.13052 Epoch: 10, loss: 0.13184 Epoch: 11, loss: 0.13284 Epoch: 12, loss: 0.13308 Epoch: 13, loss: 0.13251 Epoch: 14, loss: 0.13131 . &#26597;&#30475;&#35757;&#32451;&#25928;&#26524; . import plotly.graph_objects as go lstm.eval() lstm.to(torch.device(&#39;cpu&#39;)) with torch.no_grad(): dataY_pred = lstm(dataX) dataY_pred = dataY_pred.data.numpy() dataY_truth = dataY.data.numpy() dataY_pred = y_scaler.inverse_transform(dataY_pred) dataY_truth = y_scaler.inverse_transform(dataY_truth) fig = go.Figure(go.Scatter(y=dataY_truth.flatten(),name=&#39;Ground Truth&#39;)) fig.add_trace(go.Scatter(y=dataY_pred.flatten(),name=&#39;Predicted&#39;)) fig.update_layout( shapes = [dict( x0=len(x_train), x1=len(x_train), y0=0, y1=1, xref=&#39;x&#39;, yref=&#39;paper&#39;, line_width=2)], #在图上划分训练集和测试集 xaxis_rangeslider_visible=True, ) py.iplot(fig, filename=&quot;stock-result&quot;) . 发现预测值基本取标签的平均值，也就是说它并不会根据输入调整输出，而是直接输出标签的平均值，没有任何参考价值 . import random i = random.randint(0,testX.shape[1]) with torch.no_grad(): y_pred = lstm(testX[:,i,::].reshape(testX.shape[0],1,testX.shape[2])) print(&#39;预测值:{0}, 实际值:{1}&#39;.format(y_pred.data.numpy(),testY[i].reshape(-1,1))) . 预测值:[[0.288591]], 实际值:tensor([[1.]]) . &#21442;&#32771;&#36164;&#26009; . 超生动图解LSTM和GPU，一文读懂循环神经网络！ . LSTM细节分析理解（pytorch版） .",
            "url": "https://invisprints.github.io/blog/pytorch/stock/lstm/2020/04/17/LSTM-stock.html",
            "relUrl": "/pytorch/stock/lstm/2020/04/17/LSTM-stock.html",
            "date": " • Apr 17, 2020"
        }
        
    
  
    
        ,"post14": {
            "title": "subconverter 实用案例",
            "content": "subconverter . subconverter 是在各种订阅格式之间进行转换的实用程序 . 本文已更新到兼容 subconverter v0.6.4，更新日期 2020-11-08 . github 项目地址 . 公共 API . 常用案例 . 关于 subconverter 的用法在 readme 中已经给出详细的说明与部分简单用法了，本文将继续扩充一些 readme 中没有涉及到的 example。 . 云端运行 . readme 中介绍了大量本地运行的情况，但是对于众多用户来说我们并不希望在本地一直运行着 subconverter，我们希望有个云端 API。每当我们更新云端数据时，所有的更新就会自动 update 到我们的手机、电脑、路由器中，十分方便。 . 最简单的方法是使用公共 API，但有些人担心隐私机场泄漏问题，因此我们需要自己搭建一个云端转换器。 . Heroku 是一个在云端部署 web app 的平台，它托管于 Amazon 云且与 Github 深度集成。 subconverter 作者也提供了一键部署到 Herokuapp 的模版 heroku-subconverter，这里你可以一键部署到你的 Heroku 平台上，然后就可以使用 subconverter readme 中的简易用法。 . 但简易用法的链接通常十分冗长且难以记忆，在出现这种情况后，我们就需要利用 subconverter 提供的配置档案简化操作 . . step 1 既然需要用到配置档案，我们自然就不能使用 heroku 一键部署的功能（不然怎么添加本地文件？）。在heroku-subconverter页面，点击 use this template 将该模版 copy 自己的仓库下，这里建议将仓库权限设置为 Private，不然全世界人们都可以看见你的配置档案了。 . step 2 所有的配置档案都应保存在 base 文件夹中，因为 base 文件夹是软件运行的根目录。 . 修改 README.md 中的部署地址为 https://heroku.com/deploy?template=自己的仓库地址，这样在配置完成后点击 README 中 Deploy to Heroku 即可将服务部署在 Heroku 上。 . step 3 根据你的喜好在 base 中添加相应的配置档案。 配置档案参照subconverter 说明进行配置。 . . 建议在本地调试好后再上传云端。 step 4 在 Heroku 中关联 GitHub 的方法已经失效。每次修改完成后都需点击 Deploy to Heroku 将 Docker 部署到云端。 . step 5 至此部署云端 API 基本完成，这里有几个注意事项。 . 云端的根目录就是 base 目录。比如你在 base 下有一个example_profile.ini配置文件，路径就是https://***.herokuapp.com/getprofile?name=example_profile.ini&amp;token=*** | 需修改你在pref.ini的managed_config_prefix路径，将其指向云端路径 | 为了安全考虑，建议修改token默认密码 | 订阅时直接在订阅链接里输入云端 API 地址即可，如https://***.herokuapp.com/getprofile?name=example_profile.ini&amp;token=*** | 你可以建立多个配置文件，让不同软件使用不同配置文件。 | . 自定义规则 . 在 subconverter 说明文档中对自定义规则有少许描述，这里给出一个完整的自定义规则配置过程。 subconverter 的默认配置规则为神机规则，里面包含了大量与广告相关的规则。下面我们就以去除神机规则中的广告拦截规则为例。 . 在配置档案中，我们可以通过添加config参数加载额外的配置文件。当然我们也可以通过直接修改 pref.ini 实现。 . [Profile] target=clash url=ss://Y2hhY2hhMjAtaWV0Zi1wb2x5MTMwNTpwYXNzd29yZA@www.example.com:1080#Example ; 加载位于 config/example_external_config.ini 的配置文件 config=config/example_external_config.ini . 仿照默认的配置文件编辑自定义配置文件，默认配置文件在pref.ini由surge_ruleset和custom_proxy_group指出。 比如我们不想添加广告过滤。 . [custom] ; 自定义策略组 custom_proxy_group=🔰 节点选择`select`[]♻️ 自动选择`[]🎯 全球直连`.* custom_proxy_group=♻️ 自动选择`url-test`.*`http://www.gstatic.com/generate_204`300 custom_proxy_group=🌍 国外媒体`select`[]🔰 节点选择`[]♻️ 自动选择`[]🎯 全球直连`.* custom_proxy_group=🌏 国内媒体`select`[]🎯 全球直连`[]🔰 节点选择 custom_proxy_group=Ⓜ️ 微软服务`select`[]🎯 全球直连`[]🔰 节点选择`.* custom_proxy_group=📲 电报信息`select`[]🔰 节点选择`[]🎯 全球直连`.* custom_proxy_group=🍎 苹果服务`select`[]🔰 节点选择`[]🎯 全球直连`[]♻️ 自动选择`.* custom_proxy_group=🎯 全球直连`select`[]DIRECT custom_proxy_group=🐟 漏网之鱼`select`[]🎯 全球直连`[]🔰 节点选择`[]♻️ 自动选择`.* ;Options for custom rulesets ; 自定义规则片段 enable_rule_generator=true overwrite_original_rules=true surge_ruleset=🎯 全球直连,rules/LocalAreaNetwork.list surge_ruleset=Ⓜ️ 微软服务,rules/MSServices.list surge_ruleset=🎯 全球直连,rules/ConnersHua/Surge/Ruleset/Unbreak.list surge_ruleset=🌍 国外媒体,rules/ConnersHua/Surge/Ruleset/GlobalMedia.list surge_ruleset=🌏 国内媒体,rules/lhie1/Surge/Surge 3/Provider/AsianTV.list surge_ruleset=📲 电报信息,rules/ConnersHua/Surge/Ruleset/Telegram.list surge_ruleset=🔰 节点选择,rules/ConnersHua/Surge/Ruleset/Global.list surge_ruleset=🍎 苹果服务,rules/ConnersHua/Surge/Ruleset/Apple.list surge_ruleset=🎯 全球直连,rules/ConnersHua/Surge/Ruleset/China.list surge_ruleset=🎯 全球直连,rules/NobyDa/Surge/Download.list surge_ruleset=🎯 全球直连,[]GEOIP,CN surge_ruleset=🐟 漏网之鱼,[]FINAL . 至此在调用配置档案时，会调用自定义配置档案并覆盖掉原始配置档案。 . 管理订阅节点 . 如果多份配置文件都要使用同一套订阅节点，比如我同时用到 Clash，surge，quanx，shadowrocket 等，在每处配置文件的 url 处都加上订阅节点显得有些繁琐，特别是节点有修改时就很容易出错。 . 方法是将节点信息添加进pref.ini中，这是全局配置文件，根据需求在default_url或insert_url添加相应的节点信息即可。支持如下格式： . 机场订阅：https://dler.cloud/subscribe/ABCDE?surge=ss | 节点链接：ss://YWVzLTEyOC1nY206dGVzdA==@192.168.100.1:8888#Example1 | 文件路径：config/nodes.txt | . 其中文件里的节点内容支持 Clash 和 Quanx 格式（其它格式可能也支持，但我没有测试） . 小结 . subconverter 还有很多高级玩法，这篇文章只是抛砖引玉补充一些基础自定义案例，方便读者了解部分高级 API 的使用。 .",
            "url": "https://invisprints.github.io/blog/subconverter/heroku/2020/04/12/subconverter-example.html",
            "relUrl": "/subconverter/heroku/2020/04/12/subconverter-example.html",
            "date": " • Apr 12, 2020"
        }
        
    
  
    
        ,"post15": {
            "title": "更新 fastpages 框架",
            "content": "fastpages . fastpages 是一个在开发中的博客平台，因此会不断有新功能出现或修复现有的bug。fastpages 提供了 2 种更新方法，适用于新手的自动化更新和适用于自定义玩家的手动更新。 . 本文参考 Upgrading fastpages . 自动更新 . . Important: 自动更新适合那些没有修改网站 HTML 的博客。 第一步：使用 Upgrade Template 提出 Issue . 在你的博客 repo 中点击 New issue，并点击显示 [fastpages] Automated Upgrade 的 Get Started 按钮。 . 第二步: 点击 Submit new issue 按钮 . 不要对页面做任何改动 . 第三步: 查看自动生成的 PR . 接下来 GitHub 会打开 PR 自动更新，PR 界面如下 . 此时可能会报 error，通常的原因有如下几点： . - 已是最新版，error 上会显示 &quot;nothing to commit&quot;. - 之前有未合并的自动更新 PR 请求 . 你可以在 fastai 社区 提问。 . 第四步: 检查并合并 PR . 仔细检查 PR 中修改的文件，确保你自定义的部分没有被修改。之后点击Merge pull request 更新 fastpages。 | 如果 PR 中修改了你自定义的部分或不想被改动的部分，请采用手动更新。 | . 手动更新 . . 手动更新适合那些修改过网站 HTML 的博客。 直接在 GitHub 网页上修改 . 进行到自动更新的第四步之后，如果你发现 PR 中修改了你不想修改的内容，可以直接在 Files changed 标签页中修改 PR 内容，修改完成后等待 GitHub 冲突检查，解决完可能存在的冲突或失败之后就可以点击Merge pull request 更新 fastpages。 . clone 到本地解决 . 参考 GitHub - Pull changes from a template repository 和 How to sync fastai/fastpages with forked FastPages . 第一步 . 添加远程模版库 . $ git remote add template git@github.com:fastai/fastpages.git $ git remote -v origin git@github.com:byteshiva/blog.git (fetch) origin git@github.com:byteshiva/blog.git (push) template git@github.com:fastai/fastpages.git (fetch) template git@github.com:fastai/fastpages.git (push) upstream git@github.com:fastai/fastpages.git (fetch) upstream git@github.com:fastai/fastpages.git (push) . 第二步 . 更新 . $ git fetch --all Fetching origin remote: Enumerating objects: 43, done. remote: Counting objects: 100% (43/43), done. remote: Compressing objects: 100% (11/11), done. remote: Total 26 (delta 9), reused 24 (delta 7), pack-reused 0 Unpacking objects: 100% (26/26), done. From github.com:byteshiva/blog d7e8201..b67202a gh-pages -&gt; origin/gh-pages Fetching upstream remote: Enumerating objects: 86, done. remote: Counting objects: 100% (86/86), done. remote: Compressing objects: 100% (54/54), done. remote: Total 86 (delta 38), reused 64 (delta 27), pack-reused 0 Unpacking objects: 100% (86/86), done. From github.com:fastai/fastpages e8bf9f8..bcdbc22 gh-pages -&gt; upstream/gh-pages 5b4b79e..8f5a7bc master -&gt; upstream/master Fetching template From github.com:fastai/fastpages * [new branch] change-docker -&gt; template/change-docker * [new branch] gh-pages -&gt; template/gh-pages * [new branch] master -&gt; template/master * [new branch] pin-jekyll-version -&gt; template/pin-jekyll-version * [new branch] search-highlight -&gt; template/search-highlight . 第三步 . 合并 . $ git merge template/master fatal: refusing to merge unrelated histories . 如果出现 fatal: refusing to merge unrelated histories，则需要允许不关联的git 历史，参照第四步 . 第四步 . $ git merge template/master --allow-unrelated-histories CONFLICT (add/add): Merge conflict in index.md Auto-merging index.md CONFLICT (add/add): Merge conflict in assets/main.scss Auto-merging assets/main.scss CONFLICT (add/add): Merge conflict in assets/js/search.js Auto-merging assets/js/search.js CONFLICT (add/add): Merge conflict in _posts/2020-01-14-test-markdown-post.md Auto-merging _posts/2020-01-14-test-markdown-post.md CONFLICT (add/add): Merge conflict in _notebooks/2020-02-20-test.ipynb Auto-merging _notebooks/2020-02-20-test.ipynb CONFLICT (add/add): Merge conflict in _includes/youtube.html Auto-merging _includes/youtube.html CONFLICT (add/add): Merge conflict in _includes/twitter.html Auto-merging _includes/twitter.html CONFLICT (add/add): Merge conflict in _includes/notebook_github_link.html Auto-merging _includes/notebook_github_link.html CONFLICT (add/add): Merge conflict in _includes/notebook_colab_link.html Auto-merging _includes/notebook_colab_link.html CONFLICT (add/add): Merge conflict in _includes/favicons.html Auto-merging _includes/favicons.html CONFLICT (add/add): Merge conflict in _config.yml Auto-merging _config.yml CONFLICT (add/add): Merge conflict in _action_files/settings.ini Auto-merging _action_files/settings.ini CONFLICT (add/add): Merge conflict in _action_files/nb2post.py Auto-merging _action_files/nb2post.py CONFLICT (add/add): Merge conflict in _action_files/action_entrypoint.sh Auto-merging _action_files/action_entrypoint.sh CONFLICT (add/add): Merge conflict in README.md Auto-merging README.md CONFLICT (add/add): Merge conflict in Makefile Auto-merging Makefile CONFLICT (add/add): Merge conflict in .github/workflows/setup.yaml Auto-merging .github/workflows/setup.yaml CONFLICT (add/add): Merge conflict in .github/workflows/ci.yaml Auto-merging .github/workflows/ci.yaml Automatic merge failed; fix conflicts and then commit the result. . 第五步 . 显示冲突文件 参考 List conflicted files in git . git diff --name-only --diff-filter=U .github/workflows/ci.yaml .github/workflows/setup.yaml Makefile README.md _action_files/action_entrypoint.sh _action_files/nb2post.py _action_files/settings.ini _config.yml _includes/favicons.html _includes/notebook_colab_link.html _includes/notebook_github_link.html _includes/twitter.html _includes/youtube.html _notebooks/2020-02-20-test.ipynb _posts/2020-01-14-test-markdown-post.md assets/js/search.js assets/main.scss index.md . 第六步 . 用你擅长的方式解决冲突 . 第七步 . 合并并提交更新 . git add . git commit -m &quot; commit message comes here &quot; .",
            "url": "https://invisprints.github.io/blog/fastpages/2020/04/08/fastpages-upgrade.html",
            "relUrl": "/fastpages/2020/04/08/fastpages-upgrade.html",
            "date": " • Apr 8, 2020"
        }
        
    
  
    
        ,"post16": {
            "title": "markdown 博文发布教程",
            "content": "基本设置 . fastpages 会将存放在 _post 文件夹内的 markdown 文章自动转换成博文，因此你应该将所有的markdown博文放在该文件夹下。 . fastpages 也会将存放在 _notebooks 中的 jupyter notebook 和 _word 中的 word 文章自动转换成博文。因此你的博文应该存放在这三个文件夹内。 . 所有的博文遵循同一套命名规范，即 YYYY-MM-DD-filename.ext，如本篇 markdown 教程的文件名为 2020-04-04-markdown-tutorial.md . 格式 . markdown 文章格式遵从 markdown 格式，如不了解，请自行搜索相关内容。 . . . 以下内容引用自MWeb 标题 . Markdown 语法： . # 第一级标题 `&lt;h1&gt;` ## 第二级标题 `&lt;h2&gt;` ###### 第六级标题 `&lt;h6&gt;` . 效果如下： . 第一级标题 &lt;h1&gt; . 第二级标题 &lt;h2&gt; . 第六级标题 &lt;h6&gt; . 强调 . Markdown 语法： . *这些文字会生成`&lt;em&gt;`* _这些文字会生成`&lt;u&gt;`_ **这些文字会生成`&lt;strong&gt;`** __这些文字会生成`&lt;strong&gt;`__ . 效果如下： . 这些文字会生成&lt;em&gt; 这些文字会生成&lt;u&gt; . 这些文字会生成&lt;strong&gt; 这些文字会生成&lt;strong&gt; . 换行 . 四个及以上空格加回车。 . 列表 . 无序列表 . Markdown 语法： . * 项目一 无序列表 `* + 空格键` * 项目二 * 项目二的子项目一 无序列表 `TAB + * + 空格键` * 项目二的子项目二 . 效果如下： . 项目一 无序列表 * + 空格键 | 项目二 | 项目二的子项目一 无序列表 TAB + * + 空格键 | 项目二的子项目二 | . 有序列表 . Markdown 语法： . 1. 项目一 有序列表 `数字 + . + 空格键` 2. 项目二 3. 项目三 1. 项目三的子项目一 有序列表 `TAB + 数字 + . + 空格键` 2. 项目三的子项目二 . 效果如下： . 项目一 有序列表 数字 + . + 空格键 | 项目二 | 项目三 项目三的子项目一 有序列表 TAB + 数字 + . + 空格键 | 项目三的子项目二 | | 任务列表（Task lists） . Markdown 语法： . - [ ] 任务一 未做任务 `- + 空格 + [ ]` - [x] 任务二 已做任务 `- + 空格 + [x]` . 效果如下： . 任务一 未做任务 - + 空格 + [ ] | 任务二 已做任务 - + 空格 + [x] | . 图片 . Markdown 语法： . ![GitHub set up](http://zh.mweb.im/asset/img/set-up-git.gif) 格式: ![Alt Text](url) . 效果如下： . . 链接 . Markdown 语法： . email &lt;example@example.com&gt; [GitHub](http://github.com) 自动生成连接 &lt;http://www.github.com/&gt; . 效果如下： . Email 连接： example@example.com 连接标题Github网站 自动生成连接像： http://www.github.com/ 这样 . 区块引用 . Markdown 语法： . 某某说: &gt; 第一行引用 &gt; 第二行费用文字 . 效果如下： . 某某说: . 第一行引用 第二行费用文字 . 行内代码 . Markdown 语法： . 像这样即可：`&lt;addr&gt;` `code` . 效果如下： . 像这样即可：&lt;addr&gt; code . 多行或者一段代码 . Markdown 语法： . js function fancyAlert(arg) { if(arg) { $.facebox({div:&#39;#foo&#39;}) } } . 效果如下： . function fancyAlert(arg) { if(arg) { $.facebox({div:&#39;#foo&#39;}) } } . 表格 . Markdown 语法： . 第一格表头 | 第二格表头 | - 内容单元格 第一列第一格 | 内容单元格第二列第一格 内容单元格 第一列第二格 多加文字 | 内容单元格第二列第二格 . 效果如下： . 第一格表头 第二格表头 . 内容单元格 第一列第一格 | 内容单元格第二列第一格 | . 内容单元格 第一列第二格 多加文字 | 内容单元格第二列第二格 | . 删除线 . Markdown 语法： . 加删除线像这样用： 删除这些 . 效果如下： . 加删除线像这样用： 删除这些 . 分隔线 . 以下三种方式都可以生成分隔线： . *** ***** - - - . 效果如下： . . . . MathJax . Markdown 语法： . 块级公式： $$ x = frac{-b pm sqrt{b^2 - 4ac}}{2a} $$ [ frac{1}{ Bigl( sqrt{ phi sqrt{5}}- phi Bigr) e^{ frac25 pi}} = 1+ frac{e^{-2 pi}} {1+ frac{e^{-4 pi}} {1+ frac{e^{-6 pi}} {1+ frac{e^{-8 pi}} {1+ ldots} } } } ] 行内公式： $$ Gamma(n) = (n-1)! quad forall n in mathbb N$$ . 在 _config.yml 中设置 use_math: true 可开启渲染数学公式 . 块级公式： . x=−b±b2−4ac2ax = frac{-b pm sqrt{b^2 - 4ac}}{2a}x=2a−b±b2−4ac . ​​ . [ frac{1}{ Bigl( sqrt{ phi sqrt{5}}- phi Bigr) e^{ frac25 pi}} = 1+ frac{e^{-2 pi}} {1+ frac{e^{-4 pi}} {1+ frac{e^{-6 pi}} {1+ frac{e^{-8 pi}} {1+ ldots} } } } ] . 行内公式： Γ(n)=(n−1)!∀n∈N Gamma(n) = (n-1)! quad forall n in mathbb NΓ(n)=(n−1)!∀n∈N . . 在本地测试时可能会遇到数学公式渲染出错的情况 脚注（Footnote） . Markdown 语法： . 这是一个脚注：[^sample_footnote] . 效果如下： . 这是一个脚注：1 . . 以上内容引用自MWeb . 除了标准markdown格式，fastpages还允许你增添一些额外的内容。 . 图片与图注 . 如果你想显示本地图片，可将图片放入 images 文件夹中，然后用 /blog/images 表示图片路径，同时你可以仿照下面格式显示图注 . ![](/blog/images/logo.png &quot;fast.ai&#39;s logo&quot;) . . Tweet 卡片 . 请查看原md文档以了解如何使用该功能 . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Boxes / Callouts . 请查看原md文档以了解如何使用该功能 . . You can include alert boxes . You can include info boxes FrontMatter . FrontMatter 相当于每篇博文的配置文件，它控制着每篇博文该如何展现内容。 在 markdown 博文中，我们会将 FrontMatter 写在文章的开头 . title: &quot;My Title&quot; summary: &quot;Awesome summary&quot; toc: false comments: true image: images/some_folder/your_image.png hide: false search_exclude: true categories: [fastpages, jupyter] metadata_key1: metadata_value1 metadata_key2: metadata_value2 . FrontMatter允许用户自定义额外选项，但必须遵守YAML格式规则。 . 可以访问 fastpages 主页 了解更多内容 . 这里是脚注信息 &#8617; . |",
            "url": "https://invisprints.github.io/blog/markdown/fastpages/2020/04/04/markdown-tutorial.html",
            "relUrl": "/markdown/fastpages/2020/04/04/markdown-tutorial.html",
            "date": " • Apr 4, 2020"
        }
        
    
  
    
        ,"post17": {
            "title": "GitHub Actions: Providing Data Scientists With New Superpowers",
            "content": "What Superpowers? . Hi, I’m Hamel Husain. I’m a machine learning engineer at GitHub. Recently, GitHub released a new product called GitHub Actions, which has mostly flown under the radar in the machine learning and data science community as just another continuous integration tool. . Recently, I’ve been able to use GitHub Actions to build some very unique tools for Data Scientists, which I want to share with you today. Most importantly, I hope to get you excited about GitHub Actions, and the promise it has for giving you new superpowers as a Data Scientist. Here are two projects I recently built with Actions that show off its potential: . fastpages . fastpages is an automated, open-source blogging platform with enhanced support for Jupyter notebooks. You save your notebooks, markdown, or Word docs into a directory on GitHub, and they automatically become blog posts. Read the announcement below: . We&#39;re launching `fastpages`, a platform which allows you to host a blog for free, with no ads. You can blog with @ProjectJupyter notebooks, @office Word, directly from @github&#39;s markdown editor, etc.Nothing to install, &amp; setup is automated!https://t.co/dNSA0oQUrN . &mdash; Jeremy Howard (@jeremyphoward) February 24, 2020 Machine Learning Ops . Wouldn’t it be cool if you could invoke a chatbot natively on GitHub to test your machine learning models on the infrastructure of your choice (GPUs), log all the results, and give you a rich report back in a pull request so that everyone could see the results? You can with GitHub Actions! . Consider the below annotated screenshot of this Pull Request: . . A more in-depth explanation about the above project can be viewed in this video: . Using GitHub Actions for machine learning workflows is starting to catch on. Julien Chaumond, CTO of Hugging Face, says: . GitHub Actions are great because they let us do CI on GPUs (as most of our users use the library on GPUs not on CPUs), on our own infra! 1 . Additionally, you can host a GitHub Action for other people so others can use parts of your workflow without having to re-create your steps. I provide examples of this below. . A Gentle Introduction To GitHub Actions . What Are GitHub Actions? . GitHub Actions allow you to run arbitrary code in response to events. Events are activities that happen on GitHub such as: . Opening a pull request | Making an issue comment | Labeling an issue | Creating a new branch | … and many more | . When an event is created, the GitHub Actions context is hydrated with a payload containing metadata for that event. Below is an example of a payload that is received when an issue is created: . { &quot;action&quot;: &quot;created&quot;, &quot;issue&quot;: { &quot;id&quot;: 444500041, &quot;number&quot;: 1, &quot;title&quot;: &quot;Spelling error in the README file&quot;, &quot;user&quot;: { &quot;login&quot;: &quot;Codertocat&quot;, &quot;type&quot;: &quot;User&quot;, }, &quot;labels&quot;: [ { &quot;id&quot;: 1362934389, &quot;node_id&quot;: &quot;MDU6TGFiZWwxMzYyOTM0Mzg5&quot;, &quot;name&quot;: &quot;bug&quot;, } ], &quot;body&quot;: &quot;It looks like you accidently spelled &#39;commit&#39; with two &#39;t&#39;s.&quot; } . This functionality allows you to respond to various events on GitHub in an automated way. In addition to this payload, GitHub Actions also provide a plethora of variables and environment variables that afford easy to access metadata such as the username and the owner of the repo. Additionally, other people can package useful functionality into an Action that other people can inherit. For example, consider the below Action that helps you publish python packages to PyPi: . The Usage section describes how this Action can be used: . - name: Publish a Python distribution to PyPI uses: pypa/gh-action-pypi-publish@master with: user: __token__ password: ${{ secrets.pypi_password }} . This Action expects two inputs: user and a password. You will notice that the password is referencing a variable called secrets, which is a variable that contains an encrypted secret that you can upload to your GitHub repository. There are thousands of Actions (that are free) for a wide variety of tasks that can be discovered on the GitHub Marketplace. The ability to inherit ready-made Actions in your workflow allows you to accomplish complex tasks without implementing all of the logic yourself. Some useful Actions for those getting started are: . actions/checkout: Allows you to quickly clone the contents of your repository into your environment, which you often want to do. This does a number of other things such as automatically mount your repository’s files into downstream Docker containers. | mxschmitt/action-tmate: Proivdes a way to debug Actions interactively. This uses port forwarding to give you a terminal in the browser that is connected to your Actions runner. Be careful not to expose sensitive information if you use this. | actions/github-script: Gives you a pre-authenticated ocotokit.js client that allows you to interact with the GitHub API to accomplish almost any task on GitHub automatically. Only these endpoints are supported (for example, the secrets endpoint is not in that list). | . In addition to the aforementioned Actions, it is helpful to go peruse the official GitHub Actions docs before diving in. . Example: A fastpages Action Workflow . The best to way familiarize yourself with Actions is by studying examples. Let’s take a look at the Action workflow that automates the build of fastpages (the platform used to write this blog post). . Part 1: Define Workflow Triggers . First, we define triggers in ci.yaml. Like all Actions workflows, this is a YAML file located in the .github/workflows directory of the GitHub repo. . The top of this YAML file looks like this: . name: CI on: push: branches: - master pull_request: . This means that this workflow is triggered on either a push or pull request event. Furthermore, push events are filtered such that only pushes to the master branch will trigger the workflow, whereas all pull requests will trigger this workflow. It is important to note that pull requests opened from forks will have read-only access to the base repository and cannot access any secrets for security reasons. The reason for defining the workflow in this way is we wanted to trigger the same workflow to test pull requests as well as build and deploy the website when a PR is merged into master. This will be clarified as we step through the rest of the YAML file. . Part 2: Define Jobs . Next, we define jobs (there is only one in this workflow). Per the docs: . A workflow run is made up of one or more jobs. Jobs run in parallel by default. . jobs: build-site: if: ( github.event.commits[0].message != &#39;Initial commit&#39; ) || github.run_number &gt; 1 runs-on: ubuntu-latest steps: . The keyword build-site is the name of your job and you can name it whatever you want. In this case, we have a conditional if statement that dictates if this job should be run or not. We are trying to ensure that this workflow does not run when the first commit to a repo is made with the message ‘Initial commit’. The first variable in the if statement, github.event, contains a json payload of the event that triggered this workflow. When developing workflows, it is helpful to print this variable in order to inspect its structure, which you can accomplish with the following YAML: . - name: see payload run: | echo &quot;PAYLOAD: n${PAYLOAD} n&quot; env: PAYLOAD: ${{ toJSON(github.event) }} . Note: the above step is only for debugging and is not currently in the workflow. . toJson is a handy function that returns a pretty-printed JSON representation of the variable. The output is printed directly in the logs contained in the Actions tab of your repo. In this example, printing the payload for a push event will look like this (truncated for brevity): . { &quot;ref&quot;: &quot;refs/tags/simple-tag&quot;, &quot;before&quot;: &quot;6113728f27ae8c7b1a77c8d03f9ed6e0adf246&quot;, &quot;created&quot;: false, &quot;deleted&quot;: true, &quot;forced&quot;: false, &quot;base_ref&quot;: null, &quot;commits&quot;: [ { &quot;message&quot;: &quot;updated README.md&quot;, &quot;author&quot;: &quot;hamelsmu&quot; }, ], &quot;head_commit&quot;: null, } . Therefore, the variable github.event.commits[0].message will retrieve the first commit message in the array of commits. Since we are looking for situations where there is only one commit, this logic suffices. The second variable in the if statement, github.run_number is a special variable in Actions which: . [is a] unique number for each run of a particular workflow in a repository. This number begins at 1 for the workflow’s first run, and increments with each new run. This number does not change if you re-run the workflow run. . Therefore, the if statement introduced above: . if: ( github.event.commits[0].message != &#39;Initial commit&#39; ) || github.run_number &gt; 1 . Allows the workflow to run when the commit message is “Initial commit” as long as it is not the first commit. ( || is a logical or operator). . Finally, the line runs-on: ubuntu-latest specifies the host operating system that your workflows will run in. . Part 3: Define Steps . Per the docs: . A job contains a sequence of tasks called steps. Steps can run commands, run setup tasks, or run an Action in your repository, a public repository, or an Action published in a Docker registry. Not all steps run Actions, but all Actions run as a step. Each step runs in its own process in the runner environment and has access to the workspace and filesystem. Because steps run in their own process, changes to environment variables are not preserved between steps. GitHub provides built-in steps to set up and complete a job. . Below are the first two steps in our workflow: . - name: Copy Repository Contents uses: actions/checkout@master with: persist-credentials: false - name: convert notebooks and word docs to posts uses: ./_action_files . The first step creates a copy of your repository in the Actions file system, with the help of the utility action/checkout. This utility only fetches the last commit by default and saves files into a directory (whose path is stored in the environment variable GITHUB_WORKSPACE that is accessible by subsequent steps in your job. The second step runs the fastai/fastpages Action, which converts notebooks and word documents to blog posts automatically. In this case, the syntax: . uses: ./_action_files . is a special case where the pre-made GitHub Action we want to run happens to be defined in the same repo that runs this workflow. This syntax allows us to test changes to this pre-made Action when evaluating PRs by referencing the directory in the current repository that defines that pre-made Action. Note: Building pre-made Actions is beyond the scope of this tutorial. . The next three steps in our workflow are defined below: . - name: setup directories for Jekyll build run: | rm -rf _site sudo chmod -R 777 . - name: Jekyll build uses: docker://fastai/fastpages-jekyll with: args: bash -c &quot;gem install bundler &amp;&amp; jekyll build -V&quot; env: JEKYLL_ENV: &#39;production&#39; - name: copy CNAME file into _site if CNAME exists run: | sudo chmod -R 777 _site/ cp CNAME _site/ 2&gt;/dev/null || : . The step named setup directories for Jekyll build executes shell commands that remove the _site folder in order to get rid of stale files related to the page we want to build, as well as grant permissions to all the files in our repo to subsequent steps. . The step named Jekyll build executes a docker container hosted by the Jekyll community on Dockerhub called jekyll/jekyll. For those not familiar with Docker, see this tutorial. The name of this container is called fastai/fastpages-jekyll because I’m adding some additional dependencies to jekyll/jekyll and hosting those on my DockerHub account for faster build times2. The args parameter allows you to execute arbitrary commands with the Docker container by overriding the CMD instruction in the Dockerfile. We use this Docker container hosted on Dockerhub so we don’t have to deal with installing and configuring all of the complicated dependencies for Jekyll. The files from our repo are already available in the Actions runtime due to the first step in this workflow, and are mounted into this Docker container automatically for us. In this case, we are running the command jekyll build, which builds our website and places relevant assets them into the _site folder. For more information about Jekyll, read the official docs. Finally, the env parameter allows me to pass an environment variable into the Docker container. . The final command above copies a CNAME file into the _site folder, which we need for the custom domain https://fastpages.fast.ai. Setting up custom domains are outside the scope of this article. . The final step in our workflow is defined below: . - name: Deploy if: github.event_name == &#39;push&#39; uses: peaceiris/actions-gh-pages@v3 with: deploy_key: ${{ secrets.SSH_DEPLOY_KEY }} publish_dir: ./_site . The statement . if: github.event_name == &#39;push&#39; . uses the variable github.event_name to ensure this step only runs when a push event ( in this case only pushes to the master branch trigger this workflow) occur. . This step deploys the fastpages website by copying the contents of the _site folder to the root of the gh-pages branch, which GitHub Pages uses for hosting. This step uses the peaceiris/actions-gh-pages Action, pinned at version 3. Their README describes various options and inputs for this Action. . Conclusion . We hope that this has shed some light on how we use GitHub Actions to automate fastpages. While we only covered one workflow above, we hope this provides enough intuition to understand the other workflows in fastpages. We have only scratched the surface of GitHub Actions in this blog post, but we provide other materials below for those who want to dive in deeper. We have not covered how to host an Action for other people, but you can start with these docs to learn more. . Still confused about how GitHub Actions could be used for Data Science? Here are some ideas of things you can build: . Jupyter Widgets that trigger GitHub Actions to perform various tasks on GitHub via the repository dispatch event | Integration with Pachyderm for data versioning. | Integration with your favorite cloud machine learning services, such Sagemaker, Azure ML or GCP’s AI Platform. | . Related Materials . GitHub Actions official documentation | Hello world Docker Action: A template to demonstrate how to build a Docker Action for other people to use. | Awesome Actions: A curated list of interesting GitHub Actions by topic. | A tutorial on Docker for Data Scientists. | . Getting In Touch . Please feel free to get in touch with us on Twitter: . Hamel Husain @HamelHusain | Jeremy Howard @jeremyphoward | . . Footnotes . You can see some of Hugging Face’s Actions workflows for machine learning on GitHub &#8617; . | These additional dependencies are defined here, which uses the “jekyll build” command to add ruby dedpendencies from the Gemfile located at the root of the repo. Additionally, this docker image is built by another Action workflow defined here. &#8617; . |",
            "url": "https://invisprints.github.io/blog/actions/markdown/2020/03/06/fastpages-actions.html",
            "relUrl": "/actions/markdown/2020/03/06/fastpages-actions.html",
            "date": " • Mar 6, 2020"
        }
        
    
  
    
        ,"post18": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://invisprints.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  
    
        ,"post19": {
            "title": "Microsoft Word Example Post",
            "content": "When writing a blog post with Microsoft Word – the filename becomes the title. In this case the file name is “2020-01-01-Microsoft-Word-Example-Post.docx”. . There is minimal support for Word documents in fastpages compared to Jupyter notebooks. Some known limitations: . alt text in Word documents are not yet supported by fastpages, and will break links to images. . | You can only specify front matter for Word documents globally. See the README for more details. . | . For greater control over the content produced from Word documents, you will need to convert Word to markdown files manually. You can follow the steps in this blog post, which walk you through how to use pandoc to do the conversion. Note: If you wish to customize your Word generated blog post in markdown, make sure you delete your Word document from the _word directory so your markdown file doesn’t get overwritten! . If your primary method of writing blog posts is Word documents, and you plan on always manually editing Word generated markdown files, you are probably better off using fast_template instead of fastpages. . The material below is a reproduction of this blog post, and serves as an illustrative example. . Maintaining a healthy open source project can entail a huge amount of toil. Popular projects often have orders of magnitude more users and episodic contributors opening issues and PRs than core maintainers capable of handling these issues. . Consider this graphic prepared by the NumFOCUS foundation showing the number of maintainers for three widely used scientific computing projects: . . We can see that across these three projects, there is a very low ratio maintainers to users. Fixing this problem is not an easy task and likely requires innovative solutions to address the economics as well as tools. . Due to its recent momentum and popularity, Kubeflow suffers from a similar fate as illustrated by the growth of new issues opened: . . Source: “TensorFlow World 2019, Automating Your Developer Workflow With ML” . Coincidentally, while building out end to end machine learning examples for Kubeflow, we built two examples using publicly available GitHub data: GitHub Issue Summarization and Code Search. While these tutorials were useful for demonstrating components of Kubeflow, we realized that we could take this a step further and build concrete data products that reduce toil for maintainers. . This is why we started the project kubeflow/code-intelligence, with the goals of increasing project velocity and health using data driven tools. Below are two projects we are currently experimenting with : . Issue Label Bot: This is a bot that automatically labels GitHub issues using Machine Learning. This bot is a GitHub App that was originally built for Kubeflow but is now also used by several large open source projects. The current version of this bot only applies a very limited set of labels, however we are currently A/B testing new models that allow personalized labels. Here is a blog post discussing this project in more detail. . | Issue Triage GitHub Action: to compliment the Issue Label Bot, we created a GitHub Action that automatically adds / removes Issues to the Kubeflow project board tracking issues needing triage. . | Together these projects allow us to reduce the toil of triaging issues. The GitHub Action makes it much easier for the Kubeflow maintainers to track issues needing triage. With the label bot we have taken the first steps in using ML to replace human intervention. We plan on using features extracted by ML to automate more steps in the triage process to further reduce toil. . Building Solutions with GitHub Actions . One of the premises of Kubeflow is that a barrier to building data driven, ML powered solutions is getting models into production and integrated into a solution. In the case of building models to improve OSS project health, that often means integrating with GitHub where the project is hosted. . We are really excited by GitHub’s newly released feature GitHub Actions because we think it will make integrating ML with GitHub much easier. . For simple scripts, like the issue triage script, GitHub actions make it easy to automate executing the script in response to GitHub events without having to build and host a GitHub app. . To automate adding/removing issues needing triage to a Kanban board we wrote a simple python script that interfaces with GitHub’s GraphQL API to modify issues. . As we continue to iterate on ML Models to further reduce toil, GitHub Actions will make it easy to leverage Kubeflow to put our models into production faster. A number of prebuilt GitHub Actions make it easy to create Kubernetes resources in response to GitHub events. For example, we have created GitHub Actions to launch Argo Workflows. This means once we have a Kubernetes job or workflow to perform inference we can easily integrate the model with GitHub and have the full power of Kubeflow and Kubernetes (eg. GPUs). We expect this will allow us to iterate much faster compared to building and maintaining GitHub Apps. . Call To Action . We have a lot more work to do in order to achieve our goal of reducing the amount of toil involved in maintaining OSS projects. If your interested in helping out here’s a couple of issues to get started: . Help us create reports that pull and visualize key performance indicators (KPI). https://github.com/kubeflow/code-intelligence/issues/71 . We have defined our KPI here: issue #19 | . | Combine repo specific and non-repo specific label predictions: https://github.com/kubeflow/code-intelligence/issues/70 . | . In addition to the aforementioned issues we welcome contributions for these other issues in our repo. .",
            "url": "https://invisprints.github.io/blog/2020/01/01/Microsoft-Word-Example-Post.html",
            "relUrl": "/2020/01/01/Microsoft-Word-Example-Post.html",
            "date": " • Jan 1, 2020"
        }
        
    
  
    
        ,"post20": {
            "title": "LEDE 系统 IPV6 搭建方法",
            "content": "LEDE 系统 IPV6 搭建方法 . 对于需要认证才能用 IPv6 的华科来说，不需要点奇技淫巧是不行的。 . 参考博文 LEDE 下的 ipv6 NAT6 . 看参考博文标题就知道，正常认证后是路由器能上 IPv6 网，但下游终端设备还不行。因此需要搭建 NAT 来拯救世界！ . 在锐捷认证过后，路由器应该能直接上 IPv6 网了，测试一下： . ping6 ipv6.google.com . 不行的话检查是否真的连上网了。 . ##安装软件包 先安装必要软件，ip6tables 和 kmode-ipt-nat6： . opkg install ip6tables kmod-ipt-nat6 . ##设置ULA prefix 这步可以不做，据说做了后网站会尽量走 IPv6 通道。 . 在 Network-&gt;Interface 界面下，将 ULA prefix 前缀改成 2fff::/64 内的任意网段。 . ##宣告默认路由 在 Network-&gt;Interface-LAN 的 DHCP Server 界面下，选择 IPv6 Settings 标签，勾选 Always announce default router . ##宣告默认网关 查看当前IPv6默认路由如下 . ip -6 route | grep &quot;default from&quot; . 若结果是这样的 . default from [ipv6 range] via [gateway] dev [intf] proto static metric 512 . 就需要向下一级宣告默认网关，中括号的内容请自行替换为上面结果。 . ip -6 r add default via [gateway] dev [intf] . ##搭建 NAT 利用 ip6tables 进行内网 NAT，括号内容为上面的结果 . ip6tables -t nat -A POSTROUTING -o [intf] -j MASQUERADE . 这时候终端应该就可以访问 IPv6 网站了。 点此测试你的IPv6配置 . ##开机自动设置 IPv6 （可选步骤） 在/etc/hotplug.d/iface目录下建立 90-ipv6 文件，并填入以下内容： . #!/bin/sh # filename: /etc/hotplug.d/iface/90-ipv6 # please make sure this file has permission 644 # check if it is the intf which has a public ipv6 address like &quot;2001:da8:100d:aaaa:485c::1/64&quot; interface_public=&quot;wan6&quot; [ &quot;$INTERFACE&quot; = &quot;$interface_public&quot; ] || exit 0 res=`ip -6 route | grep &quot;default from&quot;` gateway=`echo $res | awk &#39;{print $5}&#39;` interface=`echo $res | awk &#39;{print $7}&#39;` if [ &quot;$ACTION&quot; = ifup ]; then ip -6 r add default via $gateway dev $interface if !(ip6tables-save -t nat | grep -q &quot;v6NAT&quot;); then ip6tables -t nat -A POSTROUTING -o $interface -m comment --comment &quot;v6NAT&quot; -j MASQUERADE fi else ip6tables -t nat -D POSTROUTING -o $interface -m comment --comment &quot;v6NAT&quot; -j MASQUERADE ip -6 r del default via $gateway dev $interface fi . 上面的脚本使用要注意，变量 interface_pulbic 是带有公网 IPV6 地址的接口地址，比如我的是在 wan6 上，那么变量 interface_pulbic 是 wan6。 最后记得修改权限： . chmod 644 /etc/hotplug.d/iface/90-ipv6 .",
            "url": "https://invisprints.github.io/blog/others/2018/01/07/LEDE-%E7%B3%BB%E7%BB%9F-IPV6-%E6%90%AD%E5%BB%BA%E6%96%B9%E6%B3%95.html",
            "relUrl": "/others/2018/01/07/LEDE-%E7%B3%BB%E7%BB%9F-IPV6-%E6%90%AD%E5%BB%BA%E6%96%B9%E6%B3%95.html",
            "date": " • Jan 7, 2018"
        }
        
    
  
    
        ,"post21": {
            "title": "macOS 下用 DOS 模拟器进行汇编实验",
            "content": "macOS 下用 DOS 模拟器进行汇编实验 . 学微机原理的同学都是要求学汇编语言的，但是这种古老的语言并没有良好的移植性，用 Mac 的同学深受其害，往往都需要在 Windows 虚拟机下运行 Dos 模拟器完成，但是 macOS 下也有很棒的 DOS 模拟器，让我们可以跳过 Window 虚拟机这一环。 . 不要给我说 nasm 命令！！那个东西基本跟学校学习的汇编不兼容，劝发现这个命令的人老老实实用 DOS 模拟器吧。 . DOSBox . Windows 下著名的 DOS 模拟器，华中科技大学自动化学生御用 DOS 模拟器，其官网已经多年没有更新了，所以对于最新的系统可能有一些兼容问题。 最新的版本是 2010 年推出的 0.74 版，之后就再也没有更新。细心的读者可能会发现，DOSBox 居然有 MAC OS X 版！各位，先别急着欢呼，我这里之所以用 MAC OS X 而没用 macOS 就是想提醒大家这个版本已经很老了，最新版的兼容性堪忧。 所以广大的 macOS 该怎么办呢？大家放心，既然我博文都写出来了，肯定有比装虚拟机更好的方法。 . ##Boxer 就是我们大名鼎鼎的 Boxer！虽然最新更新日期是 2016 年 2 月，快有一年没有更新了，但是相比于 DOSBox， 已经好太多。官网地址 软件本身自带几个 DOS 游戏，大家可以试着玩玩，但是我们今天的主题不是这个，而是用它进行汇编语言实验。 . ###搭建环境 有了著名的 DOS 操作环境，下面我们需要搭建开发环境，毕竟 Boxer 本身是不包含编译汇编程序的。 这是我找的一份 DOS 环境下汇编语言开发包，提取码是 je38。至于从哪找的我已经忘了，反正好用无毒！ 下载好后把里面的程序放到你的汇编语言开发环境中，即在同一个目录下。 . ###挂载项目 打开 Boxer 后选择 Open a DOS prompt, 即进入的我们熟悉又和蔼的 DOS 操作环境。但是我们目前处于一个神奇的位置—— Z 盘！Z 盘是在哪里呢？抱歉我也不知道，也不想知道。 . 我们目前要做的就是定位到我们的项目文件夹。方法很简单，也有多种，这里我介绍最方便的一种，其他的读者可以自己探索。 把你的项目文件夹直接拖动到 Boxer 窗口中，Boxer会把你拖动的文件夹当成 C 盘挂载。 挂载成功后，就是这样的！ 输入 dir 我们可以浏览当前文件夹下都有哪些文件。 . ###编译并运行程序 编译文件用 masm 命令，如： . masm example.asm . 编译成功后会生成 .obj 文件，用命令 link 链接对应的文件生成可执行文件，如： . link example.obj . 运行生成的 .exe 文件即可！ .",
            "url": "https://invisprints.github.io/blog/others/2018/01/05/macOS-%E4%B8%8B%E7%94%A8-DOS-%E6%A8%A1%E6%8B%9F%E5%99%A8%E8%BF%9B%E8%A1%8C%E6%B1%87%E7%BC%96%E5%AE%9E%E9%AA%8C.html",
            "relUrl": "/others/2018/01/05/macOS-%E4%B8%8B%E7%94%A8-DOS-%E6%A8%A1%E6%8B%9F%E5%99%A8%E8%BF%9B%E8%A1%8C%E6%B1%87%E7%BC%96%E5%AE%9E%E9%AA%8C.html",
            "date": " • Jan 5, 2018"
        }
        
    
  
    
        ,"post22": {
            "title": "大津算法（OTSU）",
            "content": "大津算法（OTSU） . 在图像处理领域，我们会遇到如下需求：把图像中的目标物体和背景分开。比如背景用白色表示，目标物体用黑色表示。此时我们知道目标物体的灰度值相互接近，背景灰度值相互接近，那么用大津算法能很好把目标从背景当中区分开来。 . 算法思想 . 目标 . 比如对于下面这张灰度图片 目标物体是中间黑色的几何物体，我们想让这些物体和背景区分更明显一些，比如让物体为纯黑，背景全白。那么我们就需要找到一个合适的阈值，使图片上灰度值大于这个阈值的像素点为255（白色），灰度值小于阈值的像素点为0（黑色）。也就是变成下面这幅图： 那么大津算法需要处理的就是找到最佳的阈值，让目标和物体尽可能分离开。 . 灰度直方图 . 为了找到合适的阈值，我们首先观察原图的灰度直方图📊： 这是用 Matlab 对原图形成的灰度直方图，灰度直方图的含义是统计图像中不同灰度值的分布情况。由图我们可以看出两个尖峰，在灰度值为0～20的地方存在一个尖峰，代表原图中有大量像素点灰度值为0～20，经观察我们可以认为这部分对应于目标物体。同理我们可以看出背景的灰度值大多集中于100～140之间，为了让目标和背景区分更加明显，我们想让目标物体的灰度值全为0，背景的灰度值全为255，这种处理手法也称为二值化法。 . 那么阈值取多少合适呢？从图上看似乎取50～100中的任意一点都可以，但是实际情况并不想参考图那样明显，有些图片背景和目标物体较为接近，我们需要一个算法来找到最优阈值才行。 . 聚类 . 首先我们思考什么样的东西才能成为一类，而我们又是怎么分类的。对于参考图来说，我们可以认为灰度值接近的为一类，灰度值不接近的不是同一类。那我们又是如何衡量灰度值接近的程度呢？这里面就需要用到方差的概念。 方差相比大家都了解，同一类的物体方差小，不同类的物体方差大。所以对于此图我们希望分类的结果是对于灰度值相近的同一类物体，它的方差最小，称为类内方差最小。灰度值不接近的不同类物体，它的方差大，称为类间方差最大。 . 步骤 . 所以步骤总结如下： 首先我们要形成参考图的灰度直方图，这样方便我们找到最佳阈值。 接下来我们通过穷举每一个灰度值，计算以此为阈值的类内和类间方差。 找到能形成类内方差最小的或类间方差最大的阈值，这个就是我们要找的最佳阈值。 . 算法 . 下面以两类分割讲解下具体的算法，实际上大津算法可以分割多类出来。 . 我们定义$ delta_i^2 $为第 i 类的类内方差，$ delta_w^2 $为类内方差和，$ delta_b^2 $为类间方差和；$ omega_i$为第 i 类的概率分布，t 为当前假设的阈值，p(i) 为灰度值为 i 的概率密度。则对于 2 类问题： ω1(t)=∑0tp(i)δw2(t)=∑i=1i=2ωi(t)δi2 omega_1(t)= sum_0^t p(i) delta_w^2(t)= sum _{i=1}^{i=2} omega_i(t) delta_i^2ω1​(t)=∑0t​p(i)δw2​(t)=∑i=1i=2​ωi​(t)δi2​ 而最小化类内方差和最大化类间方差是相同的，即 δb2(t)=δ2−δw2=ω1(t)ω2(t)[μ1(t)−μ2(t)]2 delta_b^2(t)= delta^2- delta_w^2= omega_1(t) omega_2(t)[ mu_1(t)- mu_2(t)]^2δb2​(t)=δ2−δw2​=ω1​(t)ω2​(t)[μ1​(t)−μ2​(t)]2 类均值$ mu_1(t)$： μ1(t)=[∑0tp(i)∗i]/ω1 mu_1(t)=[ sum_0^t p(i)*i]/ omega_1μ1​(t)=[∑0t​p(i)∗i]/ω1​ . 遍历 t 所有的可能值，找到最小$ delta_w^2$或最大$ delta_b^2$所对应的 t 值，就是我们的最佳阈值。 . 代码实现 . C语言实现 . /* OTSU 算法 * *src 存储灰度图像，width 图像宽，height 图像长 * 返回最佳阈值 */ int otsu(const int *src, int width, int height) { int histogram[256]; //存储灰度直方图，这里为256色灰度 int t,thred; float wf,wb,ub,uf,curVal,maxVal; int sumb=0,sumf=0,sumW=0,sumPixel=width*height; wb=wf=maxVal=0.0f; //求灰度直方图 memset(histogram,0,sizeof(histogram)); for(i=0;i&lt;width*height;i++) { histogram[src[i]]++; } for (i=0;i&lt;256;i++) sumW+=i*histogram[i]; //枚举每个灰度 for(t=0;t&lt;256;t++) { //求两类类概率密度 wb+=histogram[t]; wf=sumPixel-wb; if (wb==0||wf==0) continue; //求类均值 sumb+=i*histogram[t]; sumf=sumW-sumb; ub=sumb/wb; uf=sumf/wf; //求当前类间方差 curVal=wb*wf*(ub-uf)*(ub-uf); if(curVal&gt;maxVal) { thred=t; maxVal=curVal; } } return thred; } .",
            "url": "https://invisprints.github.io/blog/others/2017/12/31/%E5%A4%A7%E6%B4%A5%E7%AE%97%E6%B3%95-OTSU.html",
            "relUrl": "/others/2017/12/31/%E5%A4%A7%E6%B4%A5%E7%AE%97%E6%B3%95-OTSU.html",
            "date": " • Dec 31, 2017"
        }
        
    
  
    
        ,"post23": {
            "title": "星轨拍摄：探索篇",
            "content": "星轨拍摄：探索篇 . 前段时间武汉天气异常晴朗，空气质量也出乎意料的差强人意，所以到了晚上，能看到不少✨。 作为一个资深的业余天文爱好者，怎么能放过这大好机会？！各种找关系之后终于从某土豪手中借来一台单反📷。 虽然不是专门用来拍星空🌃的单反，但是比上次用手机的穷酸样已经是天上地下了，争取下次扶摇直上九万里吧！ . 前期准备 . 因为这次要拍摄星轨，预计时间近 2 个小时，所以带上各种装备啦，吃的喝的玩的续命宝羽绒服手套等防寒的，总的来说就是要应付“漫长”和“寒冷”这两个关键词。 然后就是各种试参数，经过调查发现，我计划使用一个叫“星迹”的 APP 辅助完成，事后证明这是最大的败笔之一，没错后面还有败笔💔。 . 开拍 . 环顾华科四周，森林公园是个非常不错的拍摄场所，于是我在一个月黑风高之际，偷偷摸摸的潜入森林公园，架好设备，对准感兴趣的星空，开拍！ 需要注意的是夜晚真的很暗，在操作相机时我都是打着手电筒照明🔦，所以拍摄的时候避免一个人单独拍摄，拉上基友来难忘今宵！ 如果你的相机很智能，建议把什么自动降燥啊自动对焦之类的全部关闭，在夜空下这些东西会出很大的偏差，无法形成较好的效果。 快门时间要长，ISO 调低，广角很好。 冬季的星空最著名的就是猎户座了，四大亮星和三小星组成的猎户座，在冬季南方特别显眼。在作为一枚萌新，从他下手最好不过！如果你像我一样担心到时候认不出来，手机上下载个 Star Walk 2 - Night Sky Map是个非常好的选择。 然后我就犯了第二个错误，忘记对焦了。这个对焦有两种，如果画面中有近景的话对焦就对到近景上，否则找颗最亮的星星对焦。 按下开始拍摄的按钮后，就可以到一旁愉快的玩耍了。 这里要注意下按下快门时机身会有一定的抖动，如果你是马上拍摄的话就会造成一定的模糊。对于这个有两种解决方案： . 买个快门线，远程操作。 | 定时拍摄，开下快门后过一段时间才开始拍摄。 | . 身为一个吃了上顿愁下顿的穷苦学生，我肯定是采用第二种啦，不过经济条件可以的话最好用第一种。 拍星轨分两种，一种是超长快门时间拍一张出来，第二种是拍很多张快门时间较短的，然后合成一张图。我强烈推荐第二种，无论从可靠性还是可编辑性还是灵活性来说都是后者更好。 . 后期处理 . 就是用了垃圾的星迹 APP，居然生成 AVI 视频！还是这种视频！！不具有任何后期处理能力！！！ . 事后我研究了下，采用延迟模式拍摄多张图片就很好，不太建议大家用视频格式，因为可编辑能力跟多张照片比差远了。 . 效果图 . 星轨： 因方便浏览，我把 AVI 视频转成了 GIF 图片。 . 猎户座、金牛座和御夫座： 这张是我拍了多张照片后生成的全景图。 . 总结 . 这是我第一次带着单反拍摄夜空，遇到了很多问题，后来也思考了很多。对于星轨拍摄，总结起来就是以下几条： . 场地要选好。 | 防寒防寂寞。 | 星星要认准。 | 自动全关，ISO超低。 | 对焦2种方法。 | 拍摄2种模式。 | .",
            "url": "https://invisprints.github.io/blog/others/2017/12/24/%E6%98%9F%E8%BD%A8%E6%8B%8D%E6%91%84-%E6%8E%A2%E7%B4%A2%E7%AF%87.html",
            "relUrl": "/others/2017/12/24/%E6%98%9F%E8%BD%A8%E6%8B%8D%E6%91%84-%E6%8E%A2%E7%B4%A2%E7%AF%87.html",
            "date": " • Dec 24, 2017"
        }
        
    
  
    
        ,"post24": {
            "title": "macOS 下 OpenCV 环境搭建",
            "content": "macOS 下 OpenCV 环境搭建 . 因为专业的原因，需要搭建个图像处理的开发环境。上网研究了下相关资料，再结合符合中国特色社会主义的时代背景，决定在 macOS 下用 Clion 搭建 OpenCV 等图像开发环境。 . ##安装 Clion Clion 是 JetBrains 公司近几年推出的 C/C++ 跨平台 IDE，由于学生免费使用并且包含 Vim 插件，所以相对于 Xcode 神一般的操作逻辑，我最终选择了 Clion。 有人问为什么不用我最喜欢的 Vim 骚遍全场呢，原因是 Vim 擅长处理小项目和临时打开一些文件，对于这种图像处理之类的大项目，还是用 IDE 来的方便，当然必须要有 Vim 插件！！！ Clion 官方主页 下载地址 . ##安装 OpenCV 对于这种著名的开源的又不知道从何开始安装的鬼东西，我们一律用 HomeBrew 安装，省时省力又简单。 . brew install opencv . 安装的 OpenCV 版本应该是 3.3.1 或以后的。 . ##创建第一个项目 安装好后怎么用呢？其实我也不太会，照着网上的教程一步一步来呗。 . 用 Clion 创建一个空白项目。 | 打开 CMakeLists.txt 配置文件，增加如下语句 . find_package(OpenCV) include_directories( ${OpenCV_INCLUDE_DIRS} ) target_link_libraries( Myexe ${OpenCV_LIBS} ) . 其中 Myexe 替换成你的可执行文件的名称。 . | 将图片（如 demo.png）拷贝到项目的工作目录下（你也可以不拷贝，但是下面的图片路径就需要你自己指定）。 | 在 main.cpp 中输入如下代码: . #include &lt;iostream&gt; #include &lt;opencv2/opencv.hpp&gt; //调用 OpenCV 的库 using namespace cv; int main() { Mat image; // OpenCV 中图片格式为 Mat image = imread( &quot;../demo.png&quot;); //读取图片 if( image.empty() ) //检查是否读取成功 { std::cout &lt;&lt; &quot;Could not open or find the image&quot; &lt;&lt; std::endl ; return -1; } imshow(&quot;demo&quot;,image); //显示图片 waitKey(); return 0; } . | 运行程序，这下我们的第一个基于 OpenCV 的工程就搭建好了！ | ##OpenCV 进阶 更多的内容请访问OpenCV 官网教程，教程给得很详细，而且有可以练手的地方，是很好的入门教程。 .",
            "url": "https://invisprints.github.io/blog/others/2017/12/16/macOS-%E4%B8%8B-OpenCV-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA.html",
            "relUrl": "/others/2017/12/16/macOS-%E4%B8%8B-OpenCV-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA.html",
            "date": " • Dec 16, 2017"
        }
        
    
  
    
        ,"post25": {
            "title": "macOS 下根据当前应用自动修改快捷键",
            "content": "macOS 下根据当前应用自动修改快捷键 . 自从习惯了 iPad 外接键盘的快捷键，越发觉得 Caps Lock 进行中英文切换十分方便。但是作为多年的标准 Vim 党，把 Caps Lock 键映射成 ctrl(or esc) 键又是理所应当的事情。人民日益增长的美好需求和不平等不充分的系统功能发展的矛盾已经成为当今 Vimer 的主要矛盾👀。 . ##基本设置 先说说在察觉的 Caps Lock 方便的中英文切换之前我是怎么做的。利用系统自带的设置可以很方便地把 Caps Lock 键映射成你想要的其他修饰键 1 。 . ###方法 . 打开系统偏好设置。 | 点击键盘选项。 . | 在键盘标签页中点击右下角的修饰键。 | 将左边的键根据自己的需求重新映射成其他的修饰键吧。图中我把 Caps Lock 键重新映射成 Ctrl 键。 | ##新的矛盾 面临新的主要矛盾，最好的方法是去解决它而不是逃避它！经过我多年深入探索尝试，终于！！！！！ 就决定是你了！出来吧！皮卡丘！ 这位皮卡丘就是我们大名鼎鼎的 Karabiner-Elements。 先奉上深藏功与名的官方网页 . 这网页设计的清晰脱俗，比花花绿绿的 vim 官网直白多了。 . Karabiner-Elements . Karabiner-Elements 是大名鼎鼎的键盘自定义软件 Karabiner 后续之作，经过完全重新设计，性能得到大副优化，专门针对 macOS 10.12 和后面的更高峰！！2 . 由于这个软件笔者也不是太熟悉，所以这里就讲讲专门针对 vim 的基础设置吧，其他的靠官网介绍和各位读者的想象力了。 . ###简单配置方法 像这种系统辅助类软件基本都没有什么好看的界面的，一般都是在偏好设置填满密密麻麻的配置选项。所以我们先打开软件的偏好设置。 我的方法是添加了一个新的配置文件，这个配置文件专门针对 Vim 快捷键。编辑配置文件在 Profiles 标签页。这软件没有中文，所以你如果英语不好的话建议早点放弃 Vim 吧。孩子，永生的 Vim 不是你能掌握的！！ 就叫 VimMode！这名字听起来既装逼又不失一些细节，读者也可以按照自己的喜好来。 创建好配置文件后选中它，我们就进入了 VimMode 的设置中，然后作为该软件的一枚萌新🐶，我们就去 Simple Modification 标签页看看吧。 . 通过一些骚操作，我们把 caps_lock 键映射成 ctrl 键了，就下来，就可以愉快的玩耍了！在平时就用默认配置，vim 下就切换成 VimMode。 . ##人是贪得无厌的。。。 作为华科大自动化的人，怎么能忍手动切换这两种模式呢？一定要自动化！！！！ 经过无数个漫长的春夏秋冬，潮涨潮落，终于在一个月黑风高的夜晚，笔者的苦心感动了上天，于是晚上周公约笔者，说：“骚年，看你骨骼惊奇，不如我送你一部xx宝典吧！”笔者定眼一看，一个大大的 Command 键 Logo 赫然印出现在眼前，不错，就是这个东西！Keyboard Maestro!! . 作为 macOS 上最强大的自动化工具之一，多次让笔者产生了放弃 Alfred 的念头，最终笔者还是忍住了，因为没有时间学这个软件怎么用。 . ###自动切换 VimMode 切换两种配置文件就是修改 Karabiner-Elements 的配置文件，经专案组调查发现，这个隐秘的窝点在 . /Users/`whoami`/.config/karabiner/karabiner.json . 只需把文件中 “profiles” 下的 “name” 后的内容修改成相应的文件名即可。 我们可以写个脚本来修改后面的字符串，平常就是 “Default profile”，遇到特殊情况就修改成其他的，比如说 VimMode。 Keyboard Maestro 可以检测你当前用的软件，从而自动触发一些命令，我们可以利用这个特点，让 Keyboard Maestro 根据当前使用的软件自动激活指定脚本，从而修改 Karabiner-Elements 的配置文件。 . 这里直接拿了 Donie Leigh 的脚本做 demo，在此表示十分感谢！！！ 一键切换脚本访问地址 . 将这个脚本放到你喜欢的地方，比如我就放到了跟作案窝点相同的位置，然后打开 Keyboard Maestro 进行如下的配置： 嗯，就是这样，多的不需要解释了吧，当 Clion 或 Vim 处于激活状态时触发脚本。如果看不懂请到评论区留言，不过我估计应该不会有多少人看就是了😒😒 不过不要忘记了，有进就又出😏！当退出这两个软件时（或切换到别的软件时）我们要修改回默认配置，这个很简单，只需对着这个稍稍修改下就可以了，不懂请到评论区留言！！ . 接下来使用就很舒服了，自动切换，美滋滋！ . 据我观察，macOS 上修饰键指的是 Caps Lock, Ctrl, Option, Cmd, Esc 这五个键。 &#8617; . | 其实是原来的不兼容新系统，作者又懒得让软件适配这么多版本的系统，干脆重新开发个软件，老软件针对老系统，新软件针对新系统，省事！ &#8617; . |",
            "url": "https://invisprints.github.io/blog/others/2017/12/10/macOS-%E4%B8%8B%E6%A0%B9%E6%8D%AE%E5%BD%93%E5%89%8D%E5%BA%94%E7%94%A8%E8%87%AA%E5%8A%A8%E4%BF%AE%E6%94%B9%E5%BF%AB%E6%8D%B7%E9%94%AE.html",
            "relUrl": "/others/2017/12/10/macOS-%E4%B8%8B%E6%A0%B9%E6%8D%AE%E5%BD%93%E5%89%8D%E5%BA%94%E7%94%A8%E8%87%AA%E5%8A%A8%E4%BF%AE%E6%94%B9%E5%BF%AB%E6%8D%B7%E9%94%AE.html",
            "date": " • Dec 10, 2017"
        }
        
    
  
    
        ,"post26": {
            "title": "最小错误率贝叶斯决策",
            "content": "最小错误率贝叶斯决策 . 在一般的模式识别问题中，人们往往希望尽量减少分类的错误，即目标是追求最小的错误率。其中利用概率论中贝叶斯公式得到的分类决策被称之为最小错误率贝叶斯决策。 . . ##问题引入 在某个地区中人们常对细胞中某一种物质（特征观察值）进行检测，来判定它是否是正常细胞。通常情况下这种细胞是正常（w1 类）的可能性是0.9，是异常（w2 类）的可能性是0.1。现在有一种待观察的细胞，其特征观察值是 x。根据以往的结果，正常（w1 类）细胞中其特征观察值是 x 的可能性是0.2；异常（w2 类）细胞中其特征观察值是 x 的可能性是0.4。试判断该细胞是正常还是异常。 . ##分析 我们的目标是让我们出现错误的概率尽可能的低，也就是所谓的最小错误率[^wrong rate] 准则。 . 那么我们如何才能实现最小错误率？试想一下如果我们只知道这个细胞是正常的可能性有0.9，异常的可能性有0.1。那么我们会认为这是正常细胞，因为我们判断失误的概率只有0.1。相对于其他判断结果（认为这是异常细胞），我们实现了最小错误率。 . 事实上，上面说的 0.1 和 0.9 是在没有对样本进行任何观察情况下得到的概率，因此我们称它为先验概率。 . 现在我们观察细胞，知道它的特征值为 x，我们需要求在已知 x 的情况下细胞属于各类的概率，用 $P( omega _{i}|x)$ 表示，相信学过条件概率的都清楚这个意思。这种概率也称为后验概率。 所以对于两类问题，我们的决策思想是谁的后验概率大，我们就认为它属于哪类。 P(ω1∣x)&gt;&lt;P(ω2∣x),x∈{ω1ω2P( omega _{1}|x) begin{matrix}&gt; &lt; end{matrix}P( omega _{2}|x), x in begin{cases} omega _{1} omega _{2} end{cases}P(ω1​∣x)&gt;&lt;​P(ω2​∣x),x∈{ω1​ω2​​ . 那么怎么求后验概率呢？我们知道后验概率 $P( omega _{i} | x)$ 换一种求法是先求特征值是 x 且 属于 $ omega _{i}$ 类的概率 $p(x, omega _{i})$，也称为联合概率密度。再除以特征值是 x 的概率 p(x)，称为总体密度。而联合概率密度则是由类条件密度 $p( omega _{i} | x)$ 乘以先验概率 $P( omega _{i} | x)$ 得到。所以我们就得到经典的贝叶斯公式： | . P(ωi∣x)=p(x,ωi)p(x)=p(x∣ωi)P(ωi)p(x)=p(x∣ωi)P(ωi)∑j=1np(x∣ωj)P(ωj)P( omega _{i}|x)= frac{p(x, omega _{i})}{p(x)}= frac{p(x| omega _{i})P( omega _{i})}{p(x)}= frac{p(x| omega _{i})P( omega _{i})}{ sum_{j=1}^{n}p(x| omega _{j})P( omega _{j})}P(ωi​∣x)=p(x)p(x,ωi​)​=p(x)p(x∣ωi​)P(ωi​)​=∑j=1n​p(x∣ωj​)P(ωj​)p(x∣ωi​)P(ωi​)​ . 所以在问题引入中，我们只需求出 w1 和 w2 的后验概率，比较它们的大小即可1。 . ##未完待续 接下来还会介绍似然比，并用图形进一步解释贝叶斯决策，但最近学业繁忙，可能最近一段时间不会更新了。 . 此题答案是把 x 归于正常细胞。 &#8617; . |",
            "url": "https://invisprints.github.io/blog/others/2017/10/15/%E6%9C%80%E5%B0%8F%E9%94%99%E8%AF%AF%E7%8E%87%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%86%B3%E7%AD%96.html",
            "relUrl": "/others/2017/10/15/%E6%9C%80%E5%B0%8F%E9%94%99%E8%AF%AF%E7%8E%87%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%86%B3%E7%AD%96.html",
            "date": " • Oct 15, 2017"
        }
        
    
  
    
        ,"post27": {
            "title": "内网穿透",
            "content": "内网穿透 . 本文件只介绍用 frp 连接内网 VPN 服务器，其他的功能及实现方法还请到官网查看。 . 题外话 . 试用了下花生壳全家套，发现要钱且免费的不太好用，作为一名学生党当然是找开源免费的东西代替啦。之前发现 SoftEtherVPN 竟然自带内网穿透，欣喜之余发现所用的 VPN 协议竟是 SSTP，Apple 全家桶都不原生支持该协议，所以还是利用 frp 进行内网穿透。 . 注意！！！该方法只在某些机器上成功了，我在实际测试中遇到不少失败，如有网友发现错误，请及时指出，谢谢！ . frp 介绍 . frp 是一个可用于内网穿透的高性能的反向代理应用，支持 tcp, udp, http, https 协议。 Github 主页 . 访问内外 VPN . 由于 frp 的原理是端口映射，因此我们首先需要一台拥有外网 IP 的服务器，以此做中转，连接内网服务器。关于 frp 的实现原理可以查看项目主页了解。 . 由于我搭建的 VPN 协议用的是 L2TP over IPsec 协议，L2TP over IPsec 协议用的是 500 和 4500 端口，因此我们需要对这两个端口进行端口映射。 . 这里 frp 规定处于内网的机器是客户端，用 frpc 工具和 frpc.ini 配置文件。拥有外网 IP 地址的是服务端，用 frps 和 frps.ini 配置文件。 . 服务端配置 . 修改拥有外网 IP 服务器的 frps.ini 文件，下面是适合 L2TP over IPsec 协议的配置，如果是其他配置请做适当的修改。 . # frps.ini [common] bind_port = 7000 . 启动 frps： . ./frps -c ./frps.ini . ###客户端配置 frpc 内置了 http proxy 和 socks5 插件，可以使其他机器通过 frpc 的网络访问互联网。 启动 frpc，启用 http_proxy 或 socks5 插件(plugin 换为 socks5 即可)， 配置如下： . # frpc.ini [common] server_addr = x.x.x.x server_port = 7000 [vpn_port1] type = udp local_port = 500 remote_port = 500 [vpn_port2] type = udp local_port = 4500 remote_port = 4500 .",
            "url": "https://invisprints.github.io/blog/others/2017/09/24/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F.html",
            "relUrl": "/others/2017/09/24/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F.html",
            "date": " • Sep 24, 2017"
        }
        
    
  
    
        ,"post28": {
            "title": "在 Windows 上搭建 VPN 服务器",
            "content": "在 Windows 上搭建 VPN 服务器 . Windows 自带的功能以强大和难用著称，在搭建多次失败后果断转向第三方软件。本文适用于不想装 Linux 系统又有 VPN 需求的同学，同样需要注意，本方法不太适合翻墙。 . 介绍 . 之前在 Windows 上搞文件共享搞了半天都没成功，网上随便下了个脚本一下就成了。最近搞 VPN 也是一直不成，找个第三方软件就很轻松搭建成功。所以原生的真的不一定好。 本文介绍的软件是 SoftEtherVPN，虽然界面丑陋，但是免费且功能强大，算是凑合着用了。 . ##安装 安装和搭建之类的教程大家去网上找吧，一搜一大片，本篇不继续造轮子了。推荐几篇博文： SoftEtherVPN——轻松搭建VPN服务器 官网 其实软件安装完成后是有中文引导的啦，如果不是高级 VPN 需求按照软件的指引来就可以了。 . ##注意点 这才是本文的精华！！ 软件下载地址 选择软件主流电脑这样选就可以啦。 . 安装时注意引导程序似乎不会引导本地网桥设置，如果你用的是本机做 VPN 服务器的话需要对本地网桥进行设置。让 VPN 的虚拟网卡和服务器的网卡桥接。这样你就能访问 VPN 服务器所在的外网了。 . 动态 DNS 针对没有固定 IP 的服务器，开启动态 DNS 服务会给你分配一个SoftEther.ent的二级域名，这样就不需要花钱申请域名或静态 IP 了。需要注意的是，介绍中的 NAT 穿透功能有很大局限性，你可以当这个穿透功能不存在。 . VPN Azure 功能是真正实现内网穿透了的，最牛逼的在于他免费！！缺点是只支持 SSTP 协议，苹果家族的就很难使用了。iOS 端目前是不行的，macOS 上可以用 sstp-client 命令行工具或 isstp 图形界面来连接。 sstp-client: . brew install sstp-client . isstp 下载地址 . 默认的 VPN 服务器搭建好后只能使用 SoftEther VPN Client 连接，如果要让 iOS 等移动端连接的话，需要打开 IPsec / L2TP 设置。 . 另外如果要远程连接需要在管理用户选项中添加用户，这里面功能还是蛮强的。 . 如果想让 iOS 设备登录处于内网中的 VPN 服务器，可以试试神器 frp。我稍后会出一篇博文将如何使用 frp 访问内网 VPN 服务器。 .",
            "url": "https://invisprints.github.io/blog/others/2017/09/17/%E5%9C%A8-Windows-%E4%B8%8A%E6%90%AD%E5%BB%BA-VPN-%E6%9C%8D%E5%8A%A1%E5%99%A8.html",
            "relUrl": "/others/2017/09/17/%E5%9C%A8-Windows-%E4%B8%8A%E6%90%AD%E5%BB%BA-VPN-%E6%9C%8D%E5%8A%A1%E5%99%A8.html",
            "date": " • Sep 17, 2017"
        }
        
    
  
    
        ,"post29": {
            "title": "Vim 折叠",
            "content": "Vim 折叠 . 作为编辑器之神，Vim 怎么可能没有代码折叠功能呢？但是 Vim 的上手难度极高，想要有顺手的折叠功能可不是一件易事。 . . 目前版本参考官方文档，后面会逐渐加上自己的探索。 . Vim 折叠方式 . Vim 有 6 种折叠方式： . manual //手工定义折叠 | indent //用缩进表示折叠 | expr　 //用表达式来定义折叠 | syntax //用语法高亮来定义折叠 | diff //对没有更改的文本进行折叠 | marker //用标志折叠 | 手动折叠 . 通过手动告诉 Vim 哪些代码块需要折叠来实现功能。 在 vimrc 中添加如下配置： . set foldmethod = manual . 试一试: 把光标置于某一段落内，并键入: . zfap . 你将会看到该段落被一行高亮的文本所代替。你已经创建一个折叠了。 zf 是个操作 符，而 ap 是一个文本对象。你可以将 zf 操作符跟任何一个移动命令联用，为所经之处的文本创建一个折叠。 zf 也能在可视模式下使用。 . 若要再阅读那些文本，可以键入以下命令以打开该折叠: . zo . 你还可以用以下命令再关闭该折叠: . zc . 所有的折叠命令都以 z 开头。展开你的想像力，这个字母看起来就像一张折叠起来的 纸的侧面。而 “z” 后面可用的字母，由于采用了帮助记忆方法选择，很容易记得住: . zf F-old creation (创建折叠) zo O-pen a fold (打开折叠) zc C-lose a fold (关闭折叠) . 折叠可以嵌套: 一个含有折叠的文本区可以被再次折叠。例如，你可以折叠本节内每一段 落，然后折叠本章内所有的节。试试看。你将注意到，打开全章的折叠，会将节的折叠还 原得跟以前一样，有些打开，而有些关闭。 . 假定你已经创建了若干折叠，而现在需要阅览全部文本。你可以移到每个折叠处，并键入 “zo”。若要做得更快，可以用这个命令: . zr . 这将减少 (R-educe) 折叠。相反的操作是: . zm . 这将折叠更多 (M-ore)。你可以重复 “zr” 和 “zm” 来打开和关闭若干层嵌套的折叠。 . 如果你有一个嵌套了好几层深的折叠，你可以用这个命令把它们全部打开: . zR . 这将减少折叠直至一个也不剩。而用下面这个命令你可以关闭所有的折叠: . zM . 这将增加折叠，直至所有的折叠都关闭了。 . 缩进折叠 . Vim 通过文本的缩进来自动添加折叠，适用于 Python 和大纲。 在 vimrc 中添加如下配置： . set foldmethod = indent . 然后你可以用 zm 和 zr 命令增加和减少折叠。在下面这个例文上很容易看明白: . 本行没有缩进 本行被缩进一次 本行被缩进两次 本行被缩进两次 本行被缩进一次 本行没有缩进 本行被缩进一次 本行被缩进一次 . 注意 缩进多少和折叠深度之间的关系倚赖于 shiftwidth 选项。每个 shiftwidth 选项规定的缩进宽度，在折叠深度上加一。这被称为一个折叠级别。 . 当你使用 zr 和 zm 命令时，你实际上是在增加或减少 foldlevel 选项。你也可以直接设置它: . :set foldlevel=3 . 这意味着，所有缩进等于或大于 shiftwidth 三倍的折叠将被关闭。折叠级别设定得越 低，越多的折叠将被关闭。当 foldlevel 为零时，所有的折叠都将被关闭。 zM 把 foldlevel 设为零。相反的命令 zR 把 foldlevel 设为文件中最深的折叠级别。 . 因此，有两种方法开启和关闭折叠: . 设定折叠级别。 这提供了一种极快的 “缩小” 方法来查看文本结构，移动光标，以及重新 “放大” 到具体的文本。 . | 利用 zo 和 zc 命令打开和关闭指定的折叠。 这个方法允许你仅仅打开那些你要打开的折叠，而不影响其它的折叠。 . | . 这两种方法可以结合起来用: 你可以先用几次 zm 以关闭大多数折叠，然后用 zo 打开一个指定的折叠。或者，用 zR 打开所有的折叠，然后用 zc 关闭指定的折叠。 . 但是，当折叠方法 foldmethod 的值为 indent 时，你不能手动定义折叠。因为那样 会引起缩进宽度和折叠级别之间的冲突。 . 标志折叠 . Vim 通过事先添加的标志折叠代码块。 在 vimrc 中添加如下配置： . set foldmethod = marker . 语法折叠 . Vim 为每一种不同的语言使用一个不同的语法文件。语法文件为文件中各种不同语法项定义颜色。在语法文件中，你可以加入一些带有 “fold” 参数的语法项。这些语法项将定义折叠。 在 vimrc 中添加如下配置： . set foldmethod = syntax . zc 关闭折叠 zo 打开折叠 za 打开/关闭折叠互相切换 . 关闭 Vim 默认折叠 . 当我们选好自动折叠后，打开代码是就会发现 vim 默认把所有代码都折叠了，如果不想要这个选项，可以在 vimrc 添加如下配置关闭默认折叠： . set foldlevelstart=99 . 折叠插件 . vim 默认的折叠配置并不容易上手，对于 C++ 项目来说，vim 自带的语法折叠太过简单，很多地方都不能折叠，而我目前又不想去修改 cpp.vim 语法文件，经过大量搜索，终于找了一个增强版的折叠插件。 . 插件地址：GitHub 主页 . 安装 . 在 .vimrc 合适位置添加如下代码（Vundle 安装）： . Plugin &#39;LucHermitte/VimFold4C&#39; . 输入 . :PluginInstall . 等待安装完成。 . 使用 . 跟默认的一致，如果想要进阶，可以去项目主页看看。 .",
            "url": "https://invisprints.github.io/blog/vim/2017/09/03/Vim-%E6%8A%98%E5%8F%A0.html",
            "relUrl": "/vim/2017/09/03/Vim-%E6%8A%98%E5%8F%A0.html",
            "date": " • Sep 3, 2017"
        }
        
    
  
    
        ,"post30": {
            "title": "《自控力是训练出来的》",
            "content": "《自控力是训练出来的》 . 这是一本可以超快速阅读的书，是一本可以当做查阅手册和行动指南的书。 . . 题外话 . 无聊时看了看室友书架上的书，这种精心包装又符合当代社会的书自然吸引了我的目光，简单看下来，这本书有惊喜之处也有让人失望的地方。 这本书并不是那本很出名的《自控力》，我刚开始也被骗了，等我发现时书已经读了一大半，想想还是读完吧。 . 概述 . 本书以“自控力”为中心，配上关键字“训练”，构成整本书。通过一系列吸引人眼球的“风靡哈佛、耶鲁、斯坦福”，“决定人生命运的关键力量”和“职场精英成功掌控xxxx”的标题，告诉读者此书非同小可。理论洗脑 + 名言警句 + 训练手册 + 成功案例，全书架构清晰，思路流畅，层层递进，可以说是一本不错的畅销书。 . 结构 . 其实在概述部分已经点出本书的结构了，这本书的结构可以从两个方向来看，第一个方向从目录直接就可以看出，理论洗脑 + 名言警句 + 训练手册 + 成功案例，很简单的平铺结构。另一种要看完了才知道，是 why how what 结构。书从“为什么要训练自控力？”-&gt;“自控力怎样训练？”-&gt;“训练内容是什么？”层层递进，铺展开来构成全书。 . 内容 . 浅显易懂是这本书的最大优点，畅销书要做到畅销首先必须是语言简单，其实看完这本书后我意外发现这是本很不错的营销优秀范本。语言简单是这本书首要特点，以“风靡”、“哈佛、耶鲁、斯坦福”、“决定人生命运”、“精英”这些吸引人的词语放在标题，充分吸引读者。抓住当代人所缺乏的自控力，可以说找到一个很好的切入口。配以训练标题，在目前知识付费这个风口上可以说是恰如其分。简单翻翻书，书中说有重点都自动标注出来，稍稍看下，语言简单，训练轻松，给人一种10周就可以登上人生巅峰的感觉。不可否认，这是本典型的营销书籍。 书的内容还是可圈可点的，每一句话都说的很有道理，考虑了现代人渴望速成和零碎时间的现状，很有针对性得提出计划。首先语言简单，这样阅读速度就可以很快，迅速把前面理论篇章看过去，顺便给读者打了一剂鸡血，而在在理论篇章配以大量警句，都是可以马上行动的语言，给渴望速成的人提供建议。而后面的训练计划一个是10周，另一个是每个训练花费不了多少时间，这样就很符合当代人的生活节奏，能在短时间内有效果，而且并不影响当前的生活节奏，可以说是十分完美的训练手册。 虽然说很多人在经历了知识付费的浪潮后很反感这种“速成”的课程，因而对我上面推荐理由不以为然，但是他们并没有认识到当前这个社会的一些现状和个人成长的局限性。首先快节奏和时间碎片化是这个时代不能改变的东西，你如果想花大把大把的时间用在培训上，那只能脱离当前社会，隐居山林，这对大部分人来说是明显不可取的。其次是人在训练过程中是需要变化来鼓励自己的，一个很长时间看不到成果的训练或计划是难以维持下去的，因此才会有速成课程的兴起。所以我们既要认清当前的现状，同时又清楚速成只是一时，我们还需要长期训练加以配合，才能真正起到我们想达到的效果。 . 缺点 . 讲述方式是这本训练手册最大的败笔。书中大堆罗列名言警句，明显就不是想让我们一条条看下去的，只能当做本字典来查询，后面的训练部分也有这个问题。在“自控力与心智训练”的章节中，竟然大堆罗列枯燥无味的方法，太让我感到意外，值得欣慰的是第三章以后恢复了正常，具有一个训练手册该有的样子，不过语言过于平淡，难以让人激发想训练的冲动。 如果是我来写这本书的话，我肯定模仿市面上流行的记忆力训练手册来写，这样的话我相信训练意义更大。 . 其他 . 既然书看错了，那我以后肯定会补《自控力》这本书的，不过目前手上只有电子版，等开学的时候再看看吧。 .",
            "url": "https://invisprints.github.io/blog/reading/2017/08/25/%E8%87%AA%E6%8E%A7%E5%8A%9B%E6%98%AF%E8%AE%AD%E7%BB%83%E5%87%BA%E6%9D%A5%E7%9A%84.html",
            "relUrl": "/reading/2017/08/25/%E8%87%AA%E6%8E%A7%E5%8A%9B%E6%98%AF%E8%AE%AD%E7%BB%83%E5%87%BA%E6%9D%A5%E7%9A%84.html",
            "date": " • Aug 25, 2017"
        }
        
    
  
    
        ,"post31": {
            "title": "《金字塔思维 - 现代人精神健康之道》",
            "content": "《金字塔思维 - 现代人精神健康之道》 . 这是近年来我读过的最好的书，这是一本可遇不可求的书。 . . ##题外话 说来也巧，这本2000年的旧书是我在图书馆闲逛时无意发现的，当时只是打算消磨消磨时间，没想到看了一小段后根本刹不住车！比起之前看了又放弃的一大堆哲学入门书和什么现代生存法则，这本书不知道比它们高到哪里去了。 . 概述 . 正如书中前言所言，《金字塔思维》这本书“想提供给读者的是一种健康的思维方法”，告诉人们在现代社会应该如何看待各种社会现象和社会纷争，怎样在这个高速发展的社会寻找自身的价值和意义。书中以超级生动形象的言语启发人们如何把握生活节奏，如何形成积极向上的人生观价值观，可以当做大多数人的哲学启蒙书。相比于另一本哲学启蒙书——《中国哲学简史》，我认为本书更加通俗易懂，而且对现实的指导意义更大。 . 结构 . 我认为每个领域的入门书都应该是自顶向下设计的。先宏观再微观，有大方向到具体细节，这样看下来我才知道自己学了什么东西，可以用在什么方向。而不是像现在的主流教科书一样，自以为以小见大，从一个突破口突破。结果是学生学了半天不知道可以应用到哪个方向上，只会做特定情况的练习题。高中以上的教科书基本都有这个毛病，最严重的就是外国翻译过来的所谓经典教科书，没有一个适合入门，《计算机网络》除外。 . 正因为市场上的书籍很多都有这个毛病，所以目前产生了新的读书法，具体可看我的学习方法下的文章，总的说来就是找到这本书自顶向下的结构，然后按照这个顺序看。 . 最让我惊喜的是这本书的结构，真的是自顶向下，由有宏观到微观，从战略到战术的排版结构，想不到这本在2000年出版的书能有如此觉悟，直接吊打现在的很多畅销书。 . 《金字塔思维 - 现代人精神健康指导》的序讲作者的意图和书与众不同的地方；前言说明这本书想告诉读者的内容；书内容第一部分总论健康思维，从精神世界的重要性到寻找精神框架，从超越对抗到顺应天人再到探索命运，层层递进，环环相扣，逻辑严密，思维敏捷。读此书时，好像看一局棋，先把握盘面局势，了解整体布局，再看整体流程，了解发展趋势，然后层层拆解，知晓孰轻孰重，最后细看局部，探索其中玄机。正如此书所言： . 当一个人有了这种智慧，便能清晰地把握人生的道路，既不会盲目羡慕那些不属于自己可走的路，也不会对自己慎重选择的道路产生后悔。由此，你便能构筑稳固的精神框架，经得起各种人生的困境和考验。这就是现代精神健康的灵魂。 . 内容 . 内容的话我只能用形象生动，通俗易懂来形容，用书中序的话来说就是“以他深厚的理论功力，进入那极其纷乱繁杂千变万化的真实世界，以轻松自然的自然语言，引人入胜的中外历史典故，生动活泼的生活例子，道出他在抽象深奥的哲学理论领域多年探索的结晶。” . 关于书中的具体内容这里不再赘述，感兴趣的可以前往图书馆借阅，网上只有二手书卖。书中的一些感悟我可能会在后面的博文中写出来，不过不要抱太大希望，因为那意味着我得有时间看第二遍。 . 缺点 . 一本书不可能只有优点没有缺点，上面说了这本书这么多好的地方，下面谈谈我认为的不足之处。 . 首先将思维的肯定要受到历史和时代的影响，有其局限性，但是令我惊讶的是里面有些思想已经突破那个时代，对近年来一些社会问题和现象具有很强的指导意义，这是让我十分惊喜的，但是书中有部分内容对当今这个社会已经不太适用，需要读者警惕，不要一味按照书中的来，毕竟当时的作者肯定没有料到当今的移动互联网时代，更没有料到互联网对人生的重要影响。 . 然后就是这本书更像一味药而不是保健手册，多放下而少争取，多治疗而少预防，如果我们的思维本身就是比较健康的，那么看这本书就需要警惕，“是药三分毒。” . 还有个缺点就是这本书有不少错别字。 . 其他 . 这段时间还在看《自控力是训练出来的》，对比起来差距明显。《自控力》这本书看了后收获还是有，不过明显看出作者对书的设计规划思考不够。书中疯狂列出忠告啊建议啊，根本不考虑读者怎么吸收这些东西，如果是我设计《自控力是训练出来的》，我肯定写成一本训练指南。 .",
            "url": "https://invisprints.github.io/blog/reading/2017/08/19/%E9%87%91%E5%AD%97%E5%A1%94%E6%80%9D%E7%BB%B4-%E7%8E%B0%E4%BB%A3%E4%BA%BA%E7%B2%BE%E7%A5%9E%E5%81%A5%E5%BA%B7%E4%B9%8B%E9%81%93.html",
            "relUrl": "/reading/2017/08/19/%E9%87%91%E5%AD%97%E5%A1%94%E6%80%9D%E7%BB%B4-%E7%8E%B0%E4%BB%A3%E4%BA%BA%E7%B2%BE%E7%A5%9E%E5%81%A5%E5%BA%B7%E4%B9%8B%E9%81%93.html",
            "date": " • Aug 19, 2017"
        }
        
    
  
    
        ,"post32": {
            "title": "vim asyncrun",
            "content": "vim asyncrun . 利用 Vim8.0 新增的异步特性，可以让很多东西后台运行。瞬间 Vim 可以做很多很牛逼的事情。 . . 项目官网 . 安装 . 把 asyncrun.vim 丢进 ~/.vim/plugin 或 用 Vundle 安装，在 vimrc 合适位置添加下面语句 . Plugin &#39;skywind3000/asyncrun.vim&#39; . 简单使用 . 输入 :AsyncRun 后面跟其他命令就相当于在后台进行了。AsyncRun 的命令格式是 . :AsyncRun[!] [options] {cmd} ... . 例如： 用 gcc 编译： . :AsyncRun gcc % -o %&lt; :AsyncRun g++ -O3 &quot;%&quot; -o &quot;%&lt;&quot; -lpthread . 编译文件： . :AsyncRun make :AsyncRun make -f makefile . 搜索关键词： . :AsyncRun! grep -R word :AsyncRun! grep -R &lt;cword&gt; . ！的意思是禁止 quickfix 的自动滚动，可以删去看看区别。 . 代表光标下的单词。 生成标签： :AsyncRun ctags -R --fields=+S ctags 在大项目时生成较慢，让它在后台运行最适合不过，cscope 同理。此语句会让 ctags 在当前目录下生成标签。 ## 进阶 ### 项目根目录 vim 对于项目的多级目录管理不是很好，Asyncrun 能够设置项目根目录位置，方便项目的编译等操作。 :AsyncRun -cwd= make :AsyncRun make -f $(VIM_ROOT)/Makefile 上面的两条语句都是在项目根目录位置编译，而不是在当前工作目录处编译。其中项目根目录位置可配置。 #### 查找根目录 AsyncRun 会自动往上层查找含有 `.svn .git .hg .root .project` 的最近目录，并设置为项目根目录。如果没有找到，则自动设置当前工作目录为项目根目录。可用 :echo asyncrun#get_root(&#39;%&#39;) 打印项目根目录位置。 #### 配置根目录 可用如下语句告诉 AsyncRun 如何寻找根目录： :let g:asyncrun_rootmarkers = [&#39;.svn&#39;, &#39;.git&#39;, &#39;.root&#39;, &#39;.bzr&#39;, &#39;_darcs&#39;, &#39;build.xml&#39;] 也可以手动设置根目录位置： :let b:asyncrun_root = &quot;/xxxx/path-to-the-project-root&quot;",
            "url": "https://invisprints.github.io/blog/vim/2017/08/13/vim-asyncrun.html",
            "relUrl": "/vim/2017/08/13/vim-asyncrun.html",
            "date": " • Aug 13, 2017"
        }
        
    
  
    
        ,"post33": {
            "title": "BetterTouchTool",
            "content": "BetterTouchTool . BTT 作为 macOS 平台最为强大的触控板扩展插件，因其不友好的配置界面将很多用户拒之门外。本文为 BTT 入门之文，高级用法还需用户自己挖掘。 . 入门文章 . 看看这些就够了，再造轮子没啥意义。 Mac 触摸板增强神器：BetterTouchTool 上手指南 OS X系统 手势终极设置方法+BetterTouchTool详细设置中文翻译 . ##手势 这个是最重要的，必须在这做个备份。 . ###单手指 corner click bottom left 左下角单击 corner click bottom right 右下角单击 single finger tap top left 单指轻拍左上角 single finger tap top middle 单指轻拍上边中点 single finger tap top right 单指轻拍右上角 single finger bottom tap left 单指轻拍左下角 single finger bottom tap middle 单指轻拍下边中点 single finger bottom tap right 单指轻拍右下角 single finger tap left side middle 单指轻拍左边中点 single finger tap right side middle 单指轻拍右边中点 . ###双手指 tipap left 中指拍住中央食指轻拍面板 tipap right 食指拍住中央中指轻拍面板 pinchi in 两个手指捏 pinch out 两个手指放开 rotate left 张开两指以两指中心为圆轴逆时针 rotate righ 张开两指以两指中心为圆轴顺时针 scroll up (modifier key needed) 双指按滚动方向滑动(需设定下面的功能键) scroll down (modifier key needed) 双指按滚动方向相反滑动(需设定下面的功能键) tow finger swipe up 双指上划 tow finger swipe down 双指下滑 tow finger swipe left 双指左滑 tow finger swipe right 双指右滑 tow finger swipe from top edge 双指从上边缘下滑 tow finger swipe from bottom edge 双指从下边缘上滑 tow finger swipe from left edge 双指从左边缘右滑 tow finger swipe from right edge 双指从右边缘左滑 . ###三手指 three finger tap 三指轻拍 three finger double tap 三指双轻拍 three finger tap top 三指拍顶端 three finger tap bottom 三指拍底部 three finger click 三指点击 three finger swipe up 三指上划 three finger swipe down 三指下划 three finger swipe left 三指左划 three finger swipe right 三指右划 three finger clickswipe up 三指点击并向上滑 three finger clickswipe down 三指点击并向下滑 three finger clickswipe left 三指点击并向左滑 three finger clickswipe right 三指点击并向右滑 tow finger tip tap left 两指轻拍住，拍左 tow finger tip tap middle 两指轻拍住，第三拍中 tow finger tip tap right 两指轻拍住，第三拍右 tipswipe left finger up 右二指固定拍住，左一上滑 tipswipe left finger down 右二指固定拍住，左一下滑 tipswipe left finger left 右二指固定拍住，左一左滑 tipswipe left finger righ 右二指固定拍住，左一右滑 . ###四手指 four finger tap 四指轻拍 four finger double tap 四指双轻拍 four finger click 四指单击 four finger swipe up 四指上滑 four finger swipe down 四指下滑 four finger swipe left 四指左滑 four finger swipe right 四指右滑 three finger tiptop left 中指无名小拍住，食单击 three finger tiptop right 食中指无名拍住，小单击 . ###五手指 five finger tap 五手指轻拍 five finger click 五手指点击 five finger swipe up 五手指上滑 five finger swipe down 五手指下滑 five finger swipe left 五手指左滑 . ##注意 我在使用这个软件的时候，发现每次电脑休眠后 BTT 都会失效，必须重启才能继续使用，望读者注意。 .",
            "url": "https://invisprints.github.io/blog/software/2017/08/11/BetterTouchTool.html",
            "relUrl": "/software/2017/08/11/BetterTouchTool.html",
            "date": " • Aug 11, 2017"
        }
        
    
  
    
        ,"post34": {
            "title": "计算机网络： IPv6 简述",
            "content": "计算机网络： IPv6 简述 . IPv6 作为替代 IPv4 的协议，目前正在全球高速普及，它以近乎无穷的 IP 地址数和简单高效的结构被全球各大互联网企业推广。 . ##IPv6 来源 开发 IPv6 的起因是因为 IPv4 不够用了，我们知道 IPv4 的 IP 地址长度为 32bit，因此最多有 2^32 种，而且在 2011 年的时候 IPv4 已经被分配完了。目前已经无法申请获得新的 IPv4 的地址了，基于此原因，IPv6 应运而生。 . IPv6 与 IPv4 . 下面是一些 IPv6 与 IPv4 的对比。 . 描述 IPv4 IPv6 . 地址长度 | 32位 | 128位 | . 地址数 | 2^10 | 2^128 | . IP 报头 | 20~60可变长度 | 40固定长度 | . 分片/重组 | 由发送方（主机或路由器）对其分段，以适应要传输的下一链路 | 只能在源节点进行分段，且只能在目标节点完成重新装配。 | . 从上面的对比可以看出，IPv6 占用的空间更大，其可用数目也更多，而且它固定长度的报头和分片重组策略能加快数据包的处理。 . IPv4 迁移到 IPv6 . 虽然 IPv6 有诸多好处，但是目前整个互联网基本上是基于 IPv4 的，而且 IP 就像房子的基石一样，稍有不慎整栋大楼就会崩塌，所以目前 IPv6 的推广主要以下面两种形式展开。 . 双栈 . 这是目前最常用方法，使用该方法的 IPv6 结点还具有完整的 IPv4 实现，在于 IPv4 结点互操作时，使用 IPv4 数据报，与 IPv6 结点则使用 IPv6数据报。因此它同时具有 IPv6 和 IPv4 两种地址。 需要注意的是，如果发送方或接收方中任意一个（包括传输路径上的）仅支持 IPv4，则必须使用 IPv4 数据报。如下图，从 A 发往 F 只能用 IPv6，其原因是 IPv6 在转换成 IPv4 时一些特定字段会丢失。 . 隧道 . 这是前几年常用的方法。 但是建隧道这个方法解决了上面双栈面临的问题。假定两个 IPv6 结点中间经过 IPv4 路由器，如上图的 B 和 E，则把中间的 IPv4 路由器的集合当成隧道。在隧道发送端的 IPv6 结点可将整个 IPv6 数据报放到一个 IPv4 数据报的数据字段中。隧道接收端的 IPv6 结点最终收到该 IPv4 数据报，在确定了数据报中含有 IPv6 数据报后，从中取出 IPv6 数据报，再为该 IPv6 数据报提供路由，如下如所示： .",
            "url": "https://invisprints.github.io/blog/others/2017/07/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-IPv6-%E7%AE%80%E8%BF%B0.html",
            "relUrl": "/others/2017/07/23/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-IPv6-%E7%AE%80%E8%BF%B0.html",
            "date": " • Jul 23, 2017"
        }
        
    
  
    
        ,"post35": {
            "title": "Vim：函数名高亮",
            "content": "Vim：函数名高亮 . vim 设定高亮时发现函数名没有高亮，需要修改 c.vim 添加函数名高亮。 . Unix . 命令如下： . sudo vim /usr/share/vim/vim80/syntax/c.vim . 在文件末尾添加如下语句： . &quot;highlight Functions syn match cFunctions &quot; &lt;[a-zA-Z_][a-zA-Z_0-9]* &gt;[^()]*)(&quot;me=e-2 syn match cFunctions &quot; &lt;[a-zA-Z_][a-zA-Z_0-9]* &gt; s*(&quot;me=e-1 hi def cFunctions gui=bold guifg=yellowgreen . 最后一行表示函数的颜色，可以自行修改。 . macOS . 由于增加了 SIP 系统保护机制，需修改 /usr/share/vim/vim80/syntax/c.vim 下的文件，其他的仿照上面即可。 . 但是你会发现对于 MacVim 上面的设置并没有起效果，原因是 MacVim 的 vimfile 不是 /usr/share/vim80，而在 MacVim 应用程序中，路径 /Applications/MacVim.app/Contents/Resources/vim/runtime/ 所以修改该目录下的 c.vim 文件即可。 .",
            "url": "https://invisprints.github.io/blog/vim/2017/07/16/Vim-%E5%87%BD%E6%95%B0%E5%90%8D%E9%AB%98%E4%BA%AE.html",
            "relUrl": "/vim/2017/07/16/Vim-%E5%87%BD%E6%95%B0%E5%90%8D%E9%AB%98%E4%BA%AE.html",
            "date": " • Jul 16, 2017"
        }
        
    
  
    
        ,"post36": {
            "title": "计算机网络：分组交换和电路交换简述",
            "content": "计算机网络：分组交换和电路交换简述 . 最近在看《计算机网络》，从中选取了自己比较感兴趣的部分写下了自己的理解。 . . 分组交换和电路交换用于互联网中网络链路和交换机移动数据的方法。形象来说就是家里面路由器和公司里交换机传输网络数据的方法，他将电脑中的数据向互联网传输，接收互联网的数据并发往电脑。 . ##分组交换 分组交换简单说来就是数据先暂存到路由器中，待要发送的数据全部到位后，再发往网络。 我们可以假设一个数据包有多个比特组成。路由器接收数据是一个比特一个比特接收，而发送则是以数据包形式完整发送，所以在路由器没有收到完整数据包之前，它是会把之前接收到的数据暂存在路由器中，这个也叫存储转发传输。 我们可以把路由器当做车站，而每一个数据包当做大巴，每一个比特当做旅客。当一辆大巴上的旅客都到齐的时候，大巴就发车。 . ###排队时延和分组丢失 排队时延顾名思义，就是在排队的时候会有时间损耗。在这里的时延主要是指大巴等人的时间消耗和大巴在路上堵车的时间消耗。 大巴等人指的是路由器的转发存储机制，必须等整个分组收齐后再发送出去，等待的过程中会耗费不少时间。而堵车指的是路由器通过链路发送数据，数据在发送之前会检查该链路是否有其他数据正在发送，如果被占用的话则需等待，这也是消耗时间的。 . 分组丢失指的是车站的容量是有限度的，如果人数超过车站容量，自然有些人就上不了车，此时就发生分组丢失。数据在等待的过程中如果仍有数据源源不断地进入，此时就可能超出路由器的最大存储范围，就会发生数据丢失。 . ###转发表和路由选择协议 前文中提到的链路指的是本地和远程建立的数据交换通道。一台路由器不止一条链路，它可能同时与多个远程服务器建立连接。因此数据在发送的过程中就会选择相应的链路发送出去。 每一个将要发送的数据都会包含对方服务器的 IP 地址，而每台路由器都用一个转发表，负责将目的地址映射成输出链路。并且这个选路过程很奇特，不是一次性将选路的结果全部告诉你，而是只告诉前往下一个站点的路，到了下一个站点将会再次查找，在通往下一个站点。类似于司机问路，到下一个路口再问行人。 . 路径选择协议就是自动设置转发表的协议，可以达到使数据走最短路径的效果。 . ##电路交换 电路交换简单来说就是建立专属通道，数据来了直接发送，无需排队。 说实话我是看到这里居然有信号课的频分复用和时分复用才决定写这篇博文的。 . 由于是建立了专属通道，形象来就可以类比于铁轨，但是一条铁轨只能承载一种车型，其他的车不能行驶这条铁轨，因此降低了数据堵塞的可能。 . ###复用 采用频分复用和时分复用技术建立专属通道。 频分复用是指划分不同频段建立专属通道，比如频率为 0~4kHz 的用于通电话，频率为 4kHz~50kHz 用于上行通道，频率为 50kHz~1MHz 的用于下行通道。收音机调频收听广播也是用的这个原理，不同频率对应不同的广播台。 时分复用就是利用时间作为划分，不同的时间段对应不同的通道，比如每晚7点就是中央电视台的专属通道。7点35分就是天气预报专属时间。 . ##分组交换和电路交换的对比 分组交换由于有排队时延和分组丢失，因此他并不适合实时服务。但是由于不需要建立专属通道，因此它的复杂度更低，对资源（主要是带宽）的需求也更低。 由于人们往往不会在同一时间要求上网，而是在不同时间段联网，因此对于电路交换来说，大部分的时间专属通道都是闲置的，而分组交换则充分利用了带宽。所以对于同样的带宽大小，分组交换能容纳更多的用户。 对于现在数百个家庭共享同一个光纤的情况，我们可以看出目前越来越多采用分组交换的方式发展。 .",
            "url": "https://invisprints.github.io/blog/others/2017/07/13/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-%E5%88%86%E7%BB%84%E4%BA%A4%E6%8D%A2%E5%92%8C%E7%94%B5%E8%B7%AF%E4%BA%A4%E6%8D%A2%E7%AE%80%E8%BF%B0.html",
            "relUrl": "/others/2017/07/13/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C-%E5%88%86%E7%BB%84%E4%BA%A4%E6%8D%A2%E5%92%8C%E7%94%B5%E8%B7%AF%E4%BA%A4%E6%8D%A2%E7%AE%80%E8%BF%B0.html",
            "date": " • Jul 13, 2017"
        }
        
    
  
    
        ,"post37": {
            "title": "移动网络简述",
            "content": "移动网络简述 . 最近在研究 4G 和 5G 协议中的 RLC 部分，分享下自己学习的东西。 . . 架构 . 整个移动网络可以看做三个部分，基站、终端和基础设备。 . 基站 . 先解决个坑，这个简单的东西困惑了我很久。3G 基站叫 NB，LTE（4G）基站叫 eNB，5G 基站叫 gNB。 基站负责无线终端的通信传输。它从无线设备接收数据并向它发送数据。 . 终端 . 终端简称 UE，它就是无线设备，比如我们生活中的手机啊上网卡啊之类的。 . 基础设备 . 可以看做基站的后台，基站本身是做不了什么事情的，相关的网络传输都是由基础设备完成。 . 内部结构 . 这个主要说的是 UE 和 eNB 的内部处理结构。类似于著名的五层因特网协议栈和七层 ISO OSI 参考模型，移动网络由如下五层构成：SDAP, PDCP, RLC, MAC, PHY。 中文名字我觉得没必要了解，了解了也是不知道什么意思。RLC 层和 MAC 层的中文名字可以说一下，因为这样有助于理解。RLC 层中文意思是无线链路层控制协议，MAC 层是媒体介入控制层。 . RLC . RLC 层主要负责对不同数据采用相适应的协议发送和解析，可靠的协议传输慢，传输快的数据可靠性不高，RLC 就是对这些数据分配不同协议的。 RLC 传输有三种模式，分别是透明模式（TM），非确认模式（UM）和确认模式（AM）。 . 透明模式 . 这个最简单了，来什么我发送什么，不作任何处理，速度最快，但是没有任何数据的重复传输和丢失检测。 . 非确认模式 . 发送端会对将要发送的数据进行分级重组，以便让每一个分组得到最大利用，同时添加了数据的顺序。 接收端会对数据进行重排序，去除重复接收的并把数据按发送端的发送数据排好。然后再把数据交由上层处理。 该模式速度相对于透明模式慢了不少，但是数据有了顺序并且避免了重复接收。但是由于是单项通讯，不可避免数据丢失。 . 确认模式 . 发送端不仅将新数据进行分级重组发送，还会接收接收端的消息。也就是说，发送端和接收端会双向通讯。发送端会主动发送询问接收端没有收到相应的数据，如果没有发送端会重新发送数据。 接收端不仅要完成数据的去重复和排序，还要向发送段发送是否丢失数据，接收发送端发来的重传数据。 . 想要更深入了解直接看协议文档吧。我画了一个思维导图，估计有帮助大家理解。 .",
            "url": "https://invisprints.github.io/blog/others/2017/07/13/%E7%A7%BB%E5%8A%A8%E7%BD%91%E7%BB%9C%E7%AE%80%E8%BF%B0.html",
            "relUrl": "/others/2017/07/13/%E7%A7%BB%E5%8A%A8%E7%BD%91%E7%BB%9C%E7%AE%80%E8%BF%B0.html",
            "date": " • Jul 13, 2017"
        }
        
    
  
    
        ,"post38": {
            "title": "Vim: tagbar",
            "content": "Vim: tagbar . tagbar 是一个标签浏览的超有用的插件，它依赖 ctags，因此可以快速查看被 ctags 索引的标签，如函数名，变量、宏定义等。 . . 项目 GitHub . 安装 . 在 .vimrc 的 vundle 部分添加如下语句即可： . Plugin &#39;majutsushi/tagbar&#39; . 然后输入 :PluginInstall 安装。 . 使用 . 在被 ctags 索引的文件中输入 :TagbarToggle 即可启动 Tagbar，当然你可以为此设置快捷键。 令我惊讶的是它居然支持鼠标操作！点一下那个三角即可折叠或展开，标签也支持鼠标操作。 . 快捷键： 感觉常用的就是回车键，跳转到该文件下函数出现部分，其他就没啥常用的了。。。 .",
            "url": "https://invisprints.github.io/blog/vim/2017/07/13/Vim-tagbar.html",
            "relUrl": "/vim/2017/07/13/Vim-tagbar.html",
            "date": " • Jul 13, 2017"
        }
        
    
  
    
        ,"post39": {
            "title": "Vim: 编码问题",
            "content": "Vim: 编码问题 . Vim 的编码问题可以说是玄学问题，它总在我们最意想不到的时候出现。 Vim 中有四个设置与 Vim 编码相关，清楚这四个选项有助于处理编码问题。但是相信我，有的时候你就算搞清楚了这四个设置，在面临编码问题的时候依然会手足足措，特别是中文方面。 . . encoding . encoding 是 Vim 内部使用的字符编码方式。Vim 在工作的时候，如果编码方式与它的内部编码不一致，它会先把编码转换成内部编码。如果工作用的编码中含有无法转换为内部编码的字符，在这些字符就会丢失。因此，在选择 Vim 的内部编码的时候，一定要使用一种表现能力足够强的编码，以免影响正常工作。 . 由于 encoding 选项涉及到 Vim 中所有字符的内部表示，因此只能在 Vim 启动的时候设置一次。在 Vim 工作过程中修改 encoding 会造成非常多的问题。一般将encoding设置成 utf-8。 . termencoding . termencoding 是 Vim 用于屏幕显示的编码，在显示的时候，Vim 会把内部编码转换为屏幕编码，再用于输出。内部编码中含有无法转换为屏幕编码的字符时，该字符会变成问号，但不会影响对它的编辑操作。如果 termencoding 没有设置，则直接使用 encoding 不进行转换。 . fileencoding . 当 Vim 从磁盘上读取文件的时候，会对文件的编码进行探测。如果文件的编码方式和 Vim 的内部编码方式不同，Vim 就会对编码进行转换。转换完毕后，Vim 会将 fileencoding 选项设置为文件的编码。当 Vim 存盘的时候，如果 encoding 和 fileencoding 不一样，Vim 就会进行编码转换。因此，通过打开文件后设置 fileencoding，我们可以将文件由一种编码转换为另一种编码。但是，由前面的介绍可以看出，fileencoding 是在打开文件的时候，由 Vim 进行探测后自动设置的。因此，如果出现乱码，我们无法通过在打开文件后重新设置 fileencoding 来纠正乱码。 . fileencodings . 编码的自动识别是通过设置 fileencodings 实现的，注意是复数形式。fileencodings 是一个用逗号分隔的列表，列表中的每一项是一种编码的名称。当我们打开文件的时候，Vim 按顺序使用 fileencodings 中的编码进行尝试解码，如果成功的话，就使用该编码方式进行解码，并将 fileencoding 设置为这个值，如果失败的话，就继续试验下一个编码。 . 因此，我们在设置 fileencodings 的时候，一定要把要求严格的、当文件不是这个编码的时候更容易出现解码失败的编码方式放在前面，把宽松的编码方式放在后面。 . 例如，latin1 是一种非常宽松的编码方式，任何一种编码方式得到的文本，用 latin1 进行解码，都不会发生解码失败。当然，解码得到的结果自然也就是理所当然的“乱码”。因此，如果你把 latin1 放到了 fileencodings 的第一位的话，打开任何中文文件都是乱码也就是理所当然的了。一般用如下设置： . set fileencodings=ucs-bom,utf-8,cp936,gb18030,big5,euc-jp,euc-kr,latin1 .",
            "url": "https://invisprints.github.io/blog/vim/2017/07/09/Vim-%E7%BC%96%E7%A0%81%E9%97%AE%E9%A2%98.html",
            "relUrl": "/vim/2017/07/09/Vim-%E7%BC%96%E7%A0%81%E9%97%AE%E9%A2%98.html",
            "date": " • Jul 9, 2017"
        }
        
    
  
    
        ,"post40": {
            "title": "Vim: Session 和 viminfo",
            "content": "Vim: Session和 viminfo . Session 和 viminfo 用来保存上次的环境，如窗口布局、映射、标记、折叠等。 用了后才发现这玩意太 tm 强大了！用了 vim 这么多年还是对 vim 知之甚少。 . . 本文参考此篇文章，调整了一些顺序，增删了一些内容，更有助于初学者上手。 . ##Session Session 文件会保存当前环境的空口、缓冲区、目录、折叠、映射、标签页等信息。用如下命令创建 Session 文件： . :mksession [filename] . 缺省文件名 Session.vim 在重新打开项目的时候，输入如下命令恢复编辑环境 . :source [filename] . 注意！Session 文件无法保存由插件动态生成的窗口，在生成 Session 文件时，需要关闭。 . ###Session 进阶 Session 文件中保存的信息由 sessionoptions 选项决定。sessionoption缺省选项包括blank, buffers, curdir, folds, help, options, tabpages, winsize . ####Session文件能被 Windows 和 Unix 共同使用 在 Vim 中输入如下命令： . set sessionoptions+=slash set sessionoptions+=unix . slash把文件名中的’ ’替换为’/’；unix会把Session文件的换行符保存成 unix 格式。 . ####将工作目录设置为 Session 文件所在位置 Session 文件默认将当前目录设为工作目录，如果我们想让当前目录设为 Session 文件所在目录的话，用如下命令： . :set sessionoptions-=curdir :set sessionoptions+=sesdir . curdir指示目录为当前目录，sesdir指示目录为 Session 文件所在目录。 . ##viminfo viminfo 文件保存的信息由viminfo选项决定。其缺省选项在 Windows 和 Unix 中不同。viminfo 文件一般保存命令记录、搜索记录、输入记录、寄存器记录和文件标记。 vim 在退出时，默认保存一个 .viminfo 文件在用户主目录。使用如下命令手动创建一个 viminfo 文件。 . :wviminfo [filename] . [filename] 不可缺省。 载入 viminfo 文件用如下命令： . :rviminfo [filepath] .",
            "url": "https://invisprints.github.io/blog/vim/2017/07/09/Vim-Session%E5%92%8C-viminfo.html",
            "relUrl": "/vim/2017/07/09/Vim-Session%E5%92%8C-viminfo.html",
            "date": " • Jul 9, 2017"
        }
        
    
  
    
        ,"post41": {
            "title": "Wireshark 学习笔记",
            "content": "Wireshark 学习笔记 . 常见问题 . 在 macOS 环境下无法读取网卡信息 . 方法一：在命令行中以管理员权限打开 wireshark sudo wireshark。 | 方法二：在命令行中输入如下命令 chmod 777 /dev/bpf* 之后重启即可。 | .",
            "url": "https://invisprints.github.io/blog/others/2017/07/04/Wireshark-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html",
            "relUrl": "/others/2017/07/04/Wireshark-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html",
            "date": " • Jul 4, 2017"
        }
        
    
  
    
        ,"post42": {
            "title": "成甲：如何靠知识管理获得爆发式成长",
            "content": "成甲：如何靠知识管理获得爆发式成长 . 听后笔记，融合了一些人的摘要，在此表示感谢。 标题说明了内容。 . ##什么是知识 能够改变行动的信息 书本上的信息 记住的东西 . ###例子：谈判技巧 知识： . 狮子大开口 | 红白脸 | 虚拟竞争者 | . 运用1：买车 . 25万-&gt;15万 | 朋友劝价格还可以 | 问问老婆（实际上没有问） | 行动2：薪资待遇 . 同学100万 | 我要求不高，其他同学48万，上个项目38万 | ##知识价值 能够告诉别人这个知识怎么用，这个知识是什么 问问题：为什么能这样？原理？用在其他地方？ . ##跨界： . ###深刻理解已经有的知识 为什么狮子大开口能用在买车和薪资待遇？ . ###锚定效应 判定感觉事情上 . ###钻的更深，获得第一性原理 . 例子1:阅读《刻意练习》 实质：抓住心理表征练习 最高效学习方法：学习别人心理表征 . 例子2:改变员工培训方式 在团队内分享高手的心理表征 高手这么思考问题 . 例子3: 看牛人访谈实录，暴露思考过程；看原始版非修剪版，如乔布斯遗失访谈 社交活动：寻找圈子里最优秀的人，面对面沟通。怎么说，为什么说，怎么思考 行万里路，不如名师指路 . ##临界知识： 少数重要广泛影响力的知识 透过现象看到别人看不到的东西。少做what多问why/how层面 . 例子1： 流行事物：熟悉+意外，旧知识新名字 . 例子2:好好学习： 黄金思维圈：为什么要写书？ . 帮助别人高效学习 | 分享自己的经历 | . 临界知识： . 安全空间 | 书的高度设定门槛 | 站在该领域大师眼光看问题（查理芒格） | . 复利率效应：A促进B，B反过来又促进A . 好好学习是5年10年后都有用的 . 影响力：从众效应，稀缺效应，权威效应 . .",
            "url": "https://invisprints.github.io/blog/others/2017/06/21/%E6%88%90%E7%94%B2-%E5%A6%82%E4%BD%95%E9%9D%A0%E7%9F%A5%E8%AF%86%E7%AE%A1%E7%90%86%E8%8E%B7%E5%BE%97%E7%88%86%E5%8F%91%E5%BC%8F%E6%88%90%E9%95%BF.html",
            "relUrl": "/others/2017/06/21/%E6%88%90%E7%94%B2-%E5%A6%82%E4%BD%95%E9%9D%A0%E7%9F%A5%E8%AF%86%E7%AE%A1%E7%90%86%E8%8E%B7%E5%BE%97%E7%88%86%E5%8F%91%E5%BC%8F%E6%88%90%E9%95%BF.html",
            "date": " • Jun 21, 2017"
        }
        
    
  
    
        ,"post43": {
            "title": "Vim 自动补全",
            "content": "Vim 自动补全 . 虽然vim跟IDE相比智能补全是一个硬伤，但是对那些补全需求不那么挑剔的人，Vim的补全已经能应付绝大多数场景了。另外在非code领域的补全我还没有见过能跟Vim相抗衡的对手。 . [toc] . ##触发自动补全 常见的是用&lt;C-p&gt;和&lt;C-n&gt;，这两个命令已经能应付绝大多数的场景了。另外还有如下实用命令： . 命令 补全类型 . &lt;C-n&gt; | 普通关键字 | . &lt;C-x&gt;&lt;C-n&gt; | 当前缓冲区关键字 | . &lt;C-x&gt;&lt;C-i&gt; | 当前文件关键字 | . &lt;C-x&gt;&lt;C-]&gt; | 标签文件关键字 | . &lt;C-x&gt;&lt;C-k&gt; | 字典查找 | . &lt;C-x&gt;&lt;C-l&gt; | 整行补全 | . &lt;C-x&gt;&lt;C-f&gt; | 文件名补全 | . &lt;C-x&gt;&lt;C-o&gt; | 全能补全 | . 触发Vim的自动补全命令后，会弹出候选菜单，此时可以用C-n和C-p选择菜单下一项或上一项。 . ##与自动补全菜单进行交互 常用的有&lt;C-n&gt;, &lt;C-p&gt;, &lt;C-e&gt;。 . 按键操作 作用 . &lt;C-n&gt; | 使用补全列表下一个匹配项 | . &lt;C-p&gt; | 使用补全列表上一个匹配项 | . &lt;C-e&gt; | 退出自动补全 | . ##自动补全来源 ###缓冲区列表 缓冲区列表代表当前Vim会话打开的所有文件 可用如下命令查看缓冲区列表 . :ls! . ###包含文件 通过设置include选项让Vim了解相应语言的对应提示符。 . ###标签文件 如用 ctags 建立代码库索引，一是让浏览代码变得简单，二是产生一份可用于自动补全的关键字列表。 . 普通关键字补全会把上述的补全组合在一起，并生成补全建议。 而全能补全往往配合插件使用，从而提供更高级的补全方式。 .",
            "url": "https://invisprints.github.io/blog/others/2017/06/21/Vim-%E8%87%AA%E5%8A%A8%E8%A1%A5%E5%85%A8.html",
            "relUrl": "/others/2017/06/21/Vim-%E8%87%AA%E5%8A%A8%E8%A1%A5%E5%85%A8.html",
            "date": " • Jun 21, 2017"
        }
        
    
  
    
        ,"post44": {
            "title": "Vim 定制项目相关配置",
            "content": "Vim 定制项目相关配置 . vimrc 只有一个，对于不同项目，有时我们需要不同的配置文件，而又不想让vimrc过于庞大，这时有两种处理方法。 . ##方法一 在项目工程目录下建立文件，假设文件名为 workspace.vim。这个文件包含了该项目的一些配置。 . 在vimrc文件中插入下面这段话： . if filereadable(&quot;workspace.vim&quot;) source workspace.vim endif . 之后每次在该目录下启动vim时，vim都会自动加载该workspace.vim . ##方法二 利用会话文件。我还不太会，没试过。可以参考这篇文章 .",
            "url": "https://invisprints.github.io/blog/others/2017/06/21/Vim-%E5%AE%9A%E5%88%B6%E9%A1%B9%E7%9B%AE%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE.html",
            "relUrl": "/others/2017/06/21/Vim-%E5%AE%9A%E5%88%B6%E9%A1%B9%E7%9B%AE%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE.html",
            "date": " • Jun 21, 2017"
        }
        
    
  
    
        ,"post45": {
            "title": "LEDE 下安装 DNSCrypt",
            "content": "LEDE 下安装 DNSCrypt . 安装完成后加持 IPv6 的话目前就只有 Twitter 上不去了。 . 本文参考官方文档完成。 . ##安装 DNSCrypt . opkg update opkg install dnscrypt-proxy . 安装完成后还不能马上使用，需要一些配置。 ##配置 DNSCrypt DNSCrypt 的配置文件在 /etc/config/dnscrypt-proxy 不过我们一般不需要修改。 . 我们需要修改 DNSmasq 的一些配置让它接入 DNSCrypt。 编译文件 /etc/config/dhcp 设置这重要三行 . # option resolvfile &#39;/tmp/resolv.conf.auto&#39; option noresolv &#39;1&#39; list server &#39;127.0.0.1#5353&#39; . resolvfile 是使用 ISP 提供的 DNS 服务器，当然要隐去。 noresolv 是禁止使用 /etc/resolv.conf 中的 DNS 服务器。 第三行为使用 DNSCrypt。 . ##启动 DNSCrypt 接下来把 DNSCrypt 加入开机启动并重启 dnsmasq . /etc/init.d/dnscrypt-proxy enable /etc/init.d/dnscrypt-proxy start /etc/init.d/dnsmasq restart . 可以愉快使用啦！ . ##备注 如果想分流使用 DNS，国内用国内 DNS，国外用 DNSCrypt，请自行参考官方文档，本博文仅作入门使用。 如果遇到开机无法启动 DNSCrypt，参考官方文档解决。 .",
            "url": "https://invisprints.github.io/blog/others/2017/06/19/LEDE-%E4%B8%8B%E5%AE%89%E8%A3%85-DNSCrypt.html",
            "relUrl": "/others/2017/06/19/LEDE-%E4%B8%8B%E5%AE%89%E8%A3%85-DNSCrypt.html",
            "date": " • Jun 19, 2017"
        }
        
    
  
    
        ,"post46": {
            "title": "解决 iCloud 不自动下载文档的问题",
            "content": "解决 iCloud 不自动下载文档的问题 . 不知道为什么垃圾 Notability 不用 iCloud Drive，也不知道 Apple 的云服务为什么那么差，反正长时间不用 Notability 后 iCloud 上面的文档搞不下来了。 . 解决方案是强制从 iCloud 上下载文件。 . 通过 Finder 是无法直接进入 iCloud 的（注意 iCloud 和 iCloud Drive的区别！！！）。下面有几种方法进入iCloud，以 Notability 为例。 . ##方案一 用 spotlight 搜索 Notability 的 iCloud 文档，在 finder 打开，然后从上层文件夹中打开。这样就进入 Notability 的 iCloud 文件夹了。 . ##方案二 在 spotlight 中搜索 ~/Library/Mobile Documents/ZP9ZJ4EF3S~com~gingerlabs~Notability然后进入对应的文件夹。 . ##方案三 通过方案二我们可以看出 iCloud 的路径。通过 terminal 我们可以直接 cd 进入。 . 接下来就点击对应的文件开始手动下载，解决问题！！ . ##总结 方案一和三是通用解决方案，二是 Notability 官方给的方案。 .",
            "url": "https://invisprints.github.io/blog/others/2017/06/04/%E8%A7%A3%E5%86%B3-iCloud-%E4%B8%8D%E8%87%AA%E5%8A%A8%E4%B8%8B%E8%BD%BD%E6%96%87%E6%A1%A3%E7%9A%84%E9%97%AE%E9%A2%98.html",
            "relUrl": "/others/2017/06/04/%E8%A7%A3%E5%86%B3-iCloud-%E4%B8%8D%E8%87%AA%E5%8A%A8%E4%B8%8B%E8%BD%BD%E6%96%87%E6%A1%A3%E7%9A%84%E9%97%AE%E9%A2%98.html",
            "date": " • Jun 4, 2017"
        }
        
    
  
    
        ,"post47": {
            "title": "MiniEAP 交叉编译",
            "content": "MiniEAP 交叉编译 . MiniEAP 相对于原来的 Mentohust 更容易适配各个学校，并受到 mentohust 原作者推荐。 本文将在 Ubuntu 下将 MiniEAP 交叉编译到 lede 系统中。 . 本文参照这篇博文完成对 MiniEAP 的交叉编译，在此表示感谢！ . ##准备 将对应路由器 CPU 的 SDK、libpcap 源码、MiniEAP源码下载到 Ubuntu 中。我用的是斐讯K2路由器，在此提供相应的地址。LEDE-SDK-mt7620、libpcap-1.8.1、minieap。 . 为了方便说明，假设主目录位置为/home/admin/，上面所有文件均放置在主目录文件下，且压缩包均已解压。 . ##配置交叉编译环境 在命令行中输入如下命令 . export PATH=$PATH:/home/admin/lede-sdk-17.01.1/staging_dir/toolchain-mipsel_24kc_gcc-5.4.0_musl-1.1.16/bin . 这里不可以照抄，SDK 的文件夹名有所改动。最后测试的话 echo $PATH . ##交叉编译 libpcap 动态链接库 进入解压后的 libpcap 文件夹，输入如下命令 . ./configure --host=mipsel-openwrt-linux --with-pcap=linux . 如果出错，查看 --host= 后面的东西是否跟上一步中配置交叉环境中的 bin 里面的文件名开头一致。 没有问题的话开始编译 . make . 之后会在当前文件夹下得到 libpcap.a 的文件。 . ##编译 minieap 进入 minieap 文件夹并打开 config.mk，参照 MiniEAP 主页进行一些定制化配置。 在我的Ubuntu上，有 getifaddr 和 iconv 库文件。因此我的 config.mk 配置如下： . #### Choose/Add your modules here #### PLUGIN_MODULES := packet_plugin_printer packet_plugin_rjv3 # Linux #PLUGIN_MODULES += if_impl_sockraw # macOS / BSD # PLUGIN_MODULES += if_impl_bpf # Other OS PLUGIN_MODULES += if_impl_libpcap # This implementation is not included in the code. # If you need it, add it yourselves. # PLUGIN_MODULES += ifaddrs ENABLE_DEBUG := false ENABLE_ICONV := true STATIC_BUILD := true # If your platform has iconv_* integrated into libc, change to false # Affects dynamic linking LIBICONV_STANDALONE := false CUSTOM_CFLAGS := CUSTOM_LDFLAGS := CUSTOM_LIBS += /home/work/libpcap-1.8.1/libpcap.a CC := mipsel-openwrt-linux-gcc # Example for cross-compiling # CC := arm-brcm-linux-uclibcgnueabi-gcc # ENABLE_ICONV := true # CUSTOM_CFLAGS += -I/home/me/libiconv-1.14/include # CUSTOM_LIBS += /home/me/arm/libiconv.a # PLUGIN_MODULES += ifaddrs # STATIC_BUILD := true . 保存后输入 . make . 编译出可执行文件。 . ##备注 这是我第一次尝试交叉编译，如有问题尽管指出。 编译后的 MiniEAP 有些 bug，比如不能自动生成配置文件，需要手动在 /etc/minieap.conf中填写相应信息。填写要求参考 MiniEAP 项目主页。 我编译好的版本在这里 密码 7dv9 .",
            "url": "https://invisprints.github.io/blog/others/2017/06/03/MiniEAP-%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91.html",
            "relUrl": "/others/2017/06/03/MiniEAP-%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91.html",
            "date": " • Jun 3, 2017"
        }
        
    
  
    
        ,"post48": {
            "title": "用路由器连上 IPv6 网络",
            "content": "用路由器连上 IPv6 网络 . 本教程极其适用于华中科技大学的学生，为了在华科用上 IPv6 我也是焦头烂额了一周。 对于其他地方的人群，本文具有一定参考价值。 . 华科的 IPv6 首先它并不免费，按网络中心的说法如果你使用 ipv6 他会奖励你两周。这个奖励我呵呵一笑。 . 电脑上可以轻而易举用上IPv6网络，请自行寻找方法。 . 到目前为止（2017-04-13），华科大部分地方的无线网均会给你的终端分配IPv6地址，但是除了刚刚装上无线网不久的宿舍片区，其他地方你基本连不上IPv6。我科就是这么神奇，不知道这个BUG要多久才能修复。 . 本人试过极路由自带的 IPv6 插件和华硕固件，均没有成功。望在这两个环境下成功了的人告诉我搭建方法，本人不胜感激！ . 路由器环境 OpenWrt15，刷机方法请自行搜索。或者等我心情好的时候贴出。 . 安装 mentohust . 这个软件用来解决锐捷登录的问题。我用的是该版本的软件 大家可以按照教程自己编译一下。 需要注意的是，在Linux环境中编译的文件不一定能在OpenWrt中跑，需要交叉编译才能保证软件的正常运行。 交叉编译：在这里的意思是模拟OpenWrt中的环境对源码进行编译，保证软件的正常运行。 . 但是我在编译中遇到了一些玄学上面的问题，编译不成功。由于我的路由器是 MT7620CPU 的路由，所以我从网上找到一个在该环境下编译成功的 mentohust 上传到路由器当中。下载地址 . 建议大家看看 mentohust 的使用说明后再进行配置。华科的在连上路由器并上传完 mentohust 后，在 /etc/mentohust.conf/ 填入如下信息 . [MentoHUST] Username=校园网 Password=登录密码 Nic=eth0.2 #这个具体看网卡 IP=0.0.0.0 Mask=0.0.0.0 Gateway=0.0.0.0 DNS=0.0.0.0 PingHost=0.0.0.0 Timeout=8 EchoInterval=30 RestartWait=15 MaxFail=8 StartMode=0 DhcpMode=2 DaemonMode=2 ShowNotify=0 Version=0.00 DataFile=/etc/mentohust/ dhcpscript=nil . 再启动 mentohust 就可以登录校园网了。 . mentohust 开机启动 在 /etc/init.d/ 新建 mentohust 文件，内容为 . #!/bin/sh /etc/rc.common # /init.d/mentohust START=99 STOP=10 start() { /root/mentohust } stop() { /root/mentohust -k &amp; } restart() { stop start } . 保存并修改文件权限为755 建立软连接 . ln -s /etc/init.d/mentohust /etc/rc.d/S99mentohust . ##配置IPv6 由于华科是认证后才有的 IPv6 地址，因此设置不像无需认证的简单。 虽然IPv6不倡导一种用 NAT 内网转发，但是在华科我还没见到用其他方法能行的。 . 大家参考这篇文章即可，写的很详细。 . 后面是这篇博客的本地实现版。 . 下面的是在路由器 web 中实现的方法，ssh后台登录配置也可以实现。 . . 在系统-&gt;网络中搜索 ip6tables、kmod-ipt-nat6这两个包，如果没有安装，则搜索安装。 . . 网络-&gt;接口：清空IPv6 ULA-Prefix一栏，保存&amp;应用。 . 这会删除 /etc/config/network 中 config globals &#39;globals&#39; 下的 option ula_prefix 条目 . . 网络-&gt;接口-&gt;WAN：设置你的IPv4外网接口参数。华科童鞋不用MAC绑定不用管。 WAN口其他参数依据你的网络配置。 保存&amp;应用 . . 网络-&gt;接口-&gt;WAN6：设置你的IPv6外网接口参数。 . 去掉“使用端局通告的DNS服务器”，填入学校的支持IPv6的DNS服务器，或者用下面的DNS服务器： . Google：2001:4860:4860::8888      2001:4860:4860::8844 HE.net DNS：2001:470:20::2 OpenDNS：2620:0:ccc::2      2620:0:ccd::2 . 保存&amp;应用 . 这会在 /etc/config/network 中 config interface &#39;wan6&#39; 下添加 option dns &#39;2001:4860:4860::8844 2620:0:ccd::2 2001:470:20::2&#39; 条目 . . 网络-&gt;接口-&gt;LAN，禁用 IPv6 assignment length（让 odhcpd 分配 IPv6 地址） . IPv6地址填写：AAAA:BBBB:CCCC:DDDD::1/64（这个内网地址可以随便改A:B:C:D::1/64也行） . IPv6 Routed Prefix：AAAA:BBBB:CCCC:DDDD::/64（上边的地址去掉末尾的1） . 这会在 /etc/config/network 中 config interface &#39;lan&#39; 下添加 option ip6addr &#39;aaaa:bbbb:cccc:dddd::1/64&#39;  和 option ip6prefix &#39;aaaa:bbbb:cccc:dddd::/64&#39; 条目 . . 勾选下方Always announce default Router . 这会在 /etc/config/dhcp 中 config dhcp &#39;lan&#39; 下添加 option ra_default &#39;1&#39; 条目 DHCPv6-Mode 改为 Stateful-only（关闭内网 SLAAC，简化网络，此项可以不做） . 这会在 /etc/config/dhcp 中 config dhcp &#39;lan&#39; 下 修改 option ra_management 参数为’2’ . 保存&amp;应用 . . . 网络-&gt;防火墙-&gt;通信规则：取消最后一项 Allow-ICMPv6-Forward 的勾选。避免不必要的ICMPv6转发。 . 保存&amp;应用 这会在 /etc/config/firewall 中 Allow-ICMPv6-Forward 规则下添加 option enabled &#39;0&#39; 条目 . 系统-&gt;启动项：填写修改后的启动脚本，本文最后贴出。该脚本负责添加 NAT 的防火墙伪装和 IPv6路由表。 提交。 . 脚本会被写入到/etc/rc.local中 . 注意：此脚本开机尝试99次获取wan口IPv6地址，若失败则不再添加IPv6路由表。 . . 点此测试你的IPv6配置 . 启动脚本： . #!/bin/sh /etc/rc.common # NAT6 init script for OpenWrt // Depends on package: kmod-ipt-nat6 ip6tables tracepath6  # Ref:  https://wiki.openwrt.org/doc/howto/ipv6.nat6 MAX_TRIES=99 WAN6_NAME=&quot;wan6&quot; #eth0.2 by default WAN6_INTERFACE=$(uci get &quot;network.$WAN6_NAME.ifname&quot;) #e.g. aaaa:bbbb:cccc:dddd::/64 LAN_IP6PREFIX=$(uci get network.lan.ip6prefix) #e.g. ddc2:d512:65f5::/48 #LAN_ULA_PREFIX=$(uci get network.globals.ula_prefix) PROBE=0 COUNT=1 while [ $PROBE -eq 0 ]         do         if [ $COUNT -gt $MAX_TRIES ]         then             logger -t NAT6 &quot;No IPv6 route found (reached retry limit $MAX_TRIES times)&quot; &amp;&amp; exit 1         fi         sleep 5         logger -t NAT6 &quot;Probing IPv6 route ($COUNT time)&quot;         COUNT=$((COUNT+1))         PROBE=$(route -A inet6 | grep -c &#39;::/0&#39;) done #ip6tables -t nat -I POSTROUTING -s &quot;$LAN_ULA_PREFIX&quot; -o &quot;$WAN6_INTERFACE&quot; -j MASQUERADE ip6tables -t nat -I POSTROUTING -s &quot;$LAN_IP6PREFIX&quot; -o &quot;$WAN6_INTERFACE&quot; -j MASQUERADE #WAN6_GATEWAY=$(route -A inet6 -e | grep &quot;$WAN6_INTERFACE&quot; | awk &#39;/:: /0/{print $2; exit}&#39; #get gateway from routing table.  !!!Caution!!! May not work ! WAN6_GATEWAY=$(ifconfig eth0.2 | grep &#39;Global&#39; | awk &#39;{print $3}&#39;| awk -F&#39;:&#39; &#39;{print $1&quot;:&quot;$2&quot;:&quot;$3&quot;:&quot;$4&quot;::1&quot;}&#39;) #caculate gateway from wan ipv6 #WAN6_GATEWAY=$(tracepath6 -n tv.byr.cn | grep &#39; 1: &#39; | awk &#39;NR==1 {print $2}&#39;) #opkg install iputils-tracepath6 .  change tv.byr.cn for faster site.   e.g. ipv6.bjtu.edu.cn #route -A inet6 add 2000::/3 gw &quot;$WAN6_GATEWAY&quot; dev &quot;$WAN6_INTERFACE&quot; route -A inet6 add default gw &quot;$WAN6_GATEWAY&quot; dev &quot;$WAN6_INTERFACE&quot; logger -t NAT6 &quot;Done with IPv6 settings&quot; exit 0 .",
            "url": "https://invisprints.github.io/blog/others/2017/06/01/%E7%94%A8%E8%B7%AF%E7%94%B1%E5%99%A8%E8%BF%9E%E4%B8%8A-IPv6-%E7%BD%91%E7%BB%9C.html",
            "relUrl": "/others/2017/06/01/%E7%94%A8%E8%B7%AF%E7%94%B1%E5%99%A8%E8%BF%9E%E4%B8%8A-IPv6-%E7%BD%91%E7%BB%9C.html",
            "date": " • Jun 1, 2017"
        }
        
    
  
    
        ,"post49": {
            "title": "《番茄工作法图解》",
            "content": "《番茄工作法图解》读书感悟 . 花了一个小时看完，写一下自己的感受。 番茄工作法简单易上手，很容易改善目前的生活。但是如果还想往上达到一个新高度，就需要深入了解番茄工作法。 . ##第一阶段 关键词： 25min，5min，专心 . 无需多阐释，这时番茄工作法易上手的根本原因，实施起来极简单。 . ##第二阶段 关键词：最重要，一次一个，每天计划，预估，马上停止，回顾番茄，防止打断，计划外紧急，新番茄计划。 . 这部分需要做一下说明：每次番茄都要完成当前最紧急的事情，这样让让你全心全意投入进去，而不会分心想我还有**没有完成。 一个番茄完成只完成一件事情，因为切换工作会造成大脑中断，大脑切换到另一个工作是需要时间的，在短短的25min内切换工作是无法达到高效学习的目的。还有这样的好处是留有时间过度学习，过度学习将在第三阶段阐述。 每天早上计划今天的任务，不要太多，完不成计划没有意义，一天能达到8个番茄就已经很好了，每天制定一定数量的番茄并坚持每天完成。长期下来会越来越有成就感，拥有好的状态。 既然有计划就有预估，判断每个任务的番茄数是关键。因为一天很少超过8个番茄，因此一个任务最好不要超过7个番茄，学会细分任务。合理的预估是保证能按时完成番茄的关键。 正如在番茄时间不能中断，到了休息时间应该马上停止。如果担心思路中断，可以先做个标记。马上停止手上工作开始休息的理由是保证下个番茄的高效进行，人长时间高精力的工作是会折寿的。 每天晚上需要回顾今天的番茄，对计划和预估做适当评价，看看有没有什么不合适的，有没有什么新发现，有没有哪里做的很好的。保证未来的番茄能够高效进行。 正如一个番茄只做一件事一样，为了保证番茄钟内高效工作，我们要尽量防止自己的番茄钟被内部或外部因素打断。让大脑处于高速运行状态。 如果遇到十分重要的事情，可以先把这件事记下来，接着进行当前的番茄钟。等番茄钟结束后再规划新的番茄来完成这个重要的事情。切忌在休息时间内完成重要事情。 如果遇到必须要打断的事情，那么当前的番茄钟作废。 . ##第三阶段 关键词：条件反射，回顾收获，连续工作，过度学习，合理休息。 . 正如我们闻到香味会流口水一样，让自己关于番茄钟形成一定的条件反射有助于自己高效工作。如在番茄开始时播放时钟滴答声，或者重复一些相同动作。长期以往后，每次在进行这些动作时，大脑就会高速运转并集中精力。 每天总结时告诉自己今天收获了什么，按照记忆曲线规律，帮助自己收获今天有价值的东西，能快速帮助自己提高。 不要让休息时间太长，避免每次开始番茄时都像从头开始一样，最好多个番茄排在一起，这样能保证工作持续高效进行。 番茄钟还没结束但任务已经完成了，这时候切换到其他任务没有意义。不如对刚刚完成的任务进行总结反思，有时候会有意想不到的收获。 为了保证番茄钟内能高效工作，休息时间一定要休息。离开位置走一走，趴在桌上休息会儿，让脑袋尽量放空，少思考。 .",
            "url": "https://invisprints.github.io/blog/reading/2017/05/24/%E7%95%AA%E8%8C%84%E5%B7%A5%E4%BD%9C%E6%B3%95%E5%9B%BE%E8%A7%A3-%E8%AF%BB%E4%B9%A6%E6%84%9F%E6%82%9F.html",
            "relUrl": "/reading/2017/05/24/%E7%95%AA%E8%8C%84%E5%B7%A5%E4%BD%9C%E6%B3%95%E5%9B%BE%E8%A7%A3-%E8%AF%BB%E4%B9%A6%E6%84%9F%E6%82%9F.html",
            "date": " • May 24, 2017"
        }
        
    
  
    
        ,"post50": {
            "title": "《高效阅读》",
            "content": "《高效阅读》 . ##消除回读 阅读环境： 光线适中、漫射灯光 . 阅读姿势： 背靠椅背，低头垂肩，书与眼睛45度 . 消除回读： 用手做引导物（反复练习） 一次比一次更快（消除默读） . ##提高理解力 找出每段主题句 大量练习：阅读-&gt;回忆-&gt;复读-&gt;回忆 . ##阅读理念 阅读可以有不同方法 阅读不需要从头到尾 阅读可以反复读 阅读要有阅读目的 . ##回忆能力 神奇之线（斜线+关键词） . ##扩展阅读速度 线性阅读：2/3倍练习 手指移动：只移动手腕以上部分 . ##了解写作技巧 非小说文学：先两头后中间 . ##刷页技巧 手掌朝下来回摆动 . 不按顺序阅读 消除默读 信号词 其他阅读方法 提前组织 改变练习态度 阅读小说技巧 手动法 游戏一样阅读 目的性阅读 阅读计划 图形记忆法 已知技巧 复杂文章 特殊训练 报纸 信件 杂志与新闻 .",
            "url": "https://invisprints.github.io/blog/reading/2017/05/22/%E9%AB%98%E6%95%88%E9%98%85%E8%AF%BB.html",
            "relUrl": "/reading/2017/05/22/%E9%AB%98%E6%95%88%E9%98%85%E8%AF%BB.html",
            "date": " • May 22, 2017"
        }
        
    
  
    
        ,"post51": {
            "title": "用手机拍星星",
            "content": "用手机拍星星 . 最近在上《天文漫谈》公选课。想在森林公园拍星轨玩玩。本来想用单反拍的，无奈四处借不到，只好用手机凑合凑合。 设备：iPhone 6, iPad pro 9.7 . ##效果图 . . 给第一张图稍稍做点注释吧： . ##方法 第一张图是用iPhone 6 拍的，软件 Camera+ 超长曝光30s拍摄。 . 第二张图用的 iPad Pro 9.7寸 拍摄，用的软件 NightCap Pro 设置调整为星轨模式，大约拍摄了半小时。 . ##总结 用手机拍摄出来的效果差强人意，由于是第一次拍摄，所以很多都是在拍摄现场探索出来的。比如我们没有三脚架，直接把 iPad 靠在凳子上完成拍摄，导致的结果是画面没有北极星。还有不知道软件设置对不对，因此先花了半小时探索软件的功能和拍摄效果，导致后面拍摄星轨的时间过短。下次应该就不会这么仓促了。另外 NightCap Pro 没有过几秒再开始拍摄的设置，因此如果用手点屏幕的开始按钮的话容易造成最后成像模糊，解决方法是用耳机线控制。 .",
            "url": "https://invisprints.github.io/blog/others/2017/04/30/%E7%94%A8%E6%89%8B%E6%9C%BA%E6%8B%8D%E6%98%9F%E6%98%9F.html",
            "relUrl": "/others/2017/04/30/%E7%94%A8%E6%89%8B%E6%9C%BA%E6%8B%8D%E6%98%9F%E6%98%9F.html",
            "date": " • Apr 30, 2017"
        }
        
    
  
    
        ,"post52": {
            "title": "用 ffmpeg 批量合并视频",
            "content": "用 ffmpeg 批量合并视频 . 我们有的时候会遇到需要将大量视频合并的任务，特别是在处理网络上抓取的视频方面。 本文讲述了在 macOS 环境下用 ffmpeg 合并大量视频。 Windows 和 Linux 都有这个工具。 . ##安装 ffmpeg 一般用 brew 安装 . brew install ffmpeg . ffmpeg 简介 . ffmpeg 是一个视频编码处理的神器。 其他请看官网 . ffmpeg基本使用 . 转换视频格式，如从 mp4 转化成 avi。 . ffmpeg -i input.mp4 output.avi . ##批量合并视频 ffmpeg 需要知道被合并视频的位置和顺序。因此我们建立一个 file.txt 文件来告诉它。文件内部格式如下： . file &#39;path/to/file001.ts&#39; file &#39;path/to/file002.ts&#39; . 前面为关键词 file， 后面跟上视频的地址和名字。 ffmpeg 将会按照 txt 文件中的顺序将视频合并。 然后在命令行中输入如下命令： . ffmpeg -f concat -i file.txt -c copy output.mp4 .",
            "url": "https://invisprints.github.io/blog/others/2017/04/13/%E7%94%A8-ffmpeg-%E6%89%B9%E9%87%8F%E5%90%88%E5%B9%B6%E8%A7%86%E9%A2%91.html",
            "relUrl": "/others/2017/04/13/%E7%94%A8-ffmpeg-%E6%89%B9%E9%87%8F%E5%90%88%E5%B9%B6%E8%A7%86%E9%A2%91.html",
            "date": " • Apr 13, 2017"
        }
        
    
  
    
        ,"post53": {
            "title": "Linux下远程传输",
            "content": "Linux下远程传输 . 介绍 Linux 两个常用工具，scp 和 wget。 . Scp . scp 主要用于文件传输。 . 命令格式： . scp [参数] [原路径] [目标路径] . 常用参数： . -r 递归复制整个目录。   -l limit 限定用户所能使用的带宽，以Kbit/s为单位。         -P port 注意是大写的P，port是指定数据传输用到的端口号    . 使用实例： .   . 从本地服务器复制文件到远程服务器：  . scp local _file remote _username@remote _ip:remote _folder scp local _file remote _username@remote _ip:remote _file scp local _file remote _ip:remote _folder scp local _file remote _ip:remote _file . 第1,2个指定了用户名，命令执行后需要输入用户密码，第1个仅指定了远程的目录，文件名字不变，第2个指定了文件名   第3,4个没有指定用户名，命令执行后需要输入用户名和密码，第3个仅指定了远程的目录，文件名字不变，第4个指定了文件名  . 从本地服务器复制目录到远程服务器：   . scp -r local _folder remote _username@remote _ip:remote _folder scp -r local _folder remote _ip:remote _folder . 第1个指定了用户名，命令执行后需要输入用户密码；   第2个没有指定用户名，命令执行后需要输入用户名和密码； . 从远程服务器复制目录或文件到本地服务器：  . 从远程复制到本地的scp命令与上面的命令雷同，只要将从本地复制到远程的命令后面2个参数互换顺序就行了。 . . Wget . wget是一个从网络上自动下载文件的工具。它支持HTTP，HTTPS和FTP协议，可以使用HTTP代理。可以在用户退出系统的之后在后台执行。 . 断点续传。 . 当文件特别大或者网络特别慢的时候，往往一个文件还没有下载完，连接就已经被切断，此时就需要断点续传。wget的断点续传是自动的，只需要使用-c参数，例如： . wget -c http://the.url.of/incomplete/file . 使用断点续传要求服务器支持断点续传。-t参数表示重试次数，例如需要重试100次，那么就写-t 100，如果设成-t 0，那么表示无穷次重试，直到连接成功。-T参数表示超时等待时间，例如-T 120，表示等待120秒连接不上就算超时。 . 批量下载。 . 如果有多个文件需要下载，那么可以生成一个文件，把每个文件的URL写一行，例如生成文件download.txt，然后用命令： . wget -i download.txt . 这样就会把download.txt里面列出的每个URL都下载下来。（如果列的是文件就下载文件，如果列的是网站，那么下载首页） .",
            "url": "https://invisprints.github.io/blog/others/2017/04/13/Linux%E4%B8%8B%E8%BF%9C%E7%A8%8B%E4%BC%A0%E8%BE%93.html",
            "relUrl": "/others/2017/04/13/Linux%E4%B8%8B%E8%BF%9C%E7%A8%8B%E4%BC%A0%E8%BE%93.html",
            "date": " • Apr 13, 2017"
        }
        
    
  
    
        ,"post54": {
            "title": "快速阅读",
            "content": "快速阅读 . 手指跟读 . 防止走神，集中注意力，理想节拍器。 . 消除回读 . 回读分有意识和无意识，用手指能消除大部分回读。 . 良好阅读条件 . 光线 . 光线适中，手放在阅读材料30cm上无较深阴影。主光线从肩部上方，对着写字手的方向射入。 . 姿势 . 凳子不能坐着难受或太舒服，背靠直角椅背，眼睛同书45度角，离书40～50min ###生物钟 一天中合适的阅读时间。 ###干扰 保持身体健康，消灭内部干扰。合适外界环境，消灭内部干扰。 ##同时看多个单词 稍稍进阶，联系难度较大，不要求一次看的单词数过多。 .",
            "url": "https://invisprints.github.io/blog/others/2017/03/12/%E5%BF%AB%E9%80%9F%E9%98%85%E8%AF%BB.html",
            "relUrl": "/others/2017/03/12/%E5%BF%AB%E9%80%9F%E9%98%85%E8%AF%BB.html",
            "date": " • Mar 12, 2017"
        }
        
    
  
    
        ,"post55": {
            "title": "成甲：读书基础课",
            "content": "成甲：读书基础课 . 读书是最大改变你命运的机会，但也有可能是最大浪费你时间的事情。 . 方法针对非虚构类书籍，如哲学思辨，方法论；不适用于散文和小说类。 . [toc] . ##误区一：读书就是要把书读完 读书不一定要把书读完。 . 判断标准： . 是否了解作者给我们传递的信息。 | 读书是否改变我们生活。 | . 避免陷入低水平勤奋的陷阱。 让书给自己服务。 . ##误区二：读书要一页一页读 一把钥匙不能开所有的门，一种方法不能适用于所有的书籍。 . 方法服务于目的，让书为我们服务。 . ##让读书为我们服务 主动阅读：书的内容和我们生活有什么关系，主动寻找联系。 . 如： 书：理性和情绪不能同时工作。 生活：平息他人情绪。 . ##第一步：5分钟破解一本书 四大板块：封、目、序、尾。 . 例子：《好好学习，个人精进指南》 . ####封面： . 题目：知识管理内容，深度讲解学习方法 | 文字：把知识运用到生活中。 | . ####目录： 带着好奇阅读不懂之处。 心中拥有大致地图。 . ####序言： 结合目录看。 写作目的。 核心结构。 . ####结尾： 总结。 拔高。 作者期望总结全书，再次阐述全书。 . 读书的二八原理：封面目录序言结尾是重点。 . ##第二步：先写答案再看答案 先不看书。 把自己对书中问题的答案写出来，再与书中内容进行比较。 不断辩证，不断改进。 . ##结硬寨，打呆仗 避免陷入懂了很多大道理但却过不好自己的人生。 . 不要追求快速读完多少内容，而是想如何把书中的内容应用到生活中。 . 现象层、原因层、行动层。 . 例子：“FFC”赞美法 赞美一个人从感受（Feeling），事实（Fact），比较（Compare）三个层面出发。 现象层：过去我的观点，现在别人的观点，谁好？ 原因层：为什么好？怎么想出来的？ 行动层：应用于生活中，为我们服务。举一反三。 . 以慢为快。 . ##第四步：判断是否扩大战役 判断是否继续要把书读完。 . 是否顺着作者和书籍找到相应圈子和领域。 . ##总结 破题，准备，钻研，判断。 . ##技巧 ###标记书中重点内容 ####彩虹笔记法： 防止事后忘记当时标记的意思。 . 红色：启发内容，重要总结。 | 黄色：疑问。 | 绿色：重要数据案例。 | . 适用于纸质书和电子书。 . ###不懂之处 留白法： 把不懂的地方标记出来（参考彩虹笔记法），带着困惑读后面内容。 . 事后选择忽略或专攻这些问题。 . ###管理知识 传统且有效：剪报纸，卡片法。 . 现代方法： . 云笔记：印象笔记。随时随地汇集一处并查阅。 | 行动清单：将零碎的启发花时间集中分类，同一类型集中在一张纸上。类似于好（错）题本。 | . ##高效阅读核心与进阶 核心思路：所有的阅读应当从使用开始 . 改变自己的行动作为阅读的起点和终点。 .",
            "url": "https://invisprints.github.io/blog/others/2017/03/10/%E6%88%90%E7%94%B2-%E8%AF%BB%E4%B9%A6%E5%9F%BA%E7%A1%80%E8%AF%BE.html",
            "relUrl": "/others/2017/03/10/%E6%88%90%E7%94%B2-%E8%AF%BB%E4%B9%A6%E5%9F%BA%E7%A1%80%E8%AF%BE.html",
            "date": " • Mar 10, 2017"
        }
        
    
  
    
        ,"post56": {
            "title": "秋叶：从零开始打造你的个人IP 学习笔记",
            "content": "秋叶：从零开始打造你的个人IP 学习笔记 . 记下了秋叶老师小讲时候的一些关键点，适合听后人士复习参照 . ##什么是个人IP 知识产权，比如写小说，小说改编权可能就很值钱 自媒体 专业领域深厚积累，同时有现实影响力，知识型IP . ##做个人IP 拥有一样受大众欢迎的专长，积累足够多，能持续输出 不依赖推手，这样不会轻易过时和淘汰 ##不懂传播，更适合做专业顾问 一定规模的基础粉丝 会表演、分享、写作、演讲等专长 拥有媒体传播领域 ##选对你的发展平台 时政评论：新浪博客 娱乐八卦：今日头条 争议话题：微博 影评：豆瓣 学习成长：简书 演讲：写书，线下巡讲，喜马拉雅 分享：微课平台，如千鸟，知乎live 颜值与表情包：直播 . ##选对IP标签 受众面大，竞争也大的跑道：笑到最后 受众面相对较小，竞争压力也小的跑道：做到第一，再顺势切入更宽更长的跑道 . 卡位：不管如何卡位，都必须先有爆款的产品出现。 先让别人记住你，再通过系列化的产出，让别人强化对你的认知，从而形成标签 . ##马上就做，不要等到准备好再出发 不仅要学习技能，还要学会传播。把学习与输出结合起来做，需要持续化专业化输出。 一开始并不需要通过输出加粉，而是打磨自己的传播能力。 . ##向业内标杆学习 知识向标杆学习，传播也要像标杆学习。 看自媒体的微博微信，翻阅历史文章可以学习很多技巧 . ##链接比你更厉害的人 争取行业内有影响力的大咖的认同和推荐，加入他们的圈子，近距离观察他们做人做事的方法 . ##个人IP变现渠道 出售产品，出售影响力，出售时间 . 打磨有影响力的产品 在线课程，微课，出书 . 出售影响力 广告，形象代言人 . 出售时间 打赏，付费阅读，付费问答 . ##个人IP社群运营 未来社会三种人：媒体人，产品人，运营人 . 沉淀口碑，持续输出，建立社群，让用户互相连接，激发氛围 个人自媒体+社群+现金流产品 . ##成为个人IP路上最大挑战 心态，工匠精神 能力，胜任成为IP的长跑道 运气 .",
            "url": "https://invisprints.github.io/blog/others/2017/03/05/%E7%A7%8B%E5%8F%B6-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%89%93%E9%80%A0%E4%BD%A0%E7%9A%84%E4%B8%AA%E4%BA%BAIP-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html",
            "relUrl": "/others/2017/03/05/%E7%A7%8B%E5%8F%B6-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%89%93%E9%80%A0%E4%BD%A0%E7%9A%84%E4%B8%AA%E4%BA%BAIP-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html",
            "date": " • Mar 5, 2017"
        }
        
    
  
    
        ,"post57": {
            "title": "朱晓华：快速阅读",
            "content": "朱晓华：快速阅读 . 适合收听了朱晓华小讲的人士复习参考 . ##引言 读书的收获=阅读速度*方法效率*投入时间*选书水平 . 纸质书 手机App 训练手册 . ###告别默读 视觉信号直接到达脑区，不经过听觉信号 看书时一片一片看书 强迫自己比默读速度快，默读就自然停止 节拍器练习摆脱练习，找一本读起来轻松的书，用正常速度读20行计时，计算读一行的时间 在节拍器上设置一拍的时间短于一行时间，手指指书，节拍器每打一拍，手指就从左到右扫一行，眼睛跟着手指看。不断调整节奏，直到默读跟不上节拍，直到形成习惯。 . ###消除回读 眼睛中只有大约左右15度的视角是看清细节，善于阅读的，其他的是形成轮廓。 看书时需要不断移动视觉焦点才能阅读。 用手和笔引导视线，消除回读。眼睛更关注移动的东西。 节拍器辅助引导。 . ###多方向阅读 手和笔引导视线 S行看 一段时间后一次性看2行，3行乃至多行 越快理解力越高 . ###电子书 多看阅读 字调大： . 看得更轻松 | 一眼看一行 | . 视觉中心：中间偏左 . 自动翻页：消除默读 . ###听书 真人朗读速度慢，材料少 语音合成，文字朗读，速度可调整 . ###技巧 多加书签，防止分神 看效果更好，但投入更多 听操作更方便，可同时运作 . ###总结 App听书开始练起，成效后挑战纸质书阅读技巧 . ###材料 《如何高效阅读》 彼得·孔普 《快速阅读》 东尼·博赞 《超级快速阅读》 格吕宁 《脑的阅读》 迪昂 . ###问答 读完书马上复习一次，之后整理笔记，放入全文检索库 不需要刻意复习，只需在需要的时候复习即可 .",
            "url": "https://invisprints.github.io/blog/others/2017/03/05/%E6%9C%B1%E6%99%93%E5%8D%8E-%E5%BF%AB%E9%80%9F%E9%98%85%E8%AF%BB.html",
            "relUrl": "/others/2017/03/05/%E6%9C%B1%E6%99%93%E5%8D%8E-%E5%BF%AB%E9%80%9F%E9%98%85%E8%AF%BB.html",
            "date": " • Mar 5, 2017"
        }
        
    
  
    
        ,"post58": {
            "title": "ssh 远程连接",
            "content": "#ssh 远程连接 从最易上手的开始讲，比如我们想连接一个服务器，服务器IP地址是192.168.1.1，账号username，那么我们输入如下两个命令中的一个命令即可 . ssh username@192.168.1.1 ssh -l username 192.168.1.1 . 如果远程服务器指定了端口，我们只需添加-p命令即可 例如登陆极路由后台（抱歉打了软广） . ssh root@192.168.199.1 -p 1022 . 以root身份登录到IP为192.168.199.1的服务器中，连接端口为1022 . 查看SSH客户端版本 . 使用ssh -V命令可以得到版本号。需要注意的是，Linux和macOS一般自带的是OpenSSH。下面的例子即表明该系统正在使用OpenSSH： . $ ssh -V OpenSSH_7.3p1, LibreSSL 2.4.1 . 查看服务器是否安装sshserver . 有些时候我们无法用ssh 连接远程服务器，原因可能是服务器上并没有安装ssh服务端，特别是用最小安装包安装系统时，一般都没有安装ssh服务端。 . 在服务器终端输入 . ssh localhost . 如果出现下面信息则没有安装sshserver . ssh: connect to hostlocalhost port 22: Connection refused . ##安装sshserver ubuntu: . sudo apt-get install openssh-server . 安装完成后启动服务 . service ssh start . 用SSH登录到远程主机 . 当你第一次使用ssh登录远程主机时，会出现没有找到主机密钥的提示信息。输入”yes”后，系统会将远程主机的密钥加入到你的主目录下的 .ssh/know_hosts下，这样你就可以继续操作了。 当你第二次登陆远程主机时，只需要你输入远程主机的登录密码即可。 . ##ssh无密码登入 . 事实再一次证明英文帮助文档常常把一个简单的功能解释的又臭又长 . 该方面目前适用于macOS 10.12以后的版本！！！ | . 使用命令生成ssh登录的公钥和密钥 . ssh-keygen -t rsa -C &quot;uesrname@remotehost&quot; . 接下来按照提示完成想要的设置 执行命令将密钥添加到Mac的keychain，其中id-rsa是你生成的密钥地址 . ssh-add -K ~/.ssh/id_rsa ssh-add -A . 编辑配置文件，在~/.ssh/config中添加如下命令 . Host * AddKeysToAgent yes UseKeychain yes IdentityFile ~/.ssh/id_rsa . 用SSH退出符切换SSH会话 . 这个技巧非常实用。尤其是远程登陆到一台主机A，然后从A登陆到B，如果希望在A上做一些操作，还得再开一个终端，很是麻烦。 当你使用ssh从本机登录到远程主机时，你可能希望切换到本地做一些操作，然后再重新回到远程主机。这个时候，你不需要中断ssh连接，只需要按照如下步骤操作即可： 当你已经登录到了远程主机时，你可能想要回到本地主机进行一些操作，然后又继续回到远程主机。在这种情况下，没有必要断开远程主机的会话，你可以用下面的办法来完成： . 登入远程主机： . localhost$ ssh -l username remotehost 已连接远程主机： remotehost$ 要临时回到本地主机，输入退出符号：`~`与`Control-Z`组合。 当你输入`~`你不会立即在屏幕上看到，当你按下`Control-Z`并且按回车之后才一起显示。如下，在远程主机中以此输入`~&lt;Control-Z&gt;` remotehost$ ~^Z [1]+ Stopped ssh -l username remotehost localhost$ . 现在你已经退回到了本地主机，ssh远程客户端会话就在UNIX后台中运行，你可以向下面那样查看它： . localhost$ jobs [1]+ Stopped ssh -l username remotehost 你可以将后台运行的ssh会话进程切换到前台，重新回到远程主机，而无需输入密码 localhost$ fg %1 ssh -l username remotehost remotehost$ .",
            "url": "https://invisprints.github.io/blog/others/2017/02/25/ssh-%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5.html",
            "relUrl": "/others/2017/02/25/ssh-%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5.html",
            "date": " • Feb 25, 2017"
        }
        
    
  
    
        ,"post59": {
            "title": "Automator",
            "content": "Automator 使用案列 . 尽管前端时间爆出Apple撤销了自动化部门，但是automator对于大量重复性生产工作的任务依然有着windows无法达到的优势 ##将多份ppt一键转化成pdf 本人是学生，对于许多ppt课件，转换成pdf稍后学习是本人的刚需 在Automator中新建文稿，选择服务，然后如下配置 . 其中AppleScript代码部分如下： . on run {input, parameters} set theOutput to {} tell application &quot;Microsoft PowerPoint&quot; -- work on version 15.15 or newer launch set theDial to start up dialog set start up dialog to false repeat with i in input open i set pdfPath to my makeNewPath(i) save active presentation in pdfPath as save as PDF -- save in same folder close active presentation saving no set end of theOutput to pdfPath as alias end repeat set start up dialog to theDial end tell return theOutput end run on makeNewPath(f) set t to f as string if t ends with &quot;.pptx&quot; then return (text 1 thru -5 of t) &amp; &quot;pdf&quot; else if t ends with &quot;.ppt&quot; then return (text 1 thru -4 of t) &amp; &quot;pdf&quot; else return t &amp; &quot;.pdf&quot; end if end if end makeNewPath . 保存好以后就可以直接使用了，在选中需要转换的ppt之后，右键-服务-你保存的服务的名字 .",
            "url": "https://invisprints.github.io/blog/software/2017/02/16/Automator-%E4%BD%BF%E7%94%A8%E6%A1%88%E5%88%97.html",
            "relUrl": "/software/2017/02/16/Automator-%E4%BD%BF%E7%94%A8%E6%A1%88%E5%88%97.html",
            "date": " • Feb 16, 2017"
        }
        
    
  
    
        ,"post60": {
            "title": "Final Cut Pro X",
            "content": "Final Cut Pro X 学习笔记 . 参照Final Cut Pro X 10.1 非线性编辑高级教程 . 本学习笔记仅针对于那些阅读过Final Cut Pro高级教程的人，方便他们遗忘时快速查阅 . [toc] . ##导入媒体 ###备份原媒体 对于Final Cut Pro可识别的设备，可以在导入界面单击左下角的创建归档来创建备份 ###个人收藏 如果需要经常打开某一文件导入视频，可以在导入界面右键选择该文件夹，单击“个人收藏” ###媒体导入选项 创建优化的媒体：将生成一个新的Apple ProRes 422文件，该文件适合合成、特效的工作，减少处理运算时间 创建代理文件：生成新的Apple ProRes 422(Proxy) 文件，该文件体积较小 ###一个片段中标记多个选择范围 运用cmd-shift-i 和cmd-shift-o快捷键 ###从其他软件中拖动 在Final Cut Pro的偏好设置中单击导入图标，可以设置从其他软件拖动时的一些默认选项。 导入时操作光标的信息： 加号➕：将文件拷贝进 拐弯的箭头：让文件包保留在原位 . ##整理片段 在选择片段中某一部分时，可以用左右键逐帧调整。 ###关键词使用 应用关键词可以减少搜索想要片段的时间，关键词不能太独特，定位介于名字和事件之间。 关键词可以分配到整个片段或部分片段上，在被关键词标记的片段上方会出现蓝线。 ####添加关键词 选中目标片段后，在工具栏上单击“关键词编辑器”按钮🔑 打开关键词编辑器HUD，输入相应关键词，【Enter】键完成该关键词 . 若想创建空的关键词精选，右键事件，点击“新建关键词精选” 创建好后可以将相应片段拖动到该关键词精选中 . 可以事先将关键词输入到关键词编辑器HUD中，这样可以利用快捷键快速添加关键词 ###修改名称 选中某些片段后，选择“修改&gt;应用自定名称” ###添加注释 注释只能对整个片段添加，在列表视图或检查器中添加 ###评价片段 未评价：新导入的片段都默认未评价 个人收藏：被添加进个人收藏的 片段或部分片段 画面上会显示绿线，个人收藏标签可被重命名和添加注释 拒绝片段：拒绝片段默认被隐藏起来 ###搜索过滤排序 浏览器的搜索栏可以对元数据进行搜索，过滤器图标可以添加更多搜索条件。 . 创建智能精选： 相当于把过滤器的搜索条件保留下来 ###侦测任务和拍摄场景 右键被选择的片段，在快捷菜单中选择“分析并修正”命令 勾选“查找人物”和“在分析后创建智能精选” 下面是分析后可能得到的结果： . 幅面 人物 . 特写镜头 | 单人 | . 中等镜头 | 两人 | . 宽镜头 | 三人 | . ###角色 分配角色有助于剪辑操作，在剪辑时决定哪些角色起作用，哪些不起作用 ####分配角色 选择“修改&gt;编辑角色”，打开角色编辑器 单击加号添加角色，接下来有几种方法把角色分配给一些片段，选定片段后 . 单击“修改&gt;分配**角色” | 打开信息检查器，选择相应角色 | 可以给多组片段同时设定角色 . 在“角色”索引中，取消一些角色，该角色所指向的片段将被禁用，这样可以减少修剪某些片段时其他片度的干扰 . ##前期剪辑 ###项目 对应于Premiere的序列，所有视频剪辑工作都是在项目上的时间线上剪辑 概念点： 主要故事情节 创建项目 磁性连接 追加片段 片段外观 扫视 将多个片段同时追加到主要故事情节上 . 令播放头位于时间线最开始地方：按住【Fn】，再按下左箭头⬅️键 . ###波纹修建 . 切换到选择工具 | 在时间线上将光标放在该片段末尾，直到波纹修建工具图标上出现胶卷，如果向左延伸，则会修剪左侧片段 | 按住鼠标并拖动，直到修建到理想位置 | 键盘精准修剪 | . 选中该片段的起始点或结束点，按,向左修剪一帧，按.向右修剪一帧 . 更改片段时间长度 . | 选择某一片段，右键单击更改时间长度，或快捷键ctrl-D在Dashboard中输入数字，若想5秒，输入“5.(Enter)”，此为裁剪掉超时部分 | 选择某一片段，进入自定速度界面，更改速度 | . ###调整主要故事情节的时间 波纹删除：直接按【Del】删除片段，后续片段向左滑动填充空隙 空隙片段代替：按【Shift-Del】组合键，在该片段位置留下相同时间长度的空隙片段，后续片段不动 . 插入空隙片段：将播放头放在想插入空隙的位置，选择“编辑&gt;插入发生器&gt;空隙”命令，空隙默认3秒，可调整空隙时间长度 . 切割片段：熟记快捷键 接合片段：选择接合编辑点，按【Del】键删除接合编辑点。仅对该结合点左右部分原来就连接在一起的片段有用 . ###在主要故事情节上方进行编辑 添加切入切除片段，快捷键Q，添加的片段都是连接片段，随主要故事情节移动 按住cmd-option再单击连接片段的底部可以重新确定连接点 . 覆盖连接： 按住【`】键拖动主要故事情节，此时光标的形状变成一个斜杠横过连接片段，表示Final Cut Pro忽略任何连接片段，连接片段不随主要故事情节移动 . ###连接的故事情节 连接的故事情节是一种容器，容纳一些片段。若希望在连接的故事情节中插入一个新片段，必须选择这个横栏再进行剪辑，而不能选择该故事情节中的某一个片段 . 创建故事情节：选择某些片段后，右键-创建故事情节或使用快捷键 . 在同一个故事情节的片段之间有主要故事情节的一些特性，如磁性时间线。可以进行波纹修剪和卷动修剪（不影响故事情节的时间长度） . ###在主要故事情节下方进行编辑 添加背景音乐，快捷键【Q】 . ###调整剪辑 音量控制线 渐变手柄：在音量控制线的开头结尾 独奏：Option-S . 添加标记：M 标记可以与标记对齐，适用于音频节奏和视频画面对齐 . 调整片段音量： 单击Dashboard的音频指示器按钮，出现大号音频指示器 选择多个片段，按ctrl--和ctrl-=同时添加或减少片段音量 . 转场和渐变手柄的使用 . ##剪辑修改 多版本项目： . 快照：与原项目再无任何关系，可当作备份 | 复制项目：某些特殊片段类型会保持动态更新，如复合片段 | . ###将片段从故事情节中举出|替换片段 保证所有连接片段和故事情节同步 . 选择需要的片段 | 右键，选择“从故事情节中拷贝” | “替换” | . | ###创建Time at 0:00 ####例1 将播放头向左移动3秒 将播放头移动到指定位置后，按ctrl-P，Dashboard上的数值会被清除，等待输入新的数字 既可以输入时间码数值，也可以输入位移量数值，这次用位移量数值 在键盘上按-（=的话是向右移动），接着输入3.，此时Dashboard显示出播放头将要向左移动3秒的长度 按回车键确定 . ####例2 倒放 选中指定片段，在视频检视器左下角点击重新定时按钮 点击倒转片段按钮，此时片段上方会出现横栏，标志相应信息 在重新定时下拉菜单中选择“隐藏重新定时按钮”可隐藏横栏 . ###标记 一共有四种形式的标记： . 标准 | 待办事项 | 已完成 | 章节 | . 在浏览器窗格中，可以通过搜索栏找到标记；在时间线中，可以通过时间线索引窗格找到片段中的标记 . 时间线索引：时间线索引有3种索引：片段，标记和角色。都支持搜索和多个选择范围 | 创建标记：按一下M创建标记。连按两下创建标记并打开 | . ###位置工具 类似于Premiere上的覆盖操作 . 位置工具快捷键：P 覆盖编辑：D . ###试演 将多个镜头打包起来，以同一个片段的形式放置在项目中，方便切换比较 . 选中多个相似片段，右键选择“创建试演”，此时浏览器会出现一个新的试演片段 单击试演片段上的聚光灯图标，打开试演窗口 左右键可切换不同片段，单击“完成”确定 试演片段可以像普通片段一样加入到时间线中 . 避免试演引发的波纹：将试演片段举出，令其成为一个连接片段，并在故事情节中留下空隙片段 . ###修剪开头结尾 修剪结尾：option-] 修剪开头：option-[ 修剪到所选部分：option- . 复制片段：按住【option】并拖动片段 . ##精剪 ###片段重新定时 cmd-R 调出重新定时编辑器 在定时器的最右侧，拖动把手，手动调整片段播放速度 在速度下拉菜单选“自定”命令，手动输入播放速度，波纹选项指的是后续片段跟不跟随移动 . ####切割速度 一个片段中至少有两种不同的播放速度 . 将播放头移到需要速度变化的地方，从“重新定时”菜单中选择“切割速度”，快捷键shift-B，将速度调整到理想位置 在速度变化之间，会有速度转场，用于控制不同段落之间速度的变化，可以调整 在速度转场HUB中可以选择是否启用速度转场，源帧编辑器用于卷动编辑两个速度段落之间的内容 . ###视频效果 双击应用视频效果，扫视查看每个效果 ####景深效果 将需要创建景深效果的画面复制并粘贴，使粘贴的片段完全粘贴在原有片段的上方 停用下层视频画面，对上层视频应用遮罩效果，改变控制点的位置，露出想要景深的画面部分 对上层视频应用高斯效果，恢复下层视频，调整上层视频遮罩范围和高斯模糊程度，使其过渡自然 . ###转场 ####添加转场 . 选择某个编辑点，应用转场，转场会应用到该编辑点上 | 选择一个片段，应用转场，转场会应用到该片段的开始点和结束点上 | 选择某些片段，按cmd-T快捷键，这些片段都会添加默认的转场（一般是交叉叠化） | 媒体余量： 片段的编辑点是黄色的方括号形状，则至少有2帧的媒体余量可用于转场，如果是红色的，则没有媒体余量 在没有媒体余量时添加转场，软件会自动剪裁相应媒体，这样会影响后面其他片度的位置，整体时间长度变短。 . ####编辑自定转场 检查器 画面 时间线 选中转场后，按ctrl-D在Dashboard上调整转场时间长度 . ###画面合成 变换画面： 按住option键并单击想要变换的画面片段，在监视器中选择变换工具 . 修建与裁剪： 修建去除图像中某些部分，裁剪除了去除图像中某些部分，还会将剩余部分放大以填充当前画面的线框 . 视频动画编辑器：选中片段，右键显示视频编辑器，不透明度在复合选项中 . 复制粘贴属性：复制片段后，选择“编辑&gt;粘贴属性”，或者Cmd-Shift-V ##复合片段 可以将许多片段复合成一个复合片段，当其中一个复合片段更新时，其他项目中使用该复合片段的部分也会动态更新 创建复合片段右键或快捷键option-G 双击该复合片段即可编辑该复合片段 . ##完成剪辑 ###字幕 ####添加字幕 将播放头放到需要显示字幕的第一帧，在字幕浏览器中双击选好的字幕样式添加字幕 ####编辑字幕 双击时间线上的字幕，在检查器中编辑字幕，可对字幕中部分文字单独设置字体颜色等属性 ####字幕长度 够编辑师看两遍但不够看第三遍 ####延长编辑 . 选择片段结束点 | 将扫视播放头放在需要修剪到的位置上 | 按shift-X，片段结束点将自动与扫视播放头对齐 | ###音频 单独修建音频： 双击需要分离音频片段的音频波形部分，音视频就会分离。或者右键片段，单击展开音频 . 创建关键帧： 按住option键单击控制线，快捷键option-K . 音量动态范围： 电影院级别音响36dB，移动设备12dB动态范围 . 改变通道配置： 选择含有优先级的声音通道的片段 . 选择时间线上的片段： 在索引中搜索片段名称，或片段标记角色等，可以同时选择一个或多个片段 在音频检查器中找到“音频配置”选项，将立体声改成双单声道 取消第二个单声道，令其静音，使第一个通道成为唯一的采访谈话音源 . 关键帧范围选择： 使用范围选择工具（r键），在片段上选择某一区间，拖动控制线，这时系统会自动设定4个关键帧 . 片段浏览： 显示-片段浏览命令激活 激活后可以单独查看片段，没有上下片段和音频的混合干扰 . ###平衡颜色 ####自动白平衡 . 选择某一片段，单击视频画面检查器的魔术棒图标，会显示平衡颜色 | 单击平衡颜色，Final Cut Pro 会优化那帧画面，但整个片段并没有被分析 | ####手动调节片段曝光 只有片段被剪辑到项目中后，才能控制颜色调整参数 . 选择需要修改的在时间线上的片段，单击视频检查器中的魔术棒，选中显示颜色版 | 在“显示”选项卡中，单击”在检视器中显示“-视频观测仪 | 为方便调整，建议关闭浏览器 | 首先调整对比度，在视频观测仪中选择“显示”下面的一个小图标，选择“波形”和“RGB列示图“。 | 对比度第一步先调整像素亮度，在右边的“颜色板”中选择“曝光”标签，有四个可以调节的选项，从左到右分别是全局-阴影-中间调-高光，调整是注意要让所有亮度在0～100范围内 | 亮度调好后切换到“颜色”标签。 | ####手动调节片段色彩 1.在颜色版中选中颜色标签 . 四个圆球代表全局-阴影-中间调-高光，都位于一个方格上，方格上半部带有“+”号，为增加该颜色数值，方格下半部带有“-”号，为减少该颜色数值。在调整之前现在视频观测仪中调整到矢量显示器。 | 如果图像完全没有偏色问题，观测仪中所有代表像素的点会集中在中央。 | 观测仪中图像偏向哪种颜色，就在颜色版中将四个圆球拖向该颜色区域的下半部分 | 若调整过度，可单击还原按钮重新调整 | ####匹配颜色 为了在不同画面维持一致画面感觉，需要匹配颜色 . 选择需要调整的片段，按住option键单击该片段，在选中该片段的同时播放头也对准该片段 | 在检视器中选择魔术棒图标，单击”匹配颜色“，检视器此时会分成左右两个画面，左为原片段，右为需要调整的片段。 | 扫视到需要匹配的画面后，单击一下，右侧片段会更新匹配，效果满意后，单击“应用匹配项”。 | ##共享文件 ###捆绑包 将影片同时发布到多个位置。 打开Final Cut Pro偏好设置，选择“目的位置“-“添加目的位置”，将捆绑包拖入左侧边栏中，将需要的预置项目拖到捆绑包中，并给捆绑包重新命名 . ##导入文件 ###引用外部媒体 引用外部媒体的意思是让源文件保留在原位，Final Cut Pro会创建一系列替身文件指向源文件 . 创建好资源库和事件后，打开导入媒体窗口，选择指定片段后在右边选择“让文件保留在原位”，单击导入按钮 . 若遇到丢失文件状态，只需选择离线片段，“文件”-“重新链接文件”即可 | . ###文件拷贝进资源库 将原媒体文件直接内置于Final Cut Pro . 创建好资源库和事件后，打开导入媒体窗口，选择指定片段后在右边选择“拷贝到资源库”，单击导入按钮 . ###资源库内部拖动文件 将事件1中的视频移到事件2中只需鼠标拖动过去 将事件1中的视频复制到事件2中时，拖动的同时按住option键 . ###制作便携资源库 . 新建一个空的资源库，如“On the Go” | 选中要转移的事件，选择”将事件拷贝到资源库”-“On the Go” | 取消选择“优化的媒体”和“代理媒体”，选择“好“ | 选择该资源库”On the Go“，菜单栏中选择“文件”-“整合资源库文件” | 单击“好” | 关闭资源库 | ##双系统录制同步 有时会在不同设备上录制视频和音频，这时候需要将它们同步组合成一个新片段 . 选择视频和相对应的音频，右键选择“同步片段”命令，这时候会生成一个新的片段，在该资源库中。但此时该片段同时播放了视频中的音频和单独录制的音频，需要调整。 右键该同步片段，选择“在时间线中打开”，目前有两个方法关闭视频中的音频 . 将视频片段中的音量控制线向下拖到无限小 | 在音频检查器中取消“故事情节”选项 | . ##颜色抠像 选中需要抠像的片段，在效果浏览器中选择“抠像”-“抠像器”，双击应用效果。 对于被去掉的背景，还需要在该片段下方添加相应其他背景填充 利用遮罩工具，去掉其他的一些元素 . 若想手动选择样本颜色，则在视频检查器中将抠像器参数中的“强度”滑块拖到0% 找到“精炼抠像”中的样本颜色按钮，将光标移动到监视器上，在背景上拖出一个矩形框，去除背景 反复执行上一步骤，直到所有背景都消失 . ##快捷键 停用某段视频画面：V 添加默认转场过渡快捷键：cmd-T 选择工具：A 切割工具：B 滑动工具：T 位置工具：P 切割片段：Cmd-B 范围选择工具：R 吸附磁力：N 按照时间线上的长度选择开始点和结束点：X 向开始点和结束点填入视频内容（从结束点开始向前填充）：shift-Q 显示视频动画编辑器：ctrl-V 撤回编辑：shift-X 波纹修剪：T 连接编辑：Q 追加编辑：E 插入编辑：W 覆盖编辑：D 插入空隙：option-W 更改片段外观：ctrl-option-1, ctrl-option-down, ctrl-option-up 创建故事情节：cmd-G 独奏：Option-S 标记：M 扫视：S 隐藏重新定时编辑器：cmd-R 切割速度：shift-B 预览片段：/ 修剪结尾：option-] 修剪开头：option-[ 修剪到所选部分：option- 粘贴属性：cmd-shift-V 新建复合片段：option-G 关键帧：option-K 显示视频观测仪：cmd-7 显示颜色版：cmd-6 取消对任何项目的选择：cmd-shift-A 导入媒体：cmd-I 音频指示器：cmd-shift-8 将文件拷贝进：option 让文件包保留在原位：cmd-option 关键词编辑器：cmd-K 个人收藏：F 拒绝片段：Del 取消评价：U 打开检查器：cmd-4 放大时间线：cmd-= .",
            "url": "https://invisprints.github.io/blog/software/2017/02/14/Final-Cut-Pro-X-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html",
            "relUrl": "/software/2017/02/14/Final-Cut-Pro-X-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html",
            "date": " • Feb 14, 2017"
        }
        
    
  
    
        ,"post61": {
            "title": "MathStudio使用说明",
            "content": "MathStudio使用说明 . MathStudio作为iOS上最为强大的数学神器之一，以其丑陋的外表将许多人拒之墙外。本文参考网上《Math Studio中文教程——内置函数全翻译》和MathStudio官方教程，并融入个人经验 . 本文以MathStudio Express为例，MathStudio上的操作方法大致相似，如果读者想深入研究MathStudio，欢迎访问官网 . ##基本操作 当你第一次打开时，MathStudio会教你一些基本操作，这里不说明。 另外，在App顶部的Menu菜单中有Tutorials选项，对一些常用功能做了些讲解。 .     . 基础 | 解方程 | . 极限 | 求导 | . 积分 | 2D画图 | . 3D画图 | 矩阵 | . 自定义函数 | 脚本 | . 滑块 |   | . 如果你想尽快装逼，建议查看Menu中的Demos选项，里面内置了很多吊炸天的演示 . ###基础 跳过，这个系统计算器就可以胜任 ###解方程 . x^2=9 Solve(x^2+y^2=9,x) Solve(6,13,5) . 第一行表示可以解简单方程 第二行表示可以解带参数的方程，Solve()中第一个参数填方程，后面的参数填你要求解的变量 第三行是解一元二次方程的简便表达方式，个人测试这种表示法只支持一元二次方程 . Solve(x+y+z=5,x+2y=6,z-x=3) Solve(x^2+y^2=25, y^2=x^2+3) Solve(3sin(x)+exp(x)=2,x,[-2π,2π]) . 前两行表示可以求解多元多次方程 最后一行第三个参数表示约束了x的范围 ###求极限 . Limit((3-3tan(x))/(sin(x)-cos(x)),x,π/4) Limit(-1/x,x,0) Limit(n!/n^n,n,∞) Limit(cos(a*x)/x^2 - cos(b*x)/x^2,x,0) . 极限函数 Limit() 中第一个参数填表达式，第二个填变量，第三个填趋近的值 除了简单的求极限运算，我们可以看出这个函数支持无穷∞运算，带参数求极限 . ###求导 . D(x^6+3x,x) D(f(x),x) D(exp(-s*t),t) D(f(x)*g(x),x) D(a^(x^2),x) D(sin(3x+6),x,3) . 第一二行表示可以求导具体和抽象的方程 第三行表示可以求导带参数的方程 四五行表示可以按链式法则求解 最后一行最后一个参数表示求导次数，这里是连续求导三次 . ###积分 . ∫(sin(x)^2) ∫(x^2+y^2,x) ∫(1/(x^4+4),x) ∫(ln(x+1)^2*x,x,u=x+1) ∫(asin(sqrt(x)),x,u=sqrt(x),1) . ∫ 与 Integrate()函数等价 可以积分带参数的方程 第四行表示用x+1的形式表达积分结果，相当于用u替换x表达结果 最后一行的最后一个参数1我不知道什么意思，不过结果很炫酷！ . ###2D画图 . sin(x) sin(4𝛉) sin(4𝛉+T) [y,-x] [sin(x),cos(x)] . 第一行在输入框中输入完表达式后需要按键盘上面的Plot按钮 第二三行在输入表达式后需要按键盘上的Polar按钮（在数字键盘的上方的上方，需要滑动两次），显示为极坐标 第三行实现方法跟第二行一样 第四行在输入表达式后需要按键盘上的Vector按钮，显示为矩阵向量 第五行在输入表达式后按Plot按钮，显示为在笛卡尔坐标上同时显示两个函数图像 . ###3D画图 . cos(x+T)*sin(y+T) . 输入完成后按Plot按钮 . ###矩阵 . a=[[1,2],[3,4]] a(1) a(1,2) . 创建了一个2*2的矩阵，并赋值给a 显示a的第一行 显示a[1,2]的值，这里可以用数组的概念去理解 . ###函数 . f(x,y)=x^2+y^2 f(2,3) . 创建一个自定义函数 求特定的值 . ###脚本 . 这里需要图片说明，首先按下Script键 这里的脚本其实相当于更强大的函数，Name后填函数名称，Parameters后填变量，之后可以直接用了，想当年我的物理实验数据就是这样求出来的。 . ###滑块 . 本人觉得最好玩的功能，先按Slider按钮 底下的1……..a那行是可以拖动的，蓝色的是个滑块，由Slider定义，a为变量名，1为滑块最小值，10为滑块最大值，0.1为最小移动单位。 . ##深入了解 限于个人水平，在这个标题下仅做一些个人能力之内的事情 要想用好 MathStudio 需要经常查询Manual，里面给出了所有函数的具体使用方法 ###矩阵相关 ####matrix . matrix(3) matrix(2,3) matrix(2,6)+2 . 创建一个3*3的空矩阵 创建一个2*3的矩阵 创建一个2*6的矩阵并全部赋值为2 ##其他用法 . ###单位换算 这个功能不知道为什么在我的设备上无法运行，不过我宁愿用Siri也不会用这个功能 就贴几个官方的示意图 英里与千米换算 . 3@miles-&gt;@kilometers . 升与加仑换算 . 10@liters -&gt; @gallons .",
            "url": "https://invisprints.github.io/blog/others/2017/02/05/MathStudio%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E.html",
            "relUrl": "/others/2017/02/05/MathStudio%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E.html",
            "date": " • Feb 5, 2017"
        }
        
    
  
    
        ,"post62": {
            "title": "Vim配置文件",
            "content": "Vim配置文件 . Vim的配置 . Vim本身的系统配置文件夹是在/usr/share/vim/和/etc/vim/两个文件夹下。一般情况下，我们不会去改变这两个文件夹下的配置文件，而是在用户文件夹/home/user（其中，user为用户名）下建立自己的配置文件。进入用户文件夹（/home/user/）之后，用gedit新建一个名叫.vimrc的文件（进入终端）： . $ cd ~ $ gedit .vimrc . 注：使用gedit主要是为了方便大段大段的文字粘贴 然后把下面的文字拷贝进这个文件之后保存 . &quot; Configuration file for vim &quot; Normally we use vim-extensions. If you want true vi-compatibility &quot; remove change the following statements set nocompatible &quot; 去除VI一致性，不然没有vim特性 filetype off &quot; 必须 . 下面这段是配置vundle所需的配置段 . &quot; 设置包括vundle和初始化相关的runtime path set rtp+=~/.vim/bundle/Vundle.vim call vundle#begin() &quot; 另一种选择, 指定一个vundle安装插件的路径 &quot;call vundle#begin(&#39;~/some/path/here&#39;) &quot; 请将安装插件的命令放在vundle#begin和vundle#end之间. &quot; Github上的插件 &quot; 格式为 Plugin &#39;用户名/插件仓库名&#39; &quot; 让vundle管理插件版本,必须 Plugin &#39;VundleVim/Vundle.vim&#39; Plugin &#39;tczengming/autoload_cscope.vim&#39; &quot; 你的所有插件需要在下面这行之前 call vundle#end() &quot; 必须 filetype plugin indent on &quot; 必须 加载vim自带和插件相应的语法和文件类型相关脚本 &quot; 忽视插件改变缩进,可以使用以下替代: &quot;filetype plugin on &quot; &quot; 简要帮助文档 &quot; :PluginList - 列出所有已配置的插件 &quot; :PluginInstall - 安装插件,追加 `!` 用以更新或使用 :PluginUpdate &quot; :PluginSearch foo - 搜索 foo ; 追加 `!` 清除本地缓存 &quot; :PluginClean - 清除未使用插件,需要确认; 追加 `!` 自动批准移除未使用插件 . 开始个性配置 . set backspace=2 &quot; more powerful backspacing &quot; Don&#39;t write backup file if vim is being called by &quot;crontab -e&quot; au BufWrite /private/tmp/crontab. * set nowritebackup nobackup &quot; Don&#39;t write backup file if vim is being called by &quot;chpass&quot; au BufWrite /private/etc/pw. * set nowritebackup nobackup set bg=dark set hlsearch &quot;高亮匹配项 set autoindent &quot; always set autoindenting on set nu &quot; 显示行号 set relativenumber &quot; 相对行号 set showmatch &quot; 设置匹配模式，显示匹配的括号 set shiftwidth=4 set tabstop=4 &quot; 设置制表符(tab键)的宽度 set softtabstop=4 &quot; 设置软制表符的宽度 set shiftwidth=4 &quot; (自动) 缩进使用的4个空格 set cindent &quot; 使用 C/C ++ 语言的自动缩进方式 set cinoptions= {0,1s,t0,n-2,p2s,(03s,=.5s,&gt;1s,=1s,:1s &quot;设置C/C ++语言的具体缩进方式 colorscheme koehler set gfn=Osaka-Mono:h20 set tabstop=4 set transparency=10 &quot;macvim独有的透明特效 set backspace=indent,eol,start set foldmethod=syntax &quot;使用语法高亮定义代码折叠 set foldlevelstart=99 &quot;默认代码不折叠 set tags=tags; &quot;不断递归向上查找tags set showcmd &quot;显示正在输入的命令 set clipboard=unnamed &quot;共用系统剪贴板 . 下面是配置一些快捷键 . &quot;==========快捷键========= &quot; 调用lldb进行单步调试 map &lt;D-8&gt; call LLDB()&lt;CR&gt; func! LLDB() exec &quot;w&quot; exec &quot;!lldb %&lt;.out&quot; endfunc &quot; 调用gcc编译单文件 map &lt;D-9&gt; call Comm()&lt;CR&gt; func! Comm() exec &quot;w&quot; exec &quot;!gcc %&lt;.c -o %&lt;.out -g -Wall&quot; exec &quot;! %&lt;.out&quot; endfunc . &quot;========插件特殊配置======== &quot; autoload_cscope let g:autocscope_menus=0 &quot;关闭autoload_cscope的快捷键映射 nmap fc :cs find c &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt; nmap ft :cs find t &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt; nmap &lt;Down&gt; :cnext&lt;CR&gt; nmap &lt;Up&gt; :cprev&lt;CR&gt; .",
            "url": "https://invisprints.github.io/blog/others/2017/02/02/Vim%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6.html",
            "relUrl": "/others/2017/02/02/Vim%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6.html",
            "date": " • Feb 2, 2017"
        }
        
    
  
    
        ,"post63": {
            "title": "KMP 算法",
            "content": "KMP 算法 . 参考资料 . 本文参考算法导论，清华大学出版社的数据结构C语言版，伯乐在线的我理解的KMP算法，matrix67大神的博客，再根据自己理解写下这篇文章 . 正文 . KMP算法是解决字符串匹配问题，详细来说，是当前有A，B两个字符串，KMP算法就是来判断B串是否是A串子串的高效算法。比如你可以委婉地问你的MM：“假如你要向你喜欢的人表白的话，我的名字是你的告白语中的子串吗？” 相对于朴素的时间复杂度为O(mn)的比较算法（虽然在大多是情况下只有O(m+n) 但在这里我们只考虑最坏情况）KMP算法稳定在O(m+n) ，因此有较广泛的应用。 KMP算法是我遇到的第一个看了算法导论和网上一些资料后还有些懵懂的算法，后来发现其实主要原因是我们上数据结构这门课时老师讲的不是很清楚，所以有些关键的东西一直没有弄清。 . 出于对Matrix67大神的崇拜，直接引用他的例子说事。当前有两个字符串A=”abababaababacb”，B=”ababacb”，首先看看朴素算法是怎么工作的。我们用两个指针i和j分别表示，A[i-j+ 1..i]与B[1..j]完全相等。刚开始我们先从i=j=1开始比较，当我们发现i=j=5时，A和B的下一个字符就不相等了。 . i = 1 2 3 4 5 6 7 8 9 …… A = a b a b a b a a b a b … B = a b a b a c b j = 1 2 3 4 5 6 7 . 那么此时我们就要把i倒退回i=2，j倒退回j=1重新开始比较。 . i = 1 2 3 4 5 6 7 8 9 …… A = a b a b a b a a b a b … B = a b a b a c b j = 1 2 3 4 5 6 7 . 因此当我们遇到像A= “aaaaaaaaaaaaaaaaaaaaaaaaaab”，B=”aaaaaaaab”这样的字符串时，传统朴素算法每次匹配错误后B串只前进一格的做法就显得很慢。 KMP算法高效解决了字符串匹配中不断回退的问题，也就是上面例子中i从5倒退回2的问题。KMP算法的想法是相对于之前一次匹配不成功子串前进一格，能不能子串一次前进多个格子。在提出解决方案前，我们首先引入一些概念： . 部分匹配表 . 下面这个是“ababacb”这个模板的部分匹配表： . index: 1 2 3 4 5 6 7 . char: | a | b | a | b | a | c | b | . value: | 0 | 0 | 1 | 2 | 3 | 0 | 0 | . 如果我有一个7个字符的模板（这里我们就用“ababacb”来举例子），我的部分匹配表将会有7格。如果此时此刻我正匹配模板的第7格即最后一格，那意味着我匹配了整个模板（“ababacb”）；如果我正匹配模板的第6格，则意味着当前仅匹配了整个模板的前6位（“ababac”），此时第7位(“b”)是无关的，不用去管它；目前我还没有提到部分匹配表每格数据的含义，在这里仅仅是交代了大概。 . 现在，为了说明刚刚提到的每格数据的含义，我们首先要明白什么是最优前缀什么是最优后缀。 . 最优前缀 . 一个字符串中，去除一个或多个尾部的字符所得的新字符串就是最优前缀。例如 “S”、 “Sn”、 “Sna”、 “Snap”都是“Snape”的最优前缀。 . 最优后缀 . 一个字符串中，去除一个或多个首部的字符所得的新字符串就是最优后缀。例如“agrid”、 “grid”、“rid”、 “id”、“d”都是 “Hagrid”的最优后缀。 . 有了两个概念，我现在可以用一句话来概括部分匹配表里每列数据的含义了： . 模板（子模板）中，既是最优前缀也是最优后缀的最长字符串的长度。 . 下面我举例说明一下这句话。我们来看部分匹配表的第3格数据，如果你还记得我在前面提到的，这意味着我们目前仅仅关心前3个字母（“aba”）。在“aba”这个子模板中，有两个最优前缀（“a”和“ab”）和两个最优后缀（“a”和“ba”）。其中，最优前缀“ab”并不是最优后缀。因此，最优前缀与最优后缀中，相同的只有“a”。那么，此时此刻既是最优前缀也是最优后缀的最长字符串的长度就是1了。 . 我们再来试试第4格，我们应该是关注于前4个字母（“abab”）。可以看出，有3个最优前缀（“a”、“ab”、 “aba”）和3个最优后缀（“b”、“ab”、“bab”）。这一次 “ab” 既是最优前缀也是最优后缀，并且长度为2，因此，部分匹配表的第4格值为2。 . 这是很有趣的例子，我们再看看第5格的情况，也就是考虑“ababa”。我们有4个最优前缀（“a”、 “ab”、“aba”，和“abab”）和4个最优后缀（“a”、 “ba”、“aba”，和“baba”）。现在，有两个匹配“a”和“aba” 既是最优前缀也是最优后缀，而“aba”比“a”要长，所以部分匹配表的第5格值为3。 . 看看第6格的情况，不难看出，这两个集合之间不会有任何的交集。因为，所有最优后缀都以“c”结尾，但没有任何最优前缀是以“c”结尾的，所以没有相匹配的，因此第7格值为0。 . 当我们找到了部分匹配的字符串时，可以用部分匹配表里的值来跳过前面一些字符（而不是重复进行没有必要的比较）。具体是这样工作的： 当i=j=5时，i的值保持不变，j=3，然后继续比较。当i=7，j=5时发现下一组又不相等了，此时i保持不变，j=3，然后又开始比较。也就是说，i是不断增加的，随着i的增加j相应地变化，且j满足以A[i]结尾的长度为j的字符串正好匹配B串的前 j个字符（j当然越大越好）。那么如何得知j该等于多少呢，现在需要检验A[i+1]和B[j+1]的关系。当A[i+1]=B[j+1]时，i和j各加一；什么时候j=m了，我们就说B是A的子串（B串已经整完了），并且可以根据这时的i值算出匹配的位置。当A[i+1]!=B[j+1]，KMP的策略是调整j的位置（减小j值）使得A[i-j+1..i]与B[1..j]保持匹配且新的B[j+1]恰好与A[i+1]匹配（从而使得i和j能继续增加）。 . 我们看一看当 i=j=5时的情况。 . i = 1 2 3 4 5 6 7 8 9 …… A = a b a b a b a a b a b … B = a b a b a c b j = 1 2 3 4 5 6 7 . 此时，A[6]!=B[6]。这表明，此时j不能等于5了，我们要把j改成比它小的值j’。j’可能是多少呢？仔细想一下，我们发现，j’必须要使得B[1..j]中的头j’个字母和末j’个字母完全相等（这样j变成了j’后才能继续保持i和j的性质）。这个j’当然要越大越好。而这恰好是部分匹配表的性质，即我们要找既是最优前缀又是最优后缀的最长字符串。在这里，B [1..5]=”ababa”，”aba”就是我们想要的，于是j=next[j]。而当新的j为3时，A[6]恰好和B[4]相等。于是，i变成了6，而j则变成了 4： . i = 1 2 3 4 5 6 7 8 9 …… A = a b a b a b a a b a b … B = a b a b a c b j = 1 2 3 4 5 6 7 . ps：代码不想写，上其他博客找吧。 .",
            "url": "https://invisprints.github.io/blog/algorithm/2016/11/13/KMP-%E7%AE%97%E6%B3%95.html",
            "relUrl": "/algorithm/2016/11/13/KMP-%E7%AE%97%E6%B3%95.html",
            "date": " • Nov 13, 2016"
        }
        
    
  
    
        ,"post64": {
            "title": "三元表稀疏矩阵转置[^foot_note]",
            "content": "三元表稀疏矩阵转置1 . 如何在茫茫人海中用最少空间标记你的女友，前女友，前前女友……的位置？ . 相对于普通矩阵还要保存其他人的信息，很明显，我们只需关注我的女友，前女友，前前女友的位置，其他人的位置我都不需要关注，因此我们建立一个顺序表，表中记录第几号女友和她的具体位置，这样我们可以节约大量空间。 这种记录方法就是传说中的三元组顺序表 . 三元组顺序表 . 三元组法是对于稀疏矩阵的一个有效记录方法，对于每一个非零元，我们分别记录下它的行坐标、列坐标和它的值。 . #define MAXSIZE 12500 typedef struct{ int i, j; //该非零元的行列坐标 ElemType e; //非零元信息 }Triple; typedef struct{ Triple data[MAXSIZE]; int mu, nu, tu; //行，列，非零元个数 } . 在这里默认三元组以行序为主序顺序排列 . ##矩阵转置 M(i,j)T=M(j,i)M(i, j)^T =M(j, i)M(i,j)T=M(j,i) 首先介绍个最容易想到的方法： ##方法一： . 元素互调：矩阵的行列值交换，如把元素行列值i=1,j=2换成i=2,j=1 | 重建三元组：重新将三元组以行序为主序排序 | 这个算法的时间复杂度为 O(tu*log(tu)) . 这个方法已经比数据结构书上的方法一好很多，但是本着做一个宇宙好公民，延缓宇宙熵增，我们要努力探究更好的方法 . ##方法二 如果在对i, j互调的过程中同时确定每一列第一个非零元的应有的位置，那么在重建三元组时就不需要排序。 . num[col] //记录第col列非零元素的个数 cpot[col] //第col列第一个非零元在新三元组中的位置 . 易知num[col]和cpot[col]的关系式是 . cpot[1]=1; cpot[col]=cpot[col-1]+num[col-1]; . 时间复杂度就将为令人惊讶的 O(tu) . ###灵感分析 在稀疏矩阵中有一种表示方法，它只记录每一行的个数和每一行开始的位置，在实现过程中的思路跟方法二一样 . 本文在清华出版社出版的数据结构基础上结合个人经验完成 &#8617; . |",
            "url": "https://invisprints.github.io/blog/others/2016/10/25/%E4%B8%89%E5%85%83%E8%A1%A8%E7%A8%80%E7%96%8F%E7%9F%A9%E9%98%B5%E8%BD%AC%E7%BD%AE-foot_note.html",
            "relUrl": "/others/2016/10/25/%E4%B8%89%E5%85%83%E8%A1%A8%E7%A8%80%E7%96%8F%E7%9F%A9%E9%98%B5%E8%BD%AC%E7%BD%AE-foot_note.html",
            "date": " • Oct 25, 2016"
        }
        
    
  
    
        ,"post65": {
            "title": "Linux 进程管理",
            "content": "#Linux 进程管理 ##查看正在运行的进程 可以使用 ps 命令查看进程的运行状态，包括后台进程，例如： . $ps PID TTY TIME CMD 18358 ttyp3 00:00:00 sh 18361 ttyp3 00:01:31 abiword 18789 ttyp3 00:00:00 ps . 还可以结合 -f 选项查看更多信息，f 是 full 的缩写，例如： . $ps -f UID PID PPID C STIME TTY TIME CMD amrood 6738 3662 0 10:23:03 pts/6 0:00 first_one amrood 6739 3662 0 10:22:54 pts/6 0:00 second_one amrood 3662 3657 0 08:10:53 pts/6 0:00 -ksh amrood 6892 3662 4 10:51:50 pts/6 0:00 ps -f . 每列的含义如下： . 列 描述 . UID | 进程所属用户ID | . PID | 进程ID | . PPID | 父进程ID | . C | CPU使用率 | . STIME | 进程被创建的时间 | . TTY | 与进程有关的终端类型 | . TIME | 进程所使用的CPU时间 | . CMD | 创建该进程命令 | . ps 命令还有其他一些选项： . 选项 说明 . -x | 显示无终端的进程 | . -u | 显示更多信息 | . -e | 显示所有进程 | . ##进程前后台命令 . command &amp; //将进程放在后台执行 ctrl-z //暂停当前进程 并放入后台 jobs //查看当前后台任务 bg //将任务转为后台执行 fg //将任务调回前台 kill //杀掉任务 .",
            "url": "https://invisprints.github.io/blog/others/2016/09/02/Linux-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86.html",
            "relUrl": "/others/2016/09/02/Linux-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86.html",
            "date": " • Sep 2, 2016"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "🥳About Me",
          "content": "研究生·深度学习 &amp; Fastai·二次元·沉迷研究各种无用工具和学习方法 .",
          "url": "https://invisprints.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  

  

  

  
  

  
      ,"page14": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://invisprints.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}